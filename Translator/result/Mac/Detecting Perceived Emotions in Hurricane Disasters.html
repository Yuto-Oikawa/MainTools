<meta charset="utf-8"/><h1 align="center">Detecting Perceived Emotions in Hurricane Disasters</h1>
<input id="btn-mode" type="checkbox">
<hr>
<body>
<div class="parent">
<div id="source">
<br><a id="s0" onmouseover="over('s0', 'r0')" onmouseout="out('r0')">Detecting Perceived Emotions in Hurricane DisastersShrey Desai1 Cornelia Caragea2 Junyi Jessy Li1</a><br><br><a id="s1" onmouseover="over('s1', 'r1')" onmouseout="out('r1')">1The University of Texas at Austin 2University of Illinois at Chicago {shreydesai@, jessy@austin.}utexas.edu cornelia@uic.edu</a><br><br><a id="s2" onmouseover="over('s2', 'r2')" onmouseout="out('r2')">Abstract</a><br><br><a id="s3" onmouseover="over('s3', 'r3')" onmouseout="out('r3')">Natural disasters (e.g., hurricanes) affect mil- lions of people each year, causing widespread destruction in their wake. People have recently taken to social media websites (e.g., Twitter) to share their sentiments and feelings with the larger community. Consequently, these platforms have become instrumental in under- standing and perceiving emotions at scale. In this paper, we introduce HURRICANEEMO, an emotion dataset of 15,000 English tweets spanning three hurricanes: Harvey, Irma, and Maria. We present a comprehensive study of fine-grained emotions and propose classi- fication tasks to discriminate between coarse- grained emotion groups. Our best BERT (De- vlin et al., 2019) model, even after task-guided pre-training which leverages unlabeled Twitter data, achieves only 68% accuracy (averaged across all groups). HURRICANEEMO serves not only as a challenging benchmark for mod- els but also as a valuable resource for analyz- ing emotions in disaster-centric domains.</a><br><br><a id="s4" onmouseover="over('s4', 'r4')" onmouseout="out('r4')">1 Introduction</a><br><br><a id="s5" onmouseover="over('s5', 'r5')" onmouseout="out('r5')">Natural disasters cause thousands of deaths and dis- place hundreds of millions each year (Ritchie and Roser, 2020). These catastrophic events not only induce material destruction but also stir an integral part of being human: our emotions. Disasters ad- versely affect individuals’ mental states (Fritz and Marks, 1954; Kinston and Rosser, 1974), and there- fore it is no surprise that many take to social media (e.g., Twitter) to share their feelings. Social me- dia websites, as a result, have become an essential platform for understanding the expression and per- ception of emotions at a significantly larger scale (Mohammad, 2012; Wang et al., 2012; Moham- mad and Kiritchenko, 2015; Volkova and Bachrach, 2016; Abdul-Mageed and Ungar, 2017), with far reaching potential influences from academic re-search to public policy (Dennis et al., 2006; Fritze et al., 2008; Fraustino et al., 2012).</a><br><br><a id="s6" onmouseover="over('s6', 'r6')" onmouseout="out('r6')">While natural language processing methods have been effective for emotion detection (Strapparava and Mihalcea, 2007), existing resources struggle in disaster-centric domains, in part due to distribu- tional shifts. Emotion detection in natural disasters (e.g., hurricanes) requires implicit reasoning not available as surface-level lexical information. For example, in “of course, [we]1 still have the [storm surge]2 coming,” given the context, we can rea- sonably infer discontent towards the “storm surge” despite the absence of polarizing words. There- fore, distantly supervised techniques largely based on lexical units (Mohammad and Turney, 2013; Abdul-Mageed and Ungar, 2017) fail to capture this type of deeper semantic phenomena.</a><br><br><a id="s7" onmouseover="over('s7', 'r7')" onmouseout="out('r7')">Our paper presents a comprehensive investiga- tion into perceived emotions in hurricane disas- ters. To this end, we introduce HURRICANEEMO, a dataset of 15,000 disaster-related tweets (in En- glish) streamed during Hurricanes Harvey, Irma, and Maria, which were devastating tropical storms occurring in the 2017 Atlantic hurricane season (Belles, 2017). Our samples are annotated with fine-grained emotions derived from the Plutchik Wheel of Emotions (Plutchik, 2001), a well-defined ontology of emotion classes commonly used in computational social science (Abdul-Mageed and Ungar, 2017).1 To measure inter-annotator agree- ment on fine-grained emotion labels, we concep- tualize the Plutchik Emotion Agreement (PEA) metric (§3). PEA is intuitively grounded; our hu- man evaluation shows workers agree with PEA’s rankings 88% of the time. Furthermore, we per- form insightful analyses on implicit and explicit emotions in hurricane tweets (§4). Quite surpris-1Specifically, we use Plutchik-8 and Plutchik-24 emotions. We refer readers to Plutchik (2001) for an in-depth discussion on their conception.</a><br><br><a id="s8" onmouseover="over('s8', 'r8')" onmouseout="out('r8')"> arXiv:2004.14299v1 [cs.CL] 29 Apr 2020</a><br><br><a id="s9" onmouseover="over('s9', 'r9')" onmouseout="out('r9')">ingly, we find consistencies in Plutchik-24 emotion distributions across Hurricanes Harvey, Irma, and Maria.</a><br><br><a id="s10" onmouseover="over('s10', 'r10')" onmouseout="out('r10')">HURRICANEEMO also serves as a challenging new benchmark for large-scale, pre-trained lan- guage models. We establish baselines for a coarser Plutchik-8 emotion detection task using BERT (De- vlin et al., 2019) and RoBERTa (Liu et al., 2019) (§5). Our experiments reveal: (1) BERT only achieves 64% (averaged) accuracy; and (2) using</a><br><br><a id="s11" onmouseover="over('s11', 'r11')" onmouseout="out('r11')">“better” pre-trained models (e.g., RoBERTa) does not help, which is a strikingly different trend than most leaderboards (Wang et al., 2018). To better understand their pitfalls, in particular BERT, we conduct a comprehensive error analysis of 200 in- correctly predicted samples. In addition, we incor- porate stronger inductive biases into BERT via pre- training on related tasks, which culminates in (av- eraged, absolute) +4% accuracy (§6). Finally, we propose unsupervised domain adaptation to bridge the domain gap between existing large-scale emo- tion datasets (e.g., EMONET (Abdul-Mageed and Ungar, 2017)) and HURRICANEEMO (§7). Our code and datasets are made publicly available.2</a><br><br><a id="s12" onmouseover="over('s12', 'r12')" onmouseout="out('r12')">2 Related Work</a><br><br><a id="s13" onmouseover="over('s13', 'r13')" onmouseout="out('r13')">Emotion detection has been extensively studied in news headlines (Strapparava and Mihalcea, 2007; Katz et al., 2007), blog posts (Aman and Szpakow- icz, 2007), health-related posts (Khanpour and Caragea, 2018), and song lyrics (Strapparava et al., 2012), but only recently, in social media websites (e.g., Twitter, Facebook) (Mohammad, 2012; Wang et al., 2012; Mohammad and Kiritchenko, 2015; Volkova and Bachrach, 2016; Abdul-Mageed and Ungar, 2017). However, emotion detection in disaster-centric domains, despite its practical im- portance, is limited. Schulz et al. (2013) (single- handedly) annotate 2,200 Hurricane Sandy tweets using Ekman-6 emotions (Ekman, 1992). In con- trast, we introduce 15,000 annotated tweets from multiple hurricanes with (much more fine-grained) Plutchik-24 emotions. Unlike Abdul-Mageed and Ungar (2017), we focus on readers’ perceived emo- tions rather than writers’ intended emotions.</a><br><br><a id="s14" onmouseover="over('s14', 'r14')" onmouseout="out('r14')">Furthermore, in disaster-centric domains, the lack of labeled data required to train reliable mod- els precludes the use of supervised learning tech- niques. Several works propose to use labeled data</a><br><br><a id="s15" onmouseover="over('s15', 'r15')" onmouseout="out('r15')">2https://github.com/shreydesai/ hurricanefrom prior (source) disasters to learn classifiers for new (target) disasters (Verma et al., 2011; Nguyen et al., 2017; Imran et al., 2013, 2016; Caragea et al., 2016). However, due to the unique nature of each disaster (e.g., type, geographical location, season, cultural differences among the affected pop- ulation), the source disaster may not accurately re- flect the characteristics of the target disaster (Palen and Anderson, 2016; Imran et al., 2015). Domain adaptation techniques address these challenges by efficiently using large amounts of unlabeled tar- get domain data, consequently outperforming the aforementioned supervised techniques (Alam et al., 2018; Li et al., 2017). Our work contributes to disaster-centric emotion detection in three ways by: (1) introducing a dataset large enough to train su- pervised classifiers; (2) exploring various forms of pre-training to instill strong inductive biases; and (3) establishing domain adaptation baselines by leveraging emotive samples obtainable via distant supervision.</a><br><br><a id="s16" onmouseover="over('s16', 'r16')" onmouseout="out('r16')">3 Dataset Construction</a><br><br><a id="s17" onmouseover="over('s17', 'r17')" onmouseout="out('r17')">In this section, we present HURRICANEEMO, an annotated dataset of 15,000 English tweets from Hurricanes Harvey, Irma, and Maria. We detail each component, including the initial preprocessing (§3.1), annotation procedures (§3.2), and the formu- lation and calculation of inter-annotator agreement (§3.3).</a><br><br><a id="s18" onmouseover="over('s18', 'r18')" onmouseout="out('r18')">3.1 Preprocessing</a><br><br><a id="s19" onmouseover="over('s19', 'r19')" onmouseout="out('r19')">Ray Chowdhury et al. (2019) release a repository of large-scale Twitter datasets consisting of tweets streamed during the Harvey, Irma, and Maria hurri- canes, which we will refer to as HURRICANEEXT (i.e., extended). We use their tweets as a starting point for the construction of our dataset. We per- form two types of preprocessing. First, we replace usernames and links with <USER> and <URL>, re- spectively, then eliminate duplicate tweets. Second, we use filtering techniques to ensure the resulting tweets contain emotive content.</a><br><br><a id="s20" onmouseover="over('s20', 'r20')" onmouseout="out('r20')">We assume a lexical prior over emotion tweets, that is, requiring that an emotive tweet consist of at least one word derived from EMOLEX (Mo- hammad and Turney, 2013). EMOLEX consists of 14,182 crowdsourced words associated with several emotion categories. Critically, these words appear in emotional contexts, but are not necessarily emo- tion words themselves. For example, “payback” is</a><br><br><a id="s21" onmouseover="over('s21', 'r21')" onmouseout="out('r21')"> related to the emotion “anger,” but is also used ex- tensively in finance. Significant past work (Bravo- Marquez et al., 2014; Majumder et al., 2017; Giat- soglou et al., 2017) has used this lexicon to boot- strap their emotion datasets, since the alternatives are (1) using unlabeled tweets as-is or (2) using a model to classify emotional tweets. Initially, we started with (1) and did no emotion-related prepro- cessing. However, the dataset contained many spu- rious tweets, such as snippets of news articles, that had little to do with emotions. The level of noise rendered the data prohibitively costly to annotate. For (2), there is simply no such large-scale data to train on, and existing resources like EMONET manifest an even stronger prior where tweets are only included if they explicitly contain an emotion hashtag (e.g., #sad, #angry, #happy).</a><br><br><a id="s22" onmouseover="over('s22', 'r22')" onmouseout="out('r22')">3.2 Annotation</a><br><br><a id="s23" onmouseover="over('s23', 'r23')" onmouseout="out('r23')">We randomly sample 5,000 tweets each for anno- tation from the filtered datasets for Harvey, Irma, and Maria; in total, this yields 15,000 annotations. We request workers on Amazon Mechanical Turk to label tweets with a list of Plutchik-24 emotions. Furthermore, to enable fine-grained emotion anal- ysis, we do not crowdsource Plutchik-8 emotions directly. We require that workers reside in the US and have completed 500+ HITs with an acceptance rate ≥ 95%. Each HIT is completed by 5 workers.</a><br><br><a id="s24" onmouseover="over('s24', 'r24')" onmouseout="out('r24')">3.3 Inter-Annotator Agreement</a><br><br><a id="s25" onmouseover="over('s25', 'r25')" onmouseout="out('r25')">In this section, we elaborate on our PEA metric for computing inter-annotator agreement with fine- grained emotion labels.</a><br><br><a id="s26" onmouseover="over('s26', 'r26')" onmouseout="out('r26')">Challenges. Fine-grained emotion annotation presents several challenges for evaluating inter- annotator agreement. First, because a tweet can convey multiple emotions, we allow workers to select more than one Plutchik-24 emotion. This implies an agreement metric must support scoring sets of categorical values. Passonneau (2004) use set distance metrics for capturing agreement be- tween coreference cluster annotations. Similarly, Wood et al. (2018) incorporate Jaccard’s similar- ity in Krippendorff’s alpha. However, these meth- ods would penalize fine-grained emotions equally, which is not ideal. For the Plutchik wheel, the prox- imity of any two emotions represents their related- ness. For example, TRUST and   be- long to the same emotion group whileand ADMIRATION are orthogonal to each other.</a><br><br><a id="s27" onmouseover="over('s27', 'r27')" onmouseout="out('r27')">Figure 1: Visualization of the PEA metric. The unit circle is superimposed on the Plutchik wheel, and each Plutchik-8 emotion is assigned a radian value. In this example, the (normalized) distance between the emo- tions corresponding to 3π and π is 0.25.</a><br><br><a id="s28" onmouseover="over('s28', 'r28')" onmouseout="out('r28')">24</a><br><br><a id="s29" onmouseover="over('s29', 'r29')" onmouseout="out('r29')">PEA Scores. We introduce the Plutchik EmotionAgreement—hereafter referred to as PEA—to ad-dress these challenges. We superimpose a unitcircle onto the Plutchik wheel, representing eachPlutchik-8 emotion as a polar coordinate (e.g.,√√DISAPPROVAL = ( 2 , − 2 )). Intuitively, the an-</a><br><br><a id="s30" onmouseover="over('s30', 'r30')" onmouseout="out('r30')"> 22gles between Plutchik-8 emotions represent how similar or dissimilar they are. If two Plutchik-24 an- notations belong to the same Plutchik-8 group, we do not penalize them (e.g., JOY and ECSTASY incur no penalty). Otherwise, we enforce a linear penalty based on how radially separate the anno- tations are (e.g., ECSTASY and GRIEF incur the highest penalty). Higher PEA scores imply more agreement.</a><br><br><a id="s31" onmouseover="over('s31', 'r31')" onmouseout="out('r31')">Example. Figure 1 visualizes our metric. In thisexample, two annotators select emotions with radi-   ans 3π and π , respectively. The |f (e(i) ) − f (e(j ) )| 24xyterm evaluates to 5π . Then, it is normalized us- 154ing π , yielding 4 = 1.25. Finally, we subtract to obtain the agreement score: |1 − 1.25| = 0.25. In- tuitively, this makes sense as the decisions are only slightly better than being in complete disagreement (i.e., orthogonal).</a><br><br><a id="s32" onmouseover="over('s32', 'r32')" onmouseout="out('r32')">Formulation. For clarity, we introduce notation. Let wx and wy denote workers with (categorical)annotation sets {e(i)}n and {e(j)}m , respec- x i=1 y j=1tively. The pairwise agreement d(wx , wy ) between the workers is computed as:</a><br><br><a id="s33" onmouseover="over('s33', 'r33')" onmouseout="out('r33')"> ADMIRATION</a><br><br><a id="s34" onmouseover="over('s34', 'r34')" onmouseout="out('r34')">1􏰂n 1(i)(j) max 􏰀|1 − |f (ex ) − f (ey )||􏰁</a><br><br><a id="s35" onmouseover="over('s35', 'r35')" onmouseout="out('r35')"> LOATHING</a><br><br><a id="s36" onmouseover="over('s36', 'r36')" onmouseout="out('r36')">n i=1 j π  VocabularyFeatures (%)# @ //</a><br><br><a id="s37" onmouseover="over('s37', 'r37')" onmouseout="out('r37')">48.1 27.4 85.3 41.4 22.5 81.7 36.5 30.3 78.3</a><br><br><a id="s38" onmouseover="over('s38', 'r38')" onmouseout="out('r38')">Mexico helped us during Houston, lets return the favor!</a><br><br><a id="s39" onmouseover="over('s39', 'r39')" onmouseout="out('r39')">Hurricane Irma is hitting Florida. Ev- eryone evacuated Here I am, still in Florida bring it on Irma, bring it on.</a><br><br><a id="s40" onmouseover="over('s40', 'r40')" onmouseout="out('r40')">puerto rico should be the ONLY THING in American News. <URL>joy, admiration, pensivenessacceptance, an- ticipation, vigi- lanceanger, annoy- ance, interest  HurricaneHarvey Irma MariaOrig.</a><br><br><a id="s41" onmouseover="over('s41', 'r41')" onmouseout="out('r41')">20.6 K 14.6 K 21.6 K</a><br><br><a id="s42" onmouseover="over('s42', 'r42')" onmouseout="out('r42')">Filt.</a><br><br><a id="s43" onmouseover="over('s43', 'r43')" onmouseout="out('r43')">14.4 K 8.8 K 15.8 K</a><br><br><a id="s44" onmouseover="over('s44', 'r44')" onmouseout="out('r44')">    Table 1: Per-hurricane dataset statistics. In the vocabu- lary section, Orig. shows vocabulary counts (obtained through whitespace tokenization) and Filt. shows counts after <USER> and <URL> preprocessing. In the features section, we show the percentage of tweets with hashtags (#), user mentions (@), and links (//).</a><br><br><a id="s45" onmouseover="over('s45', 'r45')" onmouseout="out('r45')">where π1 is a normalizing constant and f : Ω → R is a map from Plutchik-8 emotions to radians. Given a collection of workers that annotated a tweet, we obtain per-worker PEA scores by averag- ing over all possible pairwise agreements. For ex- ample, if workers w1−3 annotated the same tweet, PEA(w1) = 21 (d(w1, w2) + d(w1, w3)). For qual- ity control, we filter annotations from workers with PEA ≤ 0.55. This threshold is determined through manual inspection of 50 workers and their annota- tions. The (averaged, per-worker) PEA scores for each hurricane are: Harvey (65.7), Maria (67.3), and Irma (70.3).3asked to determine the agreement between two an- notation pairs constructed from three annotators, that is, A: (e1, e2) and B: (e1, e3). They choose between three options: (1) A has higher agree- ment than B; (2) A and B have (roughly) the same agreement; and (3) B has higher agreement than A. 88.2% of the worker rankings match with PEA’s rankings, pointing towards strong human agree- ment. The workers themselves in this study also show good agreement according to Krippendorff’s alpha (α = 74.0) (Artstein and Poesio, 2008).4Table 2: Samples from HURRICANEEMO. Each sam- ple is annotated with multiple Plutchik-24 emotions.</a><br><br><a id="s46" onmouseover="over('s46', 'r46')" onmouseout="out('r46')">vocabularies across all datasets are large consid- ering there are only 5,000 tweets per hurricane. The vocabularies do decrease by about 30% af- ter preprocessing, although the resulting sizes still suggest users use a myriad of words to express their emotions. Second, only about 50% of Har- vey tweets and 40% of Irma/Maria tweets contain hashtags. Hashtags are a unique marker of Twitter discourse (Ritter et al., 2011), but in our dataset specifically, hashtags are used to tag particular en- tities, spread disaster-relief awareness, and create trending content. This phenomena alone makes our tweets different from those collected through dis- tant supervision (Abdul-Mageed and Ungar, 2017). Third, roughly 80-85% of tweets contain links to third-party content. Users commonly use links to share news articles, resources for humanitarian aid, and other miscellaneous multimedia.</a><br><br><a id="s47" onmouseover="over('s47', 'r47')" onmouseout="out('r47')">Table 2 shows three samples from HURRICA- NEEMO. Unlike EMONET (Abdul-Mageed and Ungar, 2017), our dataset does not have the strong assumption that only one emotion can be expressed in a tweet. For example, the first tweet lexically points towards the expression of more than one emotion. The predicate “helped us” implies the user admires Mexico for providing aid, and the exclamation mark is indicative of JOY . In addi- tion, our samples contain a mix of implicit and explicit emotions, which lexical information alone cannot resolve. In the third tweet, there are no particular words that point towards ANGER andANNOYANCE , but we can infer the user is upset that the media is not prioritizing Hurricane Maria. Finally, our emotion prediction tasks cannot besolved by simply retrofitting pre-trained word em- beddings (Mikolov et al., 2013; Pennington et al., 2014) or contextualized representations (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019), which we also empirically show in our experiments (§5). These methods work best for explicit emo- tion detection as they largely overfit to sparse lex- Human Evaluation.</a><br><br><a id="s48" onmouseover="over('s48', 'r48')" onmouseout="out('r48')">We perform a human eval- uation with our proposed metric, which is absent in previous work for measuring inter-annotator agree- ment for emotion annotations (Wood et al., 2018; Öhman et al., 2018). Crowdsourced workers are  4 4.1Qualitative Analysis Dataset OverviewTable 1 presents several statistics of HURRICA- NEEMO. We make three observations. First, the3A reasonable interpretation of PEA scores may be as follows: 0—25 (no agreement), 25—50 (poor agreement), 50—75 (moderate agreement), 75—100 (high agreement).</a><br><br><a id="s49" onmouseover="over('s49', 'r49')" onmouseout="out('r49')">4See Appendix B for details on our procedures.</a><br><br><a id="s50" onmouseover="over('s50', 'r50')" onmouseout="out('r50')">  Plutchik-8 EmotionaggressivenessoptimismlovesubmissionawedisapprovalremorsecontemptPlutchik-24  Abbrv.</a><br><br><a id="s51" onmouseover="over('s51', 'r51')" onmouseout="out('r51')">agrsvoptsmlovesbmsnawedspvlrmrsecntmpEmotionrageanger annoyancevigilance anticipation interestecstasy joy serenityadmiration trust acceptanceterrorfear apprehensionamazement surprise distractiongrief sadness pensivenessloathing disgust boredomAbbrv.</a><br><br><a id="s52" onmouseover="over('s52', 'r52')" onmouseout="out('r52')">rage anger anycevglnc antcp inrstecsty joy srntyadmrn trust acptntrror fear aprhnamzmt srpse dstrngrief sadns psvnelthng dsgst brdom</a><br><br><a id="s53" onmouseover="over('s53', 'r53')" onmouseout="out('r53')">Figure 2: Per-hurricane emotion counts where each box’s Plutchik-8 emotion is broken down into its re- spective Plutchik-24 emotions. Plutchik-24 emotions are abbreviated using the codes in Table 3.</a><br><br><a id="s54" onmouseover="over('s54', 'r54')" onmouseout="out('r54')">pothesize that users use Twitter as a social platform to spread awareness of the hurricanes themselves or post-disaster relief efforts, commonly using hash- tags like #prayfortexas, #floridaevacuation, and #donationdrive. It is encouraging to see that al- though users do express natural emotions such as fear, sadness, and anger, many seek to help others in the face of adversity. Third, sharp changes in emotion counts between Harvey and Irma may be tied to their history. In the 2017 Atlantic hurricane season, Harvey materialized as a Cat-4 hurricane, and Irma followed around two weeks later as a Cat-5 hurricane.5 Through side-by-side compar- isons of both hurricanes’ tweets, we found the Irma tweets had more descriptions of destruction and its aftermath. These changes in discourse potentially explain shifts between the emotion distributions.</a><br><br><a id="s55" onmouseover="over('s55', 'r55')" onmouseout="out('r55')">4.3 Emotion Co-Occurrence</a><br><br><a id="s56" onmouseover="over('s56', 'r56')" onmouseout="out('r56')">Thus far, we have analyzed each Plutchik-24 emo- tion in isolation. In this section, we ask the follow- ing questions: How do Plutchik-8 emotion groups co-occur with one another? Do co-occurrence pat- terns change across hurricanes?Figure 3 shows co-occurrence heatmaps for each hurricane. Intuitively, we see strong corre- lations between polarized emotions, that is, emo-5Abbreviations for Category-x. This refers to the Saffir- Simpson scale for classifying hurricanes based on sustained wind speed, which ranges from 1-5 in order of severity.</a><br><br><a id="s57" onmouseover="over('s57', 'r57')" onmouseout="out('r57')">         Table 3: Plutchik-8 (left) and viations used throughout thisPlutchik-24 (right) abbre- paper.</a><br><br><a id="s58" onmouseover="over('s58', 'r58')" onmouseout="out('r58')">ical features. Rather, in order to capture implicit emotions, models must carry an inductive bias that appropriately reasons over the context (e.g., what event(s) occurred?) and semantic roles (e.g., what happened to whom?) while balancing the afore- mentioned features.</a><br><br><a id="s59" onmouseover="over('s59', 'r59')" onmouseout="out('r59')">4.2 Fine-Grained Emotions</a><br><br><a id="s60" onmouseover="over('s60', 'r60')" onmouseout="out('r60')">We begin to analyze the fine-grained emotions present in our datasets. We ask the following ques- tions: What is the general distribution of emotions? Are certain emotion groups highlighted more than others? How does the distribution change across hurricanes?Figure 2 shows Plutchik-24 emotion distribu- tions for Hurricanes Harvey, Irma, and Maria. From these plots, a couple of trends emerge. First, the Plutchik-24 emotion counts are within the ball- park of each other with the notable exceptions ofADMIRATION and FEAR . This suggests that, on average, hurricane disasters evoke a similar spread of implicit and explicit emotions among most emo- tion categories. Second, users tend to post more op- timistic content during hurricane disasters. We hy-</a><br><br><a id="s61" onmouseover="over('s61', 'r61')" onmouseout="out('r61')">  Plutchik-8 Emotion Train Aggressiveness 4,209</a><br><br><a id="s62" onmouseover="over('s62', 'r62')" onmouseout="out('r62')">Valid Test</a><br><br><a id="s63" onmouseover="over('s63', 'r63')" onmouseout="out('r63')">526 527 1,488 1,488 321 322 762 762 916 916 741 742 967 967 470 471 Optimism Love Submission Awe Disapproval Remorse Contempt</a><br><br><a id="s64" onmouseover="over('s64', 'r64')" onmouseout="out('r64')">11,902 2,569 6,092 7,324 5,931 7,732 3,763</a><br><br><a id="s65" onmouseover="over('s65', 'r65')" onmouseout="out('r65')"> Figure 3: Per-hurricane Plutchik-8 emotion co- occurrences. The matrices are symmetric across the diagonal, so we mask the upper diagonal of the matrix for clarity. Plutchik-8 emotions are abbreviated using the codes in Table 3.</a><br><br><a id="s66" onmouseover="over('s66', 'r66')" onmouseout="out('r66')">tions categorized as positive and negative. ForTable 4: Train, validation, and test splits for each Plutchik-8 emotion.</a><br><br><a id="s67" onmouseover="over('s67', 'r67')" onmouseout="out('r67')">other buckets. From here, we shuffle the positive and negative samples and perform an 80/10/10 split to create the train, validation, and test sets.6 Table 4 enumerates the splits.</a><br><br><a id="s68" onmouseover="over('s68', 'r68')" onmouseout="out('r68')">5.1 Experimental Setup</a><br><br><a id="s69" onmouseover="over('s69', 'r69')" onmouseout="out('r69')">We consider both traditional neural models and pre- trained language models. We implement our mod- els in PyTorch (Paszke et al., 2019) and perform all experiments on an NVIDIA Titan V GPU. Training and optimization hyperparameters are detailed in Appendix C. We report mean performance across 10 runs, each with a different random initialization. Below, we elaborate on our models:</a><br><br><a id="s70" onmouseover="over('s70', 'r70')" onmouseout="out('r70')">Traditional Neural Models. Each is equipped with 200D GloVe embeddings pre-trained on 2B tweets (Pennington et al., 2014): (1) Logistic Re- gression: We average the word embeddings of each token in the sequence (Iyyer et al., 2015); (2) CNN: A word-level CNN (Kim, 2014) with 100 filters of size [3, 4, 5] obtains representations. They are max-pooled and concatenated row-wise. We also experiment with a character-level CNN with filter sizes [5, 6, 7]; (3) GRU: A one-layer, uni- directional GRU (Cho et al., 2014) with a hidden dimension of 100 obtains features, which are mean pooled. For all models, penultimate representations are projected with a weight matrix W ∈ Rd×2.</a><br><br><a id="s71" onmouseover="over('s71', 'r71')" onmouseout="out('r71')">Pre-trained Language Models. We fine-tune base versions of BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019) using the Hugging- Face Transformers library (Wolf et al., 2019). We</a><br><br><a id="s72" onmouseover="over('s72', 'r72')" onmouseout="out('r72')">6We also experimented with keeping all negative samples as opposed to sampling an equal amount. Each binary task had around 5-7x more negative samples; this significantly hurt model performance. Even with a class imbalance penalty, the models almost never predicted positive samples. Note that although, in aggregate, the number of positive and negative samples match, they do not necessarily match in the train, validation, and test splits.</a><br><br><a id="s73" onmouseover="over('s73', 'r73')" onmouseout="out('r73')">  example, ( LOVE ,appear as frequently as (( CONTEMPT ,   ).</a><br><br><a id="s74" onmouseover="over('s74', 'r74')" onmouseout="out('r74')">this premise does not always hold; the pairs ({ DISAPPROVAL , REMORSE }, OPTIMISM ) also co-occur across all hurricanes. Representa- tive of this phenomenon is the tweet: “I’m rais- ing money for Hurricane Maria Destroyed Every- thing. Click to Donate: <URL> via <USER>.” The user indicates disapproval towards the hurricane by evoking pathos, but also shows optimism by do- nating money to a relief effort. Finally, similar to our previous observations (§4.2), we notice an in- crease in co-occurrence frequencies from Harvey → Irma. This increase is, somewhat surprisingly, most apparent with ( AWE , ), although ({ DISAPPROVAL , }, AWE ) frequen- cies also exhibit a noticeable gain. Once again, we posit that users may be expressing their sadness regarding the Cat-4 → Cat-5 jump, but at the same time, offering solidarity to those affected by the hurricanes.</a><br><br><a id="s75" onmouseover="over('s75', 'r75')" onmouseout="out('r75')">5 Baseline ModelingWe now turn to modeling the emotions in HURRI- CANEEMO. Because Plutchik-24 emotion counts are heavily imbalanced, we group them into Plutchik-8 emotions and consequently create 8 bi- nary classification tasks.</a><br><br><a id="s76" onmouseover="over('s76', 'r76')" onmouseout="out('r76')">The tweets are assorted into their respective label buckets; because tweets may be labeled with more than one emotion, each belongs to one or more buckets. These buckets represent positive samples (i.e., tweets labeled with that emotion). To create negative samples, we sample an equal amount from</a><br><br><a id="s77" onmouseover="over('s77', 'r77')" onmouseout="out('r77')">AGGRESSIVENESS</a><br><br><a id="s78" onmouseover="over('s78', 'r78')" onmouseout="out('r78')">) does not ) or However,</a><br><br><a id="s79" onmouseover="over('s79', 'r79')" onmouseout="out('r79')">  LOVE</a><br><br><a id="s80" onmouseover="over('s80', 'r80')" onmouseout="out('r80')">,</a><br><br><a id="s81" onmouseover="over('s81', 'r81')" onmouseout="out('r81')">OPTIMISM</a><br><br><a id="s82" onmouseover="over('s82', 'r82')" onmouseout="out('r82')"> AGGRESSIVENESS</a><br><br><a id="s83" onmouseover="over('s83', 'r83')" onmouseout="out('r83')">    OPTIMISM</a><br><br><a id="s84" onmouseover="over('s84', 'r84')" onmouseout="out('r84')">  REMORSE</a><br><br><a id="s85" onmouseover="over('s85', 'r85')" onmouseout="out('r85')"> AGR OPT LOV SBM AWE DSP RMR CNT AVG</a><br><br><a id="s86" onmouseover="over('s86', 'r86')" onmouseout="out('r86')"> Logistic Reg. Char CNN Word CNN GRU BERT RoBERTa</a><br><br><a id="s87" onmouseover="over('s87', 'r87')" onmouseout="out('r87')">49.8 74.7 50.9 50.6 50.2 74.3 43.0 47.2 43.6 74.5 44.7 45.4 48.4 74.7 54.0 50.9 67.6 75.0 54.0 67.4 59.7 74.7 54.0 62.3</a><br><br><a id="s88" onmouseover="over('s88', 'r88')" onmouseout="out('r88')">48.9 49.7 48.3 44.7 47.1 47.4 44.2 47.0 46.9 50.1 49.9 48.9 68.3 55.7 58.5 56.0 50.9 49.7</a><br><br><a id="s89" onmouseover="over('s89', 'r89')" onmouseout="out('r89')">46.8 52.5 48.8 50.3 43.9 48.8 49.2 53.3 66.8 64.1 56.4 58.0</a><br><br><a id="s90" onmouseover="over('s90', 'r90')" onmouseout="out('r90')"> Table 5: Plutchik-8 binary task accuracies, including aggressiveness (agr), optimism (opt), love (lov), submission (sbm), awe (awe), disapproval (dsp), remorse (rmr), contempt (cnt). We also report an average (avg) across all binary tasks. Best results are bolded.</a><br><br><a id="s91" onmouseover="over('s91', 'r91')" onmouseout="out('r91')">use the sentence representations embedded in the [CLS] token, then project it with a weight matrix W ∈ Rd×2. The language model and classification parameters are jointly fine-tuned.</a><br><br><a id="s92" onmouseover="over('s92', 'r92')" onmouseout="out('r92')">5.2 Results</a><br><br><a id="s93" onmouseover="over('s93', 'r93')" onmouseout="out('r93')">Table 5 presents our classification results. We make the following observations:</a><br><br><a id="s94" onmouseover="over('s94', 'r94')" onmouseout="out('r94')">BERT consistently outperforms other models on most emotion tasks. BERT shows strong per- formance across all 8 binary tasks in comparison to traditional neural models and RoBERTa. Unlike most traditional neural models, its accuracy never falls below random chance, showing it captures at least some of the complex phenomena present in our dataset. However, our tasks remain challeng- ing for both types of models alike. For traditional models, word embeddings alone do not provide enough representational power to model our emo- tional contexts. Although GRUs perform well on EMONET (Abdul-Mageed and Ungar, 2017), we suspect that they simply memorize emotion lex- icons (§4.1), which is not a notable strategy for capturing implicit emotions. Nevertheless, BERT only obtains an average accuracy of about 64%. This leaves plenty of room for future work; we perform a comprehensive error analysis as a step towards this goal (§5.3).</a><br><br><a id="s95" onmouseover="over('s95', 'r95')" onmouseout="out('r95')">“Better” pre-trained models (e.g., RoBERTa) do not necessarily help performance. Unlike popular benchmarks such as GLUE (Wang et al., 2018) where more pre-training monotonically in- creases performance, rather encouragingly, we do not observe the same trend. RoBERTa’s average performance is around 5% better than GRU’s, but still around 6% worse than BERT’s. We hypothe- size that this drop in performance is attributed to pre-training → fine-tuning domain discrepancies. That is, RoBERTa’s (additional) pre-training data (e.g., CC-News) may be too distant from Twitterdata, which is known for its short contexts and unique vernacular (Ritter et al., 2011). We encour- age practitioners to avoid applying state-of-the-art models without augmenting them with task-guided pre-training objectives, as we explore later (§6).</a><br><br><a id="s96" onmouseover="over('s96', 'r96')" onmouseout="out('r96')">5.3 Error Analysis</a><br><br><a id="s97" onmouseover="over('s97', 'r97')" onmouseout="out('r97')">Using our BERT model, we sample 25 test errors from each of the 8 emotion tasks, yielding a total of 200 errors. We group the errors into the follow- ing categories: lexical and syntactic cues (45%), insufficient context (24%), entity mentions (15%), subjective labeling (10%), and unknown reasons (6%). The top three categories are discussed below:Lexical and Syntactic Cues. BERT often relies on surface-level lexical features to make predic- tions, as do most emotion prediction models. This bias also extends to certain syntactic features, such as punctuation. In “pls be safe everyone!!!!”, BERT associates the exclamation mark with a pos- itive emotion, but here, the speaker is more con- cerned.</a><br><br><a id="s98" onmouseover="over('s98', 'r98')" onmouseout="out('r98')">Insufficient Context. Users often comment on events, public policies, or linked content that, by themselves, do not carry features for super- vised learning. This type of error is not nec- essarily a shortcoming of BERT, but rather our dataset. For example, in “for [tracy mcgrady]1, [hall induction]2 muted by effects of [hurricane harvey]3 at home”, one use external knowledge to reason between the noun phrases and discern the latent emotions.</a><br><br><a id="s99" onmouseover="over('s99', 'r99')" onmouseout="out('r99')">Entity Mentions. BERT also makes erroneous predictions in the presence of certain entity men- tions. For example, BERT classifies this tweet as AGGRESSIVENESS : “nytimesworld: mexico offered aid to texas after harvey. but after an earth- quake and hurricane, it says all help is needed at home.” Here, the user is merely quoting a</a><br><br><a id="s100" onmouseover="over('s100', 'r100')" onmouseout="out('r100')"> AGR OPT LOV SBM AWE DSP</a><br><br><a id="s101" onmouseover="over('s101', 'r101')" onmouseout="out('r101')">RMR CNT AVG</a><br><br><a id="s102" onmouseover="over('s102', 'r102')" onmouseout="out('r102')"> NO-PRETRAIN 67.6Supervised TransferEMONET 73.5 SENTIMENT 72.8Unsupervised TransferEMONET 72.1 SENTIMENT 69.1 HURRICANEEXT 73.6</a><br><br><a id="s103" onmouseover="over('s103', 'r103')" onmouseout="out('r103')">75.0 54.0 67.4</a><br><br><a id="s104" onmouseover="over('s104', 'r104')" onmouseout="out('r104')">75.2 55.2 68.8 75.8 62.7 71.0</a><br><br><a id="s105" onmouseover="over('s105', 'r105')" onmouseout="out('r105')">75.1 54.0 61.0 74.9 53.6 66.2 75.4 69.8 68.9</a><br><br><a id="s106" onmouseover="over('s106', 'r106')" onmouseout="out('r106')">68.3 55.7</a><br><br><a id="s107" onmouseover="over('s107', 'r107')" onmouseout="out('r107')">67.5 53.1 65.6 53.4</a><br><br><a id="s108" onmouseover="over('s108', 'r108')" onmouseout="out('r108')">65.1 54.2 67.3 54.3 69.7 57.9</a><br><br><a id="s109" onmouseover="over('s109', 'r109')" onmouseout="out('r109')">58.5</a><br><br><a id="s110" onmouseover="over('s110', 'r110')" onmouseout="out('r110')">66.8 64.1</a><br><br><a id="s111" onmouseover="over('s111', 'r111')" onmouseout="out('r111')">71.7 65.6 67.3 65.7</a><br><br><a id="s112" onmouseover="over('s112', 'r112')" onmouseout="out('r112')">69.4 63.9 64.4 63.5 70.2 68.2</a><br><br><a id="s113" onmouseover="over('s113', 'r113')" onmouseout="out('r113')">   60.0 57.0   60.7 57.9 60.2</a><br><br><a id="s114" onmouseover="over('s114', 'r114')" onmouseout="out('r114')"> Table 6: Task-guided pre-training accuracies (abbreviations defined in Table 5). Displayed in order of supervised (middle) and unsupervised (bottom) pre-training. Results are highlighted with blue (↑) and red (↓) with respect to NO-PRETRAIN. Best viewed in color.</a><br><br><a id="s115" onmouseover="over('s115', 'r115')" onmouseout="out('r115')">news statement as opposed to formulating opin- ions regarding NY Times’ discourse. Because the sentiment towards NY Times is negative in our datasets overall (due to public backlash on its stories), BERT likely capitalizes on this mention- emotion bias.</a><br><br><a id="s116" onmouseover="over('s116', 'r116')" onmouseout="out('r116')">6 Task-Guided Pre-training</a><br><br><a id="s117" onmouseover="over('s117', 'r117')" onmouseout="out('r117')">To improve upon our baselines, we explore pre- training as a means of implicitly incorporating an in- ductive bias into our BERT model. Our hope is that these pre-training tasks will not only make BERT more robust in the Twitter domain, but also provide useful (albeit abstract) knowledge for the end emo- tion prediction tasks. For brevity, we chiefly focus on BERT, although our methods can be generalized to other pre-trained models.</a><br><br><a id="s118" onmouseover="over('s118', 'r118')" onmouseout="out('r118')">Setup. We explore, in isolation, supervised and unsupervised pre-training tasks. For the supervised setting, we pre-train on a multi-class emotion task (EMONET) (Abdul-Mageed and Ungar, 2017) and binary sentiment analysis task (SENTIMENT) (Go et al., 2009). For the unsupervised setting, we pre- train on dynamic masked language modeling (Liu et al., 2019) on (unlabeled) samples from EMONET, SENTIMENT, and HURRICANEEXT (§3.1). For both types of tasks, we further pre-train BERT for a fixed number of epochs, then fine-tune it on a HURRICANEEMO task. We compare these results to NO-PRETRAIN, namely the BERT results ver- batim from Table 5. We report mean performance across 10 pre-training → fine-tuning runs. Further training details, including samples sizes for the pre-training tasks, are available in Appendix D.</a><br><br><a id="s119" onmouseover="over('s119', 'r119')" onmouseout="out('r119')">Results. Table 6 shows the pre-training results. Supervised pre-training significantly helps with 3-</a><br><br><a id="s120" onmouseover="over('s120', 'r120')" onmouseout="out('r120')">4 emotions, but degrades overall performance on 2-4 emotions. We posit SENTIMENT aids emotions with highly predictive features. For example, “wtf” in “it’s literally the size of texas. wtf” is correlated with AGGRESSIVENESS , but no such lexical cues exist in “not all heros wear capes <3 thank you stanley - homeless #hurricane evacuee grooms lost pets,” which is an AWE sample.</a><br><br><a id="s121" onmouseover="over('s121', 'r121')" onmouseout="out('r121')">The unsupervised pre-training results also show a couple trends. First, EMONET largely hurts downstream performance, especially reducing</a><br><br><a id="s122" onmouseover="over('s122', 'r122')" onmouseout="out('r122')">SUBMISSION accuracy by -6%. Second, SENTI- MENT (in its unlabeled form) yields no noticeable benefits. This implies sentiment information is much more valuable, but of course, subject to the fact that the emotion task is heavily aligned with the original sentiment task. Third, we obtain encourag- ing results with HURRICANEEXT pre-training. The gains are most noticeable on AGGRESSIVENESS and LOVE , but this objective adds +1-2% accuracy for tasks on which supervised pre-training suffered.</a><br><br><a id="s123" onmouseover="over('s123', 'r123')" onmouseout="out('r123')">7 Fine-Grained Unsupervised Domain Adaptation</a><br><br><a id="s124" onmouseover="over('s124', 'r124')" onmouseout="out('r124')">When new disasters emerge, it is likely we may not have emotion annotations, as alluded to previously (§2). Nevertheless, these annotations would be valuable for organizations trying to understand the emotional profile of users during a crisis (Fraustino et al., 2012). In this section, we explore ways to leverage supervision from large-scale emotion datasets (e.g., EMONET (Abdul-Mageed and Un- gar, 2017)) in providing labels for our hurricane emotion datasets. We frame this problem as un- supervised domain adaptation; EMONET is the la- beled source domain and our hurricane datasets are the unlabeled target domain. Below, we elaborate</a><br><br><a id="s125" onmouseover="over('s125', 'r125')" onmouseout="out('r125')"> AGR OPT LOV SBM AWE DSP</a><br><br><a id="s126" onmouseover="over('s126', 'r126')" onmouseout="out('r126')">RMR CNT AVG</a><br><br><a id="s127" onmouseover="over('s127', 'r127')" onmouseout="out('r127')"> SRC-ONLYPRETRAIN-SRCPRETRAIN-TRG PRETRAIN-JOINTTRG-ONLY</a><br><br><a id="s128" onmouseover="over('s128', 'r128')" onmouseout="out('r128')">53.3 42.2</a><br><br><a id="s129" onmouseover="over('s129', 'r129')" onmouseout="out('r129')">54.8 43.2 55.0 44.2 52.7 44.2</a><br><br><a id="s130" onmouseover="over('s130', 'r130')" onmouseout="out('r130')">67.6 75.0</a><br><br><a id="s131" onmouseover="over('s131', 'r131')" onmouseout="out('r131')">43.4 47.1</a><br><br><a id="s132" onmouseover="over('s132', 'r132')" onmouseout="out('r132')">45.1 47.8 46.2 48.0 45.5 47.8</a><br><br><a id="s133" onmouseover="over('s133', 'r133')" onmouseout="out('r133')">54.0 67.4</a><br><br><a id="s134" onmouseover="over('s134', 'r134')" onmouseout="out('r134')">54.7 49.8</a><br><br><a id="s135" onmouseover="over('s135', 'r135')" onmouseout="out('r135')">54.4 50.4 55.5 49.9 54.8 49.9</a><br><br><a id="s136" onmouseover="over('s136', 'r136')" onmouseout="out('r136')">68.3 55.7</a><br><br><a id="s137" onmouseover="over('s137', 'r137')" onmouseout="out('r137')">62.558.5</a><br><br><a id="s138" onmouseover="over('s138', 'r138')" onmouseout="out('r138')">56.5 51.2</a><br><br><a id="s139" onmouseover="over('s139', 'r139')" onmouseout="out('r139')">57.1 52.0 60.5 52.9 56.3 51.6</a><br><br><a id="s140" onmouseover="over('s140', 'r140')" onmouseout="out('r140')">66.8 64.1</a><br><br><a id="s141" onmouseover="over('s141', 'r141')" onmouseout="out('r141')">  63.3 63.7 61.6</a><br><br><a id="s142" onmouseover="over('s142', 'r142')" onmouseout="out('r142')">  Table 7: Unsupervised domain adaptation accuracies (abbreviations defined in Table 5). Results are highlighted with blue (↑) and red (↓) with respect to SRC-ONLY. Best viewed in color.</a><br><br><a id="s143" onmouseover="over('s143', 'r143')" onmouseout="out('r143')">on our methods.</a><br><br><a id="s144" onmouseover="over('s144', 'r144')" onmouseout="out('r144')">Framework. EMONET was conceived as a multi- class classification task for Plutchik-8 emotions (Abdul-Mageed and Ungar, 2017). In contrast, we introduce binary classification tasks, one for each Plutchik-8 emotion. We split the EMONET multi- class task into 8 binary tasks; this creates a one- to-one alignment between each source and target domain task. We separately perform unsupervised domain adaptation for each binary task.</a><br><br><a id="s145" onmouseover="over('s145', 'r145')" onmouseout="out('r145')">Methods. We use our BERT model (without task- guided pre-training) as the underlying classifier. Following Han and Eisenstein (2019), we chiefly focus on using strategic pre-training techniques that enable effective transfer between disparate do- mains. The systems for comparison are: (1) SRC- ONLY: BERT is trained in the source domain and evaluated in the target domain; (2) TRG-ONLY: BERT is trained and evaluated in the target do- main. These results are borrowed verbatim from Table 5; (3) PRETRAIN-*: BERT undergoes dy- namic masked language modeling pre-training us- ing data from domain *, is trained in the source domain, and finally evaluated in the target domain (Han and Eisenstein, 2019). PRETRAIN-SRC only uses pre-training samples from the source domain, PRETRAIN-TRG only uses samples from the tar- get domain, and PRETRAIN-JOINT uses samples from both the source and target domains.7 We re- port mean performance across 10 pre-training → fine-tuning runs.</a><br><br><a id="s146" onmouseover="over('s146', 'r146')" onmouseout="out('r146')">Results. Table 7 shows the unsupervised domain adaptation results. Overall, we do not find a sig- nificant increase in performance over the SRC- ONLY baseline. Pre-training consistently adds +1% in average accuracy, but still leaves a large gap between PRETRAIN-SRC and TRG-ONLY. Re-7PRETRAIN-JOINT is conceptually similar to ADAPT- ABERT in Han and Eisenstein (2019), however, we dynami- cally generate pre-training data (Liu et al., 2019).</a><br><br><a id="s147" onmouseover="over('s147', 'r147')" onmouseout="out('r147')">gardless, we have a few observations. First, we do not see a (relatively) large increase in perfor- mance for , AWE , DISAPPROVAL , and   . These emotions may need more explicit strategies to enable domain adaptation. This is also supported by our previous results (§6), where we also do not see a (relatively) large benefit from task-guided pre-training. Second, PRETRAIN- JOINT performs worse than both PRETRAIN-SRC and PRETRAIN-TRG. We posit that, for our emo- tion tasks, pre-training with a mixture of domains yields a noisier training signal compared to a pa- rameter bias towards the target domain.</a><br><br><a id="s148" onmouseover="over('s148', 'r148')" onmouseout="out('r148')">8 Conclusion</a><br><br><a id="s149" onmouseover="over('s149', 'r149')" onmouseout="out('r149')">We present HURRICANEEMO, an annotated dataset of perceived emotions spanning 15,000 tweets from multiple hurricanes. Tweets are annotated with fine- grained Plutchik-24 emotions, from which we an- alyze implicit and explicit emotions and construct Plutchik-8 binary classification tasks. Comprehen- sive experiments demonstrate our dataset is a chal- lenging benchmark, even for large-scale pre-trained language models. We release our code and datasets as a step towards facilitating research in disaster- centric domains.</a><br><br><a id="s150" onmouseover="over('s150', 'r150')" onmouseout="out('r150')">Acknowledgements</a><br><br><a id="s151" onmouseover="over('s151', 'r151')" onmouseout="out('r151')">Thanks to Katrin Erk for reviewing an early ver- sion of this manuscript, Yasumasa Onoe for dis- cussions on masked language model pre-training, and the anonymous reviewers for their helpful com- ments. This work was partially supported by the NSF Grants IIS-1850153, IIS-1912887, and IIS- 1903963.</a><br><br><a id="s152" onmouseover="over('s152', 'r152')" onmouseout="out('r152')">References</a><br><br><a id="s153" onmouseover="over('s153', 'r153')" onmouseout="out('r153')">Muhammad Abdul-Mageed and Lyle Ungar. 2017. EmoNet: Fine-Grained Emotion Detection with Gated Recurrent Neural Networks. In Proceedings</a><br><br><a id="s154" onmouseover="over('s154', 'r154')" onmouseout="out('r154')">  SUBMISSION</a><br><br><a id="s155" onmouseover="over('s155', 'r155')" onmouseout="out('r155')">REMORSE</a><br><br><a id="s156" onmouseover="over('s156', 'r156')" onmouseout="out('r156')">of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 718–728, Vancouver, Canada. Association for Computational Linguistics.</a><br><br><a id="s157" onmouseover="over('s157', 'r157')" onmouseout="out('r157')">Firoj Alam, Shafiq Joty, and Muhammad Imran. 2018. Domain Adaptation with Adversarial Training and Graph Embeddings. In Proceedings of the 56th An- nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1077– 1087, Melbourne, Australia. Association for Compu- tational Linguistics.</a><br><br><a id="s158" onmouseover="over('s158', 'r158')" onmouseout="out('r158')">Saima Aman and Stan Szpakowicz. 2007. Identifying Expressions of Emotion in Text". In Text, Speech and Dialogue, pages 196–205, Berlin, Heidelberg. Springer Berlin Heidelberg.</a><br><br><a id="s159" onmouseover="over('s159', 'r159')" onmouseout="out('r159')">Ron Artstein and Massimo Poesio. 2008. Inter-coder Agreement for Computational Linguistics. Compu- tational Linguistics, 34(4):555–596.</a><br><br><a id="s160" onmouseover="over('s160', 'r160')" onmouseout="out('r160')">Jonathan Belles. 2017. 2017 Atlantic Hurricane Season Recap: 17 Moments We’ll Never Forget. Weather.com.</a><br><br><a id="s161" onmouseover="over('s161', 'r161')" onmouseout="out('r161')">Felipe Bravo-Marquez, Marcelo Mendoza, and Bar- bara Poblete. 2014. Meta-level Sentiment Models for Big Social Data Analysis. Knowledge-Based Systems, 69:86–99.</a><br><br><a id="s162" onmouseover="over('s162', 'r162')" onmouseout="out('r162')">Cornelia Caragea, Adrian Silvescu, and Andrea H. Tapia. 2016. Identifying informative messages in disaster events using convolutional neural networks. In Proceedings of the 13th International Conference on Information Systems for Crisis Response and Management (ISCRAM).</a><br><br><a id="s163" onmouseover="over('s163', 'r163')" onmouseout="out('r163')">Kyunghyun Cho, Bart van Merriënboer, Caglar Gul- cehre, Dzmitry Bahdanau, Fethi Bougares, Hol- ger Schwenk, and Yoshua Bengio. 2014. Learn- ing Phrase Representations using RNN Encoder– Decoder for Statistical Machine Translation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1724–1734, Doha, Qatar. Association for Computational Linguistics.</a><br><br><a id="s164" onmouseover="over('s164', 'r164')" onmouseout="out('r164')">Michael Robert Dennis, Adrianne Kunkel, Gillian Woods, and Paul Schrodt. 2006. Making Sense of New Orleans Flood Trauma Recovery: Ethics, Re- search Design, and Policy Considerations for Future Disasters. Analyses of Social Issues and Public Pol- icy, 6(1):191–213.</a><br><br><a id="s165" onmouseover="over('s165', 'r165')" onmouseout="out('r165')">Shrey Desai, Hongyuan Zhan, and Ahmed Aly. 2019. Evaluating Lottery Tickets under Distributional Shifts. In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153–162, Hong Kong, China. Association for Computational Linguistics.</a><br><br><a id="s166" onmouseover="over('s166', 'r166')" onmouseout="out('r166')">Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Un- derstanding. In Proceedings of the 2019 Conferenceof the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.</a><br><br><a id="s167" onmouseover="over('s167', 'r167')" onmouseout="out('r167')">Paul Ekman. 1992. An Argument for Basic Emotions. Cognition and Emotion, 6(3-4):169–200.</a><br><br><a id="s168" onmouseover="over('s168', 'r168')" onmouseout="out('r168')">Julia Daisy Fraustino, Brooke Fisher Liu, and Yan Xian Jin. 2012. Social Media Use During Disasters: A Review of the Knowledge Base and Gaps. Na- tional Consortium for the Study of Terrorism and Re- sponses to Terrorism.</a><br><br><a id="s169" onmouseover="over('s169', 'r169')" onmouseout="out('r169')">Charles Fritz and Eli Marks. 1954. The NORC Studies of Human Behavior in Disaster. Journal of Social Issues, 10(3):26–41.</a><br><br><a id="s170" onmouseover="over('s170', 'r170')" onmouseout="out('r170')">Jessica Fritze, Grant Blashki, Susie Burke, and John Wiseman. 2008. Hope, Despair and Transforma- tion: Climate Change and the Promotion of Men- tal Health and Wellbeing. International Journal of Mental Health Systems, 2(1):13.</a><br><br><a id="s171" onmouseover="over('s171', 'r171')" onmouseout="out('r171')">Maria Giatsoglou, Manolis Vozalis, Konstantinos Dia- mantaras, Athena Vakali, George Sarigiannidis, and Konstantinos Chatzisavvas. 2017. Sentiment Anal- ysis Leveraging Emotions and Word Embeddings. Expert Systems with Applications, 69:214–224.</a><br><br><a id="s172" onmouseover="over('s172', 'r172')" onmouseout="out('r172')">Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter Sentiment Classification using Distant Supervision. Stanford University CS224N Project Report.</a><br><br><a id="s173" onmouseover="over('s173', 'r173')" onmouseout="out('r173')">Xiaochuang Han and Jacob Eisenstein. 2019. Unsu- pervised Domain Adaptation of Contextualized Em- beddings for Sequence Labeling. In Proceedings of the 2019 Conference on Empirical Methods in Nat- ural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4237–4247, Hong Kong, China. Association for Computational Linguistics.</a><br><br><a id="s174" onmouseover="over('s174', 'r174')" onmouseout="out('r174')">Muhammad Imran, Carlos Castillo, Fernando Diaz, and Sarah Vieweg. 2015. Processing Social Media Messages in Mass Emergency: A Survey. Associ- ation for Computing Machinery (ACM) Computing Surveys, 47(4):67:1–67:38.</a><br><br><a id="s175" onmouseover="over('s175', 'r175')" onmouseout="out('r175')">Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, and Patrick Meier. 2013. Practi- cal Extraction of Disaster-relevant Information from Social Media. In Proceedings of the 22Nd Inter- national Conference on World Wide Web, WWW 2013 Companion, pages 1021–1024, New York, NY, USA. Association for Computing Machinery (ACM).</a><br><br><a id="s176" onmouseover="over('s176', 'r176')" onmouseout="out('r176')">Muhammad Imran, Prasenjit Mitra, and Jaideep Srivas- tava. 2016. Cross-Language Domain Adaptation for Classifying Crisis-Related Short Messages. In 13th Proceedings of the International Conference on In- formation Systems for Crisis Response and Manage- ment, Rio de Janeiro, Brasil, May 22-25, 2016.</a><br><br><a id="s177" onmouseover="over('s177', 'r177')" onmouseout="out('r177')">Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber, and Hal Daumé III. 2015. Deep Unordered Com- position Rivals Syntactic Methods for Text Classi- fication. In Proceedings of the 53rd Annual Meet- ing of the Association for Computational Linguistics and the 7th International Joint Conference on Natu- ral Language Processing (Volume 1: Long Papers), pages 1681–1691, Beijing, China. Association for Computational Linguistics.</a><br><br><a id="s178" onmouseover="over('s178', 'r178')" onmouseout="out('r178')">Phil Katz, Matthew Singleton, and Richard Wicen- towski. 2007. SWAT-MP: The SemEval-2007 Sys- tems for Task 5 and Task 14. In 4th International Workshop on Semantic Evaluations, pages 308–313.</a><br><br><a id="s179" onmouseover="over('s179', 'r179')" onmouseout="out('r179')">Hamed Khanpour and Cornelia Caragea. 2018. Fine- grained emotion detection in health-related online posts. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1160–1166, Brussels, Belgium. Association for Computational Linguistics.</a><br><br><a id="s180" onmouseover="over('s180', 'r180')" onmouseout="out('r180')">Yoon Kim. 2014. Convolutional Neural Networks for Sentence Classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746–1751, Doha, Qatar. Association for Computational Lin- guistics.</a><br><br><a id="s181" onmouseover="over('s181', 'r181')" onmouseout="out('r181')">Warren Kinston and Rachel Rosser. 1974. Disaster: Ef- fects on Mental and Physical State. Journal of Psy- chosomatic Research, 18(6):437–456.</a><br><br><a id="s182" onmouseover="over('s182', 'r182')" onmouseout="out('r182')">Hongmin Li, Doina Caragea, and Cornelia Caragea. 2017. Towards Practical Usage of a Domain Adap- tation Algorithm in the Early Hours of a Disaster. In Proceedings of the 14th International Conference on Information Systems for Crisis Response and Man- agement (ISCRAM).</a><br><br><a id="s183" onmouseover="over('s183', 'r183')" onmouseout="out('r183')">Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretrain- ing Approach. arXiv preprint arXiv:1907.11692.</a><br><br><a id="s184" onmouseover="over('s184', 'r184')" onmouseout="out('r184')">Navonil Majumder, Soujanya Poria, Alexander Gel- bukh, and Erik Cambria. 2017. Deep Learning- Based Document Modeling for Personality Detec- tion from Text. IEEE Intelligent Systems, 32(2):74– 79.</a><br><br><a id="s185" onmouseover="over('s185', 'r185')" onmouseout="out('r185')">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor- rado, and Jeffrey Dean. 2013. Distributed Repre- sentations of Words and Phrases and Their Com- positionality. In Proceedings of the 26th Interna- tional Conference on Neural Information Processing Systems - Volume 2, NIPS 2013, pages 3111–3119, USA. Curran Associates Inc.</a><br><br><a id="s186" onmouseover="over('s186', 'r186')" onmouseout="out('r186')">Saif Mohammad. 2012. #Emotional Tweets. In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Vol- ume 2: Proceedings of the Sixth International Work- shop on Semantic Evaluation (SemEval 2012), pages246–255, Montréal, Canada. Association for Com- putational Linguistics.</a><br><br><a id="s187" onmouseover="over('s187', 'r187')" onmouseout="out('r187')">Saif Mohammad and Svetlana Kiritchenko. 2015. Using Hashtags to Capture Fine Emotion Cate- gories from Tweets. Computational Intelligence, 31(2):301–326.</a><br><br><a id="s188" onmouseover="over('s188', 'r188')" onmouseout="out('r188')">Saif Mohammad and Peter Turney. 2013. Crowdsourc- ing a Word-Emotion Association Lexicon. Compu- tational Intelligence, 29(3):436–465.</a><br><br><a id="s189" onmouseover="over('s189', 'r189')" onmouseout="out('r189')">Dat Nguyen, Kamela Ali Al Mannai, Shafiq Joty, Has- san Sajjad, Muhammad Imran, and Prasenjit Mi- tra. 2017. Robust Classification of Crisis-Related Data on Social Networks Using Convolutional Neu- ral Networks. In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM 2017).</a><br><br><a id="s190" onmouseover="over('s190', 'r190')" onmouseout="out('r190')">Emily Öhman, Kaisla Kajava, Jörg Tiedemann, and Timo Honkela. 2018. Creating a Dataset for Multilingual Fine-grained Emotion-detection Using Gamification-based Annotation. In Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24–30, Brussels, Belgium. Association for Computational Linguistics.</a><br><br><a id="s191" onmouseover="over('s191', 'r191')" onmouseout="out('r191')">Leysia Palen and Kenneth Anderson. 2016. Crisis In- formatics—New Data for Extraordinary Times. Sci- ence, 353(6296):224–225.</a><br><br><a id="s192" onmouseover="over('s192', 'r192')" onmouseout="out('r192')">Rebecca Passonneau. 2004. Computing Reliability for Coreference Annotation. In Proceedings of the Fourth International Conference on Language Re- sources and Evaluation (LREC 2004), Lisbon, Por- tugal. European Language Resources Association (ELRA).</a><br><br><a id="s193" onmouseover="over('s193', 'r193')" onmouseout="out('r193')">Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Te- jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learn- ing Library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Álché-Buc, E. Fox, and R. Gar- nett, editors, Advances in Neural Information Pro- cessing Systems 32, pages 8024–8035. Curran Asso- ciates, Inc.</a><br><br><a id="s194" onmouseover="over('s194', 'r194')" onmouseout="out('r194')">Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. GloVe: Global Vectors for Word Representation. In Proceedings of the 2014 Con- ference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, Doha, Qatar. Association for Computational Linguistics.</a><br><br><a id="s195" onmouseover="over('s195', 'r195')" onmouseout="out('r195')">Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke</a><br><br><a id="s196" onmouseover="over('s196', 'r196')" onmouseout="out('r196')">Zettlemoyer. 2018. Deep Contextualized Word Rep- resentations. In Proceedings of the 2018 Confer- ence of the North American Chapter of the Associ- ation for Computational Linguistics: Human Lan- guage Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, Louisiana. Association for Computational Linguistics.</a><br><br><a id="s197" onmouseover="over('s197', 'r197')" onmouseout="out('r197')">Robert Plutchik. 2001. The Nature of Emotions: Hu- man emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice. American Scientist, 89(4):344– 350.</a><br><br><a id="s198" onmouseover="over('s198', 'r198')" onmouseout="out('r198')">Jishnu Ray Chowdhury, Cornelia Caragea, and Doina Caragea. 2019. Keyphrase Extraction from Disaster- related Tweets. In The World Wide Web Confer- ence, WWW 2019, pages 1555–1566, New York, NY, USA. Association for Computing Machinery (ACM).</a><br><br><a id="s199" onmouseover="over('s199', 'r199')" onmouseout="out('r199')">Hannah Ritchie and Max Roser. 2020. Natural Disas- ters. Our World in Data.</a><br><br><a id="s200" onmouseover="over('s200', 'r200')" onmouseout="out('r200')">Alan Ritter, Sam Clark, Mausam, and Oren Etzioni. 2011. Named Entity Recognition in Tweets: An Ex- perimental Study. In Proceedings of the 2011 Con- ference on Empirical Methods in Natural Language Processing, pages 1524–1534, Edinburgh, Scotland, UK. Association for Computational Linguistics.</a><br><br><a id="s201" onmouseover="over('s201', 'r201')" onmouseout="out('r201')">Axel Schulz, Tung Dang Thanh, Heiko Paulheim, and Immanuel Schweizer. 2013. A Fine-Grained Sen- timent Analysis Approach for Detecting Crisis Re- lated Microposts. In Information Systems for Crisis Response and Management (ISCRAM).</a><br><br><a id="s202" onmouseover="over('s202', 'r202')" onmouseout="out('r202')">Carlo Strapparava and Rada Mihalcea. 2007. SemEval- 2007 Task 14: Affective Text. In Proceedings of the Fourth International Workshop on Semantic Evalua- tions (SemEval-2007), pages 70–74, Prague, Czech Republic. Association for Computational Linguis- tics.</a><br><br><a id="s203" onmouseover="over('s203', 'r203')" onmouseout="out('r203')">Carlo Strapparava, Rada Mihalcea, and Alberto Battoc- chi. 2012. A Parallel Corpus of Music and Lyrics Annotated with Emotions. In Proceedings of the Eighth International Conference on Language Re- sources and Evaluation (LREC 2012), pages 2343– 2346, Istanbul, Turkey. European Language Re- sources Association (ELRA).</a><br><br><a id="s204" onmouseover="over('s204', 'r204')" onmouseout="out('r204')">Sudha Verma, Sarah Vieweg, William Corvey, Leysia Palen, James Martin, Martha Palmer, Aaron Schram, and Kenneth Anderson. 2011. Natural Language Processing to the Rescue? Extracting "Situational Awareness" Tweets During Mass Emergency. In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM 2017).</a><br><br><a id="s205" onmouseover="over('s205', 'r205')" onmouseout="out('r205')">Svitlana Volkova and Yoram Bachrach. 2016. Inferring Perceived Demographics from User Emotional Tone and User-Environment Emotional Contrast. In Pro- ceedings of the 54th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: LongPapers), pages 1567–1578, Berlin, Germany. Asso- ciation for Computational Linguistics.</a><br><br><a id="s206" onmouseover="over('s206', 'r206')" onmouseout="out('r206')">Alex Wang, Amanpreet Singh, Julian Michael, Fe- lix Hill, Omer Levy, and Samuel Bowman. 2018. GLUE: A Multi-Task Benchmark and Analysis Plat- form for Natural Language Understanding. In Proceedings of the 2018 EMNLP Workshop Black- boxNLP: Analyzing and Interpreting Neural Net- works for NLP, pages 353–355, Brussels, Belgium. Association for Computational Linguistics.</a><br><br><a id="s207" onmouseover="over('s207', 'r207')" onmouseout="out('r207')">Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan, and Amit Sheth. 2012. Harnessing Twitter "Big Data" for Automatic Emotion Identification. In Pro- ceedings of the 2012 ASE/IEEE International Con- ference on Social Computing and 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust, SOCIALCOM-PASSAT 2012, pages 587–592, Washington, DC, USA. IEEE Computer Society.</a><br><br><a id="s208" onmouseover="over('s208', 'r208')" onmouseout="out('r208')">Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, RÃl’mi Louf, Morgan Funtow- icz, and Jamie Brew. 2019. HuggingFace’s Trans- formers: State-of-the-art Natural Language Process- ing. arXiv preprint arXiv:1910.03771.</a><br><br><a id="s209" onmouseover="over('s209', 'r209')" onmouseout="out('r209')">Ian Wood, John McCrae, Vladimir Andryushechkin, and Paul Buitelaar. 2018. A Comparison Of Emo- tion Annotation Schemes And A New Annotated Data Set. In Proceedings of the Eleventh Interna- tional Conference on Language Resources and Eval- uation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).</a><br><br><a id="s210" onmouseover="over('s210', 'r210')" onmouseout="out('r210')"> Figure 4: Top 1000 (common) wordpiece densities for EMONET (left) and HURRICANEEMO (right). Densi- ties are calculated by counting wordpiece occurrences and normalizing by the total number of occurrences.</a><br><br><a id="s211" onmouseover="over('s211', 'r211')" onmouseout="out('r211')">A Domain Shifts</a><br><br><a id="s212" onmouseover="over('s212', 'r212')" onmouseout="out('r212')">Following the methodology outlined in Desai et al. (2019), we use the Jenson-Shannon Divergence (JSD) between the vocabulary distributions in EMONET and HURRICANEEMO to quantify the domain divergence. The JSD is 0.199, approxi- mately 1e5 larger than those reported in Desai et al. (2019). Figure 4 shows the densities of the top 1000 common wordpieces between both domains. The striking visual differences, even among com- mon wordpieces, indicates a large discrepancy in the input distributions.</a><br><br><a id="s213" onmouseover="over('s213', 'r213')" onmouseout="out('r213')">B Plutchik Emotion Agreement</a><br><br><a id="s214" onmouseover="over('s214', 'r214')" onmouseout="out('r214')">Interpretable Scale. To assign PEA scores an interpretable scale, we compare randomly gener- ated annotations against our obtained annotations. We detail the process to create random annotations. First, we compute the average number of emotions a worker assigns to a tweet, which evaluates to 3 for all hurricanes. Second, we sample 3 random emotions from the Plutchik-8 wheel for 5000 to- tal annotations. Figure 5 compares the two types of annotations. The per-worker PEA scores for the random annotations collect around the mean (0.5), which is expected due to the law of large numbers. In contrast, the per-worker PEA scores for our annotations are shifted towards the right, in- dicating better agreement than the random baseline. Therefore, we interpret our annotations as showing“moderate agreement” under the PEA metric.</a><br><br><a id="s215" onmouseover="over('s215', 'r215')" onmouseout="out('r215')">Human Evaluation. Using our worker annota- tions across all three hurricanes, we create two an- notation pairs for three workers, that is, A: (w1 , w2 ) and B: (w1,w3), where A and B have a shared worker w1. This format lends a total of 73,418 A/B total pairs. We sample 500 A/B pairs from thispool, initialize each HIT with 10 pairs, and assign 5 total workers per HIT.</a><br><br><a id="s216" onmouseover="over('s216', 'r216')" onmouseout="out('r216')">C Baseline Modeling</a><br><br><a id="s217" onmouseover="over('s217', 'r217')" onmouseout="out('r217')">Table 8 shows the hyperparameters. For our pre- trained models (e.g., BERT and RoBERTa), we use the default dropout rate (0.1) on the self-attention layers, but do not use additional dropout on the top linear layer. Furthermore, we use gradient accumu- lation to enable training with larger mini-batches.</a><br><br><a id="s218" onmouseover="over('s218', 'r218')" onmouseout="out('r218')">D Task-Guided Pre-training</a><br><br><a id="s219" onmouseover="over('s219', 'r219')" onmouseout="out('r219')">Masked Language Modeling. Following De- vlin et al. (2019), we select 15% of inputs uni- formly at random (except for [CLS] and [SEP]) as prediction targets for the masked language mod- eling task. From the corresponding inputs, 80% are set to [MASK], 10% are set to random tokens, and 10% are set to the original tokens. However, we fol- low Liu et al. (2019) in creating pre-training data dynamically, rather than statically. This merely leads to slower convergence times as it becomes more difficult to fit the data. We fine-tune on the pre-training data for 10 epochs using a batch size of 16 and learning rate of 2e-5. Once pre-training concludes, we initialize a BERT model with these weights and fine-tune it on our emotion tasks using the hyperparameters in Table 8 with a learning rate of 3e-5.</a><br><br><a id="s220" onmouseover="over('s220', 'r220')" onmouseout="out('r220')">Pre-training Corpus. Our pre-training corpus is created by concatenating a collection of (shuffled) tweets x1, x2, · · · , xn together, each separated by [SEP]. The corpus is split into segments of size 512 with [CLS] prepended to each one. For clar- ity, each batch consisting of tokens xi, · · · , xj is constructed as [CLS] xi [SEP] · · · [SEP] xj [SEP]. We elaborate on two design decisions. First, prepending [CLS] to each batch, as op- posed to each tweet, leads to better results. Second, largely due to computational reasons, we pack dis- parate tweets together in the same batch.</a><br><br><a id="s221" onmouseover="over('s221', 'r221')" onmouseout="out('r221')">E Extended Pre-training Experiments E.1 EmoNet Binary Task Pre-training</a><br><br><a id="s222" onmouseover="over('s222', 'r222')" onmouseout="out('r222')">In Section 6, we pre-trained on a EMONET multi- class classification task. In this section, we ex- plore a fine-grained pre-training scheme. We cre- ate Plutchik-8 binary tasks from EMONET, then fine-tune each emotion model separately on their respective HURRICANEEMO tasks. Table 9 shows</a><br><br><a id="s223" onmouseover="over('s223', 'r223')" onmouseout="out('r223')">  Figure 5: Histograms corresponding to PEA score distributions for random annotations (top) and our annotations (bottom).</a><br><br><a id="s224" onmouseover="over('s224', 'r224')" onmouseout="out('r224')">Logistic Reg. Word CNN Char CNN GRU BERT RoBERTa Epochs 5 5 5 5 3 3</a><br><br><a id="s225" onmouseover="over('s225', 'r225')" onmouseout="out('r225')">  64 64 1e-4 1e-3 0 00 0.5</a><br><br><a id="s226" onmouseover="over('s226', 'r226')" onmouseout="out('r226')">Table 8: Hyperparameters for the baseline modeling experiments (§5).</a><br><br><a id="s227" onmouseover="over('s227', 'r227')" onmouseout="out('r227')">Batch Size Learning Rate Weight Decay Dropout64 64 16 16 5e-5 1e-4 2e-5 2e-5 0 0 0 1e-3</a><br><br><a id="s228" onmouseover="over('s228', 'r228')" onmouseout="out('r228')">0.7 0.7 –</a><br><br><a id="s229" onmouseover="over('s229', 'r229')" onmouseout="out('r229')">– the results. EMONET-BINARY performs markedly worse than EMONET-MULTI and leads to a -2% reduction in averaged accuracy. Therefore, multi- class pre-training creates better representations for downstream evaluation, although they are still not as effective as other pre-training methods (e.g., masked language modeling).</a><br><br><a id="s230" onmouseover="over('s230', 'r230')" onmouseout="out('r230')">E.2 Varying Amounts of Pre-training Data</a><br><br><a id="s231" onmouseover="over('s231', 'r231')" onmouseout="out('r231')">The SENTIMENT and HURRICANEEXT datasets contain significantly more samples than currently used. In this section, we study the effects of us- ing varying amounts of pre-training data on down- stream HURRICANEEMO performance. For both pre-training datasets, we use 1.6M samples. Table 10 shows the supervised SENTIMENT results. Ta- bles 11 and 12 show the unsupervised SENTIMENT and HURRICANEEXT results, respectively. For both types of pre-training tasks, there is no notice- able benefit to using more pre-training data. The su- pervised SENTIMENT and unsupervised HURRICA- NEEXT results both saturate around 200K samples, which is what we report in our paper. The results for unsupervised HURRICANEEXT pre-training are especially compelling because they show that, with- out any labeled data, we can achieve strong down-stream results. Finally, the unsupervised SENTI- M E N T task yields almost no gains for most emo- tions, showing that the type of data used for masked language modeling matters. Through side-by-side comparisons, we notice that the SENTIMENT sam- ples are shorter in length and the HURRICANEEXT samples contain more relevant content, such as hurricane-specific hashtags.</a><br><br><a id="s232" onmouseover="over('s232', 'r232')" onmouseout="out('r232')"> AGR OPT LOV SBM AWE DSP RMR CNT AVG</a><br><br><a id="s233" onmouseover="over('s233', 'r233')" onmouseout="out('r233')"> NO-PRETRAINMulti Binary</a><br><br><a id="s234" onmouseover="over('s234', 'r234')" onmouseout="out('r234')">67.6 75.0 54.0 67.4 68.3</a><br><br><a id="s235" onmouseover="over('s235', 'r235')" onmouseout="out('r235')">73.5 75.2 55.2 68.8 67.5 67.7 74.9 53.7 64.7 67.5</a><br><br><a id="s236" onmouseover="over('s236', 'r236')" onmouseout="out('r236')">55.7 58.5 66.8 64.1</a><br><br><a id="s237" onmouseover="over('s237', 'r237')" onmouseout="out('r237')">53.1   71.7 65.6 54.5   63.6 62.8</a><br><br><a id="s238" onmouseover="over('s238', 'r238')" onmouseout="out('r238')"> 60.055.8</a><br><br><a id="s239" onmouseover="over('s239', 'r239')" onmouseout="out('r239')"> Table 9: Pre-training using multi-class and binary EMONET tasks. See Table 6 for styling considerations.</a><br><br><a id="s240" onmouseover="over('s240', 'r240')" onmouseout="out('r240')"> AGR OPT LOV</a><br><br><a id="s241" onmouseover="over('s241', 'r241')" onmouseout="out('r241')">67.6 75.0 54.0 67.4</a><br><br><a id="s242" onmouseover="over('s242', 'r242')" onmouseout="out('r242')">RMR CNT AVG</a><br><br><a id="s243" onmouseover="over('s243', 'r243')" onmouseout="out('r243')"> NO-PRETRAIN50K 100 K 200 K 400 K 800 KSBM AWE DSP 68.3 55.7 67.1 51.358.5</a><br><br><a id="s244" onmouseover="over('s244', 'r244')" onmouseout="out('r244')">66.8 64.1</a><br><br><a id="s245" onmouseover="over('s245', 'r245')" onmouseout="out('r245')">  55.2 57.0 57.1 57.2 57.1 56.1</a><br><br><a id="s246" onmouseover="over('s246', 'r246')" onmouseout="out('r246')">73.5 75.3 60.7 69.7</a><br><br><a id="s247" onmouseover="over('s247', 'r247')" onmouseout="out('r247')">72.8 75.8 62.7 71.0 73.4 75.6 69.1 69.8 73.1 75.4 67.2 70.1 73.5 75.3 56.2 69.4 71.2 75.2 64.8 68.8</a><br><br><a id="s248" onmouseover="over('s248', 'r248')" onmouseout="out('r248')">65.6 53.4 66.5 53.3 65.7 53.2 65.1 54.4 64.7 55.1</a><br><br><a id="s249" onmouseover="over('s249', 'r249')" onmouseout="out('r249')">66.3 64.9 67.3 65.7 69.8 66.8 67.4 66.2 68.2 64.9 70.7 65.8</a><br><br><a id="s250" onmouseover="over('s250', 'r250')" onmouseout="out('r250')">1600 K</a><br><br><a id="s251" onmouseover="over('s251', 'r251')" onmouseout="out('r251')">Table 10: Pre-training using 50-1600K labeled samples from SENTIMENT. See Table 6 for styling considerations.</a><br><br><a id="s252" onmouseover="over('s252', 'r252')" onmouseout="out('r252')">  AGR OPT LOV</a><br><br><a id="s253" onmouseover="over('s253', 'r253')" onmouseout="out('r253')">67.6 75.0 54.0 67.4</a><br><br><a id="s254" onmouseover="over('s254', 'r254')" onmouseout="out('r254')">RMR CNT AVG</a><br><br><a id="s255" onmouseover="over('s255', 'r255')" onmouseout="out('r255')"> NO-PRETRAIN50K 100 K 200 K 400 K 800 K1600 KSBM AWE DSP 68.3 55.7 67.0 53.958.5</a><br><br><a id="s256" onmouseover="over('s256', 'r256')" onmouseout="out('r256')">66.8 64.1</a><br><br><a id="s257" onmouseover="over('s257', 'r257')" onmouseout="out('r257')">65.8 64.0 62.3 63.8 64.4 63.5 64.5 64.5 63.4 64.0 65.0 64.0</a><br><br><a id="s258" onmouseover="over('s258', 'r258')" onmouseout="out('r258')">  59.3 57.4 57.9 60.1 59.4 59.3</a><br><br><a id="s259" onmouseover="over('s259', 'r259')" onmouseout="out('r259')">70.7 74.9 54.6 66.3</a><br><br><a id="s260" onmouseover="over('s260', 'r260')" onmouseout="out('r260')">71.6 75.0 54.0 66.3 69.1 74.9 53.6 66.2 70.0 74.9 53.8 69.0 70.5 74.9 55.1 66.2 69.1 74.9 55.3 66.5</a><br><br><a id="s261" onmouseover="over('s261', 'r261')" onmouseout="out('r261')">68.6 55.1 67.3 54.3 68.8 54.5 69.0 53.3 67.2 54.6</a><br><br><a id="s262" onmouseover="over('s262', 'r262')" onmouseout="out('r262')"> Table 11: Pre-training using 50-1600K unlabeled samples from SENTIMENT. See Table 6 for styling considera- tions.</a><br><br><a id="s263" onmouseover="over('s263', 'r263')" onmouseout="out('r263')"> AGR OPT LOV</a><br><br><a id="s264" onmouseover="over('s264', 'r264')" onmouseout="out('r264')">67.6 75.0 54.0 67.4</a><br><br><a id="s265" onmouseover="over('s265', 'r265')" onmouseout="out('r265')">RMR CNT AVG</a><br><br><a id="s266" onmouseover="over('s266', 'r266')" onmouseout="out('r266')"> NO-PRETRAIN50K 100 K 200 K 400 K 800 K1600 KSBM AWE DSP 68.3 55.7 69.0 56.458.5</a><br><br><a id="s267" onmouseover="over('s267', 'r267')" onmouseout="out('r267')">66.8 64.1</a><br><br><a id="s268" onmouseover="over('s268', 'r268')" onmouseout="out('r268')">72.2 66.6 65.3 65.8 70.2 68.2 63.6 65.5 71.3 66.3 64.1 64.3</a><br><br><a id="s269" onmouseover="over('s269', 'r269')" onmouseout="out('r269')">  60.4 62.4 60.2 60.7 60.3 61.0</a><br><br><a id="s270" onmouseover="over('s270', 'r270')" onmouseout="out('r270')">72.7 75.0 60.0 67.2</a><br><br><a id="s271" onmouseover="over('s271', 'r271')" onmouseout="out('r271')">71.8 75.1 57.4 69.1 73.6 75.4 69.8 68.9 71.4 75.2 59.7 69.7 71.4 75.3 58.9 69.4 73.3 75.7 50.7 68.3</a><br><br><a id="s272" onmouseover="over('s272', 'r272')" onmouseout="out('r272')">70.3 55.2 69.7 57.9 68.8 55.2 69.6 54.0 65.5 55.8</a><br><br><a id="s273" onmouseover="over('s273', 'r273')" onmouseout="out('r273')"> Table 12: Pre-training using 50-1600K unlabeled samples from HURRICANEEXT. See Table 6 for styling consid- erations.</a><br><br><a id="s274" onmouseover="over('s274', 'r274')" onmouseout="out('r274')"> Figure 6: Visualization of BERT’s self-attention on a Hurricane Irma sample. In particular, this head captures the entities “hurricane irma,” “florida,” “everyone” and the verb phrase “crane collapses.”</a><br>
</div>
<div id="result">
<br><a id="r0" onmouseover="over('r0', 's0')" onmouseout="out('s0')">ハリケーン災害における知覚された感情の検出Shrey Desai1 Cornelia Caragea2 Junyi Jessy Li1</a><br><br><a id="r1" onmouseover="over('r1', 's1')" onmouseout="out('s1')">1テキサス大学オースティン校 2イリノイ大学シカゴ校 {shreydesai@, jessy@austin.}utexas.edu cornelia@uic.edu</a><br><br><a id="r2" onmouseover="over('r2', 's2')" onmouseout="out('s2')">アブストラクト</a><br><br><a id="r3" onmouseover="over('r3', 's3')" onmouseout="out('s3')">ハリケーンなどの自然災害は、毎年数百万人もの人々に被害を与え、甚大な被害をもたらしています。近年、人々はTwitterなどのソーシャルメディアを利用して、自分の感情や気持ちをより多くの人々と共有するようになりました。その結果、これらのプラットフォームは、スケールの大きい感情を理解し、認識するのに役立っている。本論文では，3つのハリケーン（Harvey，Irma，Maria）に関する15,000件の英語ツイートからなる感情データセット，HURRICANEEMOを紹介します。HURRICANEEMOでは，細粒度の感情を包括的に研究し，粗粒度の感情グループを識別するための分類タスクを提案している．我々の最良のBERT（De vlin et al., 2019）モデルは、ラベルのないTwitterデータを活用したタスク誘導型の事前学習を行っても、68％の精度しか達成できませんでした（全グループの平均値）。HURRICANEEMOは、mod-elsにとって挑戦的なベンチマークであるだけでなく、災害中心のドメインで感情を分析するための貴重なリソースとしても役立ちます。</a><br><br><a id="r4" onmouseover="over('r4', 's4')" onmouseout="out('s4')">1 はじめに</a><br><br><a id="r5" onmouseover="over('r5', 's5')" onmouseout="out('s5')">自然災害は、毎年、何千人もの死者と何億人もの被災者を出しています（Ritchie and Roser, 2020）。このような大災害は、物質的な破壊を引き起こすだけでなく、人間の本質的な部分である感情をも揺さぶります。災害は個人の精神状態に大きな影響を与えるため（Fritz and Marks, 1954; Kinston and Rosser, 1974）、多くの人が自分の感情をソーシャルメディア（Twitterなど）で共有するのは当然のことです。その結果、ソーシャル・メディア・ウェブサイトは、感情の表現と認識を理解するための重要なプラットフォームとなり(Mohammad, 2012; Wang et al., 2012; Moham- mad and Kiritchenko, 2015; Volkova and Bachrach, 2016; Abdul-Mageed and Ungar, 2017)、学術的な研究から公共政策まで、幅広い影響を及ぼす可能性があります(Dennis et al., 2006; Fritze et al., 2008; Fraustino et al., 2012)。</a><br><br><a id="r6" onmouseover="over('r6', 's6')" onmouseout="out('s6')">自然言語処理は感情検出に有効であるが(Strapparava and Mihalcea, 2007)、災害中心の領域では既存のリソースが苦戦しており、その理由の一つは分布の変化である。ハリケーンなどの自然災害における感情検出には、表面的な語彙情報では得られない暗黙の推論が必要である。例えば、"of course, [we]1 still have the [storm surge]2 coming "では、文脈から、偏光語がないにもかかわらず、"storm surge "に対する不満を推測することができます。そのため、主に語彙単位に基づく遠隔監視技術（Mohammad and Turney, 2013; Abdul-Mageed and Ungar, 2017）では、この種のより深い意味論的現象を捉えることができない。</a><br><br><a id="r7" onmouseover="over('r7', 's7')" onmouseout="out('s7')">本稿では、ハリケーン災害時に知覚される感情について包括的な調査を行った。この目的のために，2017年の大西洋ハリケーンシーズンに発生した壊滅的な熱帯低気圧であるハリケーン「ハービー」「イルマ」「マリア」の際に流れた15,000件の災害関連ツイート（En-glish）のデータセットであるHURRICANEEMOを紹介する（Belles, 2017）。このサンプルには，Plutchik Wheel of Emotions (Plutchik, 2001)という，計算社会科学でよく使われる感情クラスの明確なオントロジーに由来する，細かい感情がアノテーションされている(Abdul-Mageed and Ungar, 2017)。PEAは直感的に理解できるもので、我々の人間評価では、作業者はPEAのランキングに88%の確率で同意しています。さらに、ハリケーンのツイートに含まれる暗黙的・明示的な感情について、洞察に満ちた分析を行いました（§4）。特に、Plutchik-8とPlutchik-24の感情を使用しています。読者にはPlutchik (2001)を参照していただきたい。</a><br><br><a id="r8" onmouseover="over('r8', 's8')" onmouseout="out('s8')"> arXiv:2004.14299v1 [cs.CL] 29 Apr 2020</a><br><br><a id="r9" onmouseover="over('r9', 's9')" onmouseout="out('s9')">ハリケーン「ハービー」、「イルマ」、「マリア」の間では、Plutchik-24の感情分布に一貫性があることがわかります。</a><br><br><a id="r10" onmouseover="over('r10', 's10')" onmouseout="out('s10')">HURRICANEEMOは、大規模な事前学習された言語モデルのための挑戦的な新しいベンチマークとしても機能します。BERT (De- vlin et al., 2019) とRoBERTa (Liu et al., 2019) を用いて、より粗いPlutchik-8の感情検出タスクのベースラインを確立する（§5）。我々の実験で明らかになったことは 1）BERTは64％（平均値）の精度しか達成していない、（2）を使用して</a><br><br><a id="r11" onmouseover="over('r11', 's11')" onmouseout="out('s11')">"better" pre-trained model (e.g. RoBERTa)は役に立たず、これはほとんどのリーダーボードとは著しく異なる傾向である(Wang et al, 2018)。彼らの落とし穴、特にBERTをよりよく理解するために、我々は200のイン正しく予測されたサンプルの包括的なエラー分析を行います。さらに、関連するタスクでの事前トレーニングを介して、より強い帰納的バイアスをBERTに組み込み、（平均、絶対）＋4％の精度を達成する（§6）。最後に、既存の大規模感情データセット（例えば、EMONET（Abdul-Mageed and Ungar, 2017））とHURRICANEEMOの間のドメインギャップを埋めるために、教師なしのドメイン適応を提案する（§7）。我々のコードとデータセットは公開されている2。</a><br><br><a id="r12" onmouseover="over('r12', 's12')" onmouseout="out('s12')">2 関連作品</a><br><br><a id="r13" onmouseover="over('r13', 's13')" onmouseout="out('s13')">感情の検出は、ニュースの見出し（Strapparava and Mihalcea, 2007; Katz et al, 2007）、ブログの投稿（Aman and Szpakow- icz, 2007）、健康関連の投稿（Khanpour and Caragea, 2018）、歌の歌詞（Strapparava et al, 2012）、しかしごく最近では、ソーシャルメディアウェブサイト（例えば、Twitter、Facebook）においても行われている（Mohammad, 2012; Wang et al. しかし、災害中心のドメインにおける感情検出は、その実用的な重要性にもかかわらず、限定的である。Schulzら（2013）は、Ekman-6感情（Ekman, 1992）を用いて2,200件のハリケーン・サンディのツイートを（片手間に）アノテーションしています。これに対して、我々は、複数のハリケーンからの15,000件のツイートを、（より細かい）Plutchik-24の感情を用いてアノテーションしたものを紹介する。Abdul-Mageed and Ungar (2017)とは異なり、我々は書き手が意図した感情ではなく、読み手が知覚した感情に焦点を当てる。</a><br><br><a id="r14" onmouseover="over('r14', 's14')" onmouseout="out('s14')">さらに、災害を中心とした領域では、信頼性の高いモデルを学習するために必要なラベル付きデータが不足しているため、教師付き学習技術を使用することができません。ラベル付きデータを使用することを提案しているものもある。</a><br><br><a id="r15" onmouseover="over('r15', 's15')" onmouseout="out('s15')">2https://github.com/shreydesai/ hurricanefrom from prior (source) disasters to learn classifiers for new (target) disasters (Verma et al., 2011; Nguyen et al., 2017; Imran et al., 2013, 2016; Caragea et al., 2016). しかし、災害の種類、地理的な位置、季節、被災者の文化的な違いなど、それぞれの災害に固有の性質があるため、ソース災害がターゲット災害の特徴を正確に反映していない可能性があります（Palen and Anderson, 2016; Imran et al., 2015）。ドメイン適応技術は、大量のラベル化されていないタールゲットドメインデータを効率的に使用することでこれらの課題に対処し、結果的に前述の教師付き技術よりも優れています（Alam et al. 私たちの研究は、以下の3つの方法で災害中心の感情検出に貢献します。(1)教師付き分類器を訓練するのに十分な大きさのデータセットを導入すること、(2)強い帰納的バイアスを植え付けるための様々な形の事前訓練を模索すること、(3)遠隔監視によって得られる感情サンプルを活用することで、ドメイン適応のベースラインを確立すること。</a><br><br><a id="r16" onmouseover="over('r16', 's16')" onmouseout="out('s16')">3 データセットの構築</a><br><br><a id="r17" onmouseover="over('r17', 's17')" onmouseout="out('s17')">本節では、Hurricanes Harvey, Irma, Mariaの15,000件の英語ツイートを収録したアノテーションデータ、HURRICANEEMOを紹介します。Hurrican Harvey, Irma, Mariaの15,000件の英語ツイートにアノテーションを施したHURRICANEEMOを紹介します。</a><br><br><a id="r18" onmouseover="over('r18', 's18')" onmouseout="out('s18')">3.1 前処理</a><br><br><a id="r19" onmouseover="over('r19', 's19')" onmouseout="out('s19')">Ray Chowdhuryら（2019）は、Harvey、Irma、Mariaの3つのハリケーンの際に流れたツイートからなる大規模Twitterデータセットのリポジトリを公開しており、これをHURRICANEEXT（＝拡張）と呼ぶことにする。これらのツイートを出発点として，データセットを構築しました。2種類の前処理を行いました。まず、ユーザー名とリンクを<USER>と<URL>に置き換え、重複するツイートを削除します。2つ目は、感情的な内容を含むツイートをフィルタリングすることである。</a><br><br><a id="r20" onmouseover="over('r20', 's20')" onmouseout="out('s20')">すなわち，EMOLEX (Mo- hammad and Turney, 2013)から抽出した少なくとも1つの単語で構成されていることを条件とします．EMOLEXは、複数の感情カテゴリに関連する14,182のクラウドソースの単語から構成されています。重要なのは、これらの単語は感情的な文脈で登場するが、必ずしも感情的な単語そのものではないということである。例えば、"payback "は</a><br><br><a id="r21" onmouseover="over('r21', 's21')" onmouseout="out('s21')"> 感情の「怒り」に関連していますが、金融でも広く使われています。過去の重要な研究（Bravo- Marquez et al., 2014; Majumder et al., 2017; Giat- soglou et al., 2017）では、（1）ラベルのないツイートをそのまま使用する、または（2）モデルを使用して感情的なツイートを分類する、という選択肢があるため、この語彙を使用して感情データセットをブートストラップにしています。当初は（1）でスタートし、感情に関する前処理は一切行いませんでした。しかし、データセットには、ニュース記事の抜粋など、感情とはあまり関係のないスプリアスなつぶやきが多く含まれていました。このようなノイズが多いデータは、アノテーションのコストが非常に高くなります。また、EMONETのような既存のリソースでは、感情を表すハッシュタグ（#sad, #angry, #happyなど）が明示的に含まれている場合にのみツイートが含まれるという、さらに強い事前条件が設定されています。</a><br><br><a id="r22" onmouseover="over('r22', 's22')" onmouseout="out('s22')">3.2 アノテーション</a><br><br><a id="r23" onmouseover="over('r23', 's23')" onmouseout="out('s23')">ハービー，イルマ，マリアのフィルタリングされたデータセットから，それぞれ5,000のツイートを無作為に抽出してアノテーションを行い，合計で15,000のアノテーションを得た．Amazon Mechanical Turkのワーカーに、Plutchik-24の感情リストをツイートにラベル付けするよう依頼します。さらに，きめ細かな感情分析を可能にするため，Plutchik-8の感情を直接クラウドソーシングすることはしません．ワーカーは米国在住で，500回以上のHITを完了し，95%以上の合格率を達成していることが条件となっています．各HITは5人のワーカーによって完成されます。</a><br><br><a id="r24" onmouseover="over('r24', 's24')" onmouseout="out('s24')">3.3 注釈者間の合意</a><br><br><a id="r25" onmouseover="over('r25', 's25')" onmouseout="out('s25')">このセクションでは、細かな感情ラベルに対するアノテーター間の合意を計算するためのPEAメトリックについて詳しく説明します。</a><br><br><a id="r26" onmouseover="over('r26', 's26')" onmouseout="out('s26')">課題 細かい感情のアノテーションは、アノテーター間の一致を評価する上でいくつかの課題があります。まず、1つのツイートは複数の感情を伝えることができるため、作業者が複数のPlutchik-24感情を選択できるようにしています。そのため、一致度を評価するには、カテゴリー値のスコアリングセットをサポートする必要があります。Passonneau (2004) は、共参照クラスタアノテーション間の合意を捉えるためにセット距離メトリックを使用している。同様に、Woodら（2018）はKrippendorffのαにJaccardの類似性を組み込んでいる。しかし、これらのメトードは、細かい感情を均等にペナルティすることになり、理想的ではない。Plutchikホイールでは、任意の2つの感情の近接性は、それらの関連性を表しています。例えば、「信頼」と「忠誠」は同じ感情グループに属し、「忠誠」と「忠誠」は互いに直交しています。</a><br><br><a id="r27" onmouseover="over('r27', 's27')" onmouseout="out('s27')">図1：PEA指標の視覚化。単位円をPlutchikホイールに重ね合わせ、Plutchik-8の各感情にラジアン値を割り当てている。この例では、3πに対応する感情とπに対応する感情の間の（正規化された）距離は0.25です。</a><br><br><a id="r28" onmouseover="over('r28', 's28')" onmouseout="out('s28')">24</a><br><br><a id="r29" onmouseover="over('r29', 's29')" onmouseout="out('s29')">PEAのスコア これらの課題を解決するために、Plutchik EmotionAgreement（以下、PEAと略す）を導入しました。我々はPlutchikホイールに単位円を重ね合わせ、Plutchik-8の各感情を極座標で表しました（例えば、√DISAPPROVAL = ( 2 , - 2 ) ）。直感的には、アン-</a><br><br><a id="r30" onmouseover="over('r30', 's30')" onmouseout="out('s30')"> Plutchik-8の感情間の22glesは、それらがどれだけ似ているか、あるいは似ていないかを表しています。2つのPlutchik-24アノテーションが同じPlutchik-8グループに属する場合は、ペナルティを課さない（例えば、JOYとECSTASYはペナルティを課さない）。それ以外の場合は、アノテーションがどれだけ半径方向に離れているかに基づいて、線形のペナルティを課します（例えば、ECSTASYとGRIEFは最も高いペナルティを課します）。PEAスコアが高いほど、より多くの合意があることを意味する。</a><br><br><a id="r31" onmouseover="over('r31', 's31')" onmouseout="out('s31')">例 図1は我々の指標を視覚化したものです。この例では，2人のアノテーターがそれぞれ半径3πとπの感情を選択しています．このとき、｜f (e(i) ) - f (e(j) )| 24xytermは5πと評価される．次に，πで正規化すると，4 = 1.25となります．最後に引き算をして一致度を求めます。|1 - 1.25| = 0.25. 実際には、完全に意見が一致しない（直交している）よりもわずかにマシという程度なので、これは理にかなっています。</a><br><br><a id="r32" onmouseover="over('r32', 's32')" onmouseout="out('s32')">定式化。明確にするために、表記法を紹介する。ここで、wxとwyを、（カテゴリカル）アノテーションセット{e(i)}nと{e(j)}mを持つ作業者とすると、それぞれ、x i=1 y j=1となる。作業者間のペアワイズの一致度d(wx , wy )は次のように計算される。</a><br><br><a id="r33" onmouseover="over('r33', 's33')" onmouseout="out('s33')"> アドミレーション</a><br><br><a id="r34" onmouseover="over('r34', 's34')" onmouseout="out('s34')">1n 1(i)(j)max |1 - |f (ex ) - f (ey ) ||。</a><br><br><a id="r35" onmouseover="over('r35', 's35')" onmouseout="out('s35')"> 憎しみ</a><br><br><a id="r36" onmouseover="over('r36', 's36')" onmouseout="out('s36')">n i=1 j π VocabularyFeatures (%)# @ // です。</a><br><br><a id="r37" onmouseover="over('r37', 's37')" onmouseout="out('s37')">48.1 27.4 85.3 41.4 22.5 81.7 36.5 30.3 78.3</a><br><br><a id="r38" onmouseover="over('r38', 's38')" onmouseout="out('s38')">ヒューストンではメキシコが助けてくれたので、そのお返しをしよう。</a><br><br><a id="r39" onmouseover="over('r39', 's39')" onmouseout="out('s39')">ハリケーン・イルマがフロリダを襲っています。みんなが避難しています 私はまだフロリダにいます イルマにかかって来い、かかって来い。</a><br><br><a id="r40" onmouseover="over('r40', 's40')" onmouseout="out('s40')">プエルトリコは、アメリカのニュースの中で唯一の存在であるべきです。<URL>joy, admiration, pensivenessacceptance, an-ticipation, vigi-lanceanger, annoy- ance, interest HurricaneHarvey Irma MariaOrig.</a><br><br><a id="r41" onmouseover="over('r41', 's41')" onmouseout="out('s41')">20.6 k 14.6 k 21.6 k</a><br><br><a id="r42" onmouseover="over('r42', 's42')" onmouseout="out('s42')">フィルト。</a><br><br><a id="r43" onmouseover="over('r43', 's43')" onmouseout="out('s43')">14.4 k 8.8 k 15.8 k</a><br><br><a id="r44" onmouseover="over('r44', 's44')" onmouseout="out('s44')">    表1：ハリケーンごとのデータセットの統計。語彙のセクションでは、Orig.は（空白トークン化によって得られた）語彙数を、Filt.は<USER>と<URL>の前処理後の語彙数を示しています。特徴のセクションでは、ハッシュタグ(#)、ユーザーの言及(@)、リンク(//)を含むツイートの割合を示しています。</a><br><br><a id="r45" onmouseover="over('r45', 's45')" onmouseout="out('s45')">ここで、π1は正規化定数であり、f : Ω → R は Plutchik-8 感情からラジアンへのマップです。あるツイートにアノテーションを行った作業者の集合が与えられたとき、可能なすべてのペアワイズの合意を平均することで、作業者ごとのPEAスコアを得る。例えば、作業者w1-3が同じツイートをアノテーションした場合、PEA(w1) = 21 (d(w1, w2) + d(w1, w3)) となる。品質管理のために、PEA≦0.55の作業者のアノテーションをフィルタリングする。この閾値は，50人の作業者とそのアノテーションを手動で検査して決定した．各ハリケーンのPEAスコア（ワーカーごとの平均値）は以下の通りである。3人のアノテーターが作成した2つの表記ペア（A: (e1, e2)とB: (e1, e3)）の一致度を判断することを求められた。3つの選択肢があります。88.2%の作業者の順位がPEAの順位と一致しており、人間の強い同意が得られていることがわかる。この研究では，作業員自身もKrippendorffのα（α=74.0）によると良好な一致を示している（Artstein and Poesio, 2008）4表2: HURRICANEEMOのサンプル。各サンプルには複数のPlutchik-24の感情がアノテーションされている。</a><br><br><a id="r46" onmouseover="over('r46', 's46')" onmouseout="out('s46')">ハリケーンあたりのツイート数が5,000であることを考えると、すべてのデータセットの語彙数は大きい。前処理によって語彙数は約30%減少しますが、結果として得られたサイズは、ユーザーが自分の感情を表現するために無数の単語を使用していることを示唆しています。次に，ハッシュタグを含むツイートは，ハリケーンのツイートでは約50％，イルマ／マリアのツイートでは約40％しかありません。ハッシュタグは、Twitterの言説のユニークな目印ですが(Ritter et al., 2011)、今回のデータセットでは、ハッシュタグは、特定の人にタグを付けたり、災害救援の意識を広めたり、トレンドコンテンツを作ったりするのに使われています。この現象だけでも、私たちのツイートはdis-tant supervisionによって収集されたものとは異なります（Abdul-Mageed and Ungar, 2017）。第3に、ツイートのおよそ80～85％は、第三者のコンテンツへのリンクを含んでいます。ユーザーは一般的に、ニュース記事、人道支援のためのリソース、その他の雑多なマルチメディアを共有するためにリンクを使用します。</a><br><br><a id="r47" onmouseover="over('r47', 's47')" onmouseout="out('s47')">表2はHURRICA- NEEMOの3つのサンプルを示しています。EMONET（Abdul-Mageed and Ungar, 2017）とは異なり、我々のデータセットは、1つのツイートでは1つの感情しか表現できないという強い前提を持っていません。例えば、最初のツイートは、語彙的に複数の感情の表現を指し示しています。述語の "helped us "は、メキシコの援助を賞賛していることを意味し、感嘆符は "JOY "を表しています。また、今回のサンプルには、語彙情報だけでは解決できない、暗黙的な感情と明示的な感情が混在しています。3番目のツイートでは、ANGERやANNOYANCEを示す特定の単語はありませんが、ユーザーはメディアがハリケーン・マリアを優先していないことに腹を立てていると推測されます。最後に、我々の感情予測タスクは、事前に訓練された単語のem-beddings（Mikolov et al.2013; Pennington et al.2014）や文脈表現（Peters et al.2018; Devlin et al.2019; Liu et al.2019）を後付けするだけでは解決できませんが、これは我々の実験でも経験的に示しています（§5）。これらの手法は、スパースなlex-Human Evaluationに大きくオーバーフィットするため、明示的なエモーション検出に最適である。</a><br><br><a id="r48" onmouseover="over('r48', 's48')" onmouseout="out('s48')">感情アノテーションのアノテーター間のagree-mentを測定するための先行研究には存在しない、我々の提案したメトリックで人間の評価を行います（Wood et al, 2018; Öhman et al, 2018）。クラウドソースの労働者は4 4.1定性的分析データセットの概要表1はHURRICA- NEEMOのいくつかの統計を示しています。我々は3つの観察を行う。第一に、3PEAスコアの合理的な解釈は以下のようになるだろう。0-25（一致しない）、25-50（一致しない）、50-75（中程度の一致）、75-100（高い一致）。</a><br><br><a id="r49" onmouseover="over('r49', 's49')" onmouseout="out('s49')">4手続きの詳細については、付録Bをご参照ください。</a><br><br><a id="r50" onmouseover="over('r50', 's50')" onmouseout="out('s50')">  Plutchik-8 EmotionaggressivenessoptimismlovesubmissionawedisapprovalremorsecontemptPlutchik-24 Abbrv.</a><br><br><a id="r51" onmouseover="over('r51', 's51')" onmouseout="out('s51')">agrsvoptsmlovesbmsnawedspvlrmrsecntmpEmotionrageanger annoyancevigilance anticipation interestecstasy joy serenityadmiration trust acceptanceterrorfear apprehensionamazement surprise distractiongrief sadness pensivenessloathing disgust boredom abbrv.</a><br><br><a id="r52" onmouseover="over('r52', 's52')" onmouseout="out('s52')">怒り 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情 怒りの感情</a><br><br><a id="r53" onmouseover="over('r53', 's53')" onmouseout="out('s53')">図2：各ボックスのPlutchik-8感情を、再考可能なPlutchik-24感情に分解したハリケーンごとの感情数。Plutchik-24の感情は、表3のコードを使って略されている。</a><br><br><a id="r54" onmouseover="over('r54', 's54')" onmouseout="out('s54')">今回の調査では、ユーザーがハリケーンそのものや災害後の救援活動について認識を深めるためのソーシャルプラットフォームとしてTwitterを利用していることがわかりました。このように、ユーザーは恐怖や悲しみ、怒りなどの自然な感情を表現しているにもかかわらず、多くの人が逆境の中で他の人を助けようとしていることがわかり、勇気づけられました。第三に、ハービーとイルマの間で感情数が急激に変化したのは、それぞれの歴史と関係があるかもしれません。2017年の大西洋のハリケーンシーズンでは、ハービーがカテゴリー4のハリケーンとなり、その2週間後にイルマがカテゴリー5のハリケーンとなった5。両ハリケーンのツイートを並べて比較したところ、イルマのツイートには破壊とその余波に関する記述が多く見られた。このような言説の変化が、感情の分布の変化を説明できる可能性がある。</a><br><br><a id="r55" onmouseover="over('r55', 's55')" onmouseout="out('s55')">4.3 Emotion Co-Occurrence</a><br><br><a id="r56" onmouseover="over('r56', 's56')" onmouseout="out('s56')">これまで、私たちはPlutchik-24の各エモーションを個別に分析してきました。このセクションでは、次のような疑問を投げかけます。Plutchik-8の感情グループはどのように互いに共起するのか？図3は、各ハリケーンの共起ヒートマップです。図3はハリケーンごとの共起ヒートマップです。直観的には、偏った感情、つまり感情-5Category-xの略語の間に強い相関関係が見られます。持続風速でハリケーンを分類するSaffir-Simpsonスケールのことで、深刻度の高い順に1～5の範囲となる。</a><br><br><a id="r57" onmouseover="over('r57', 's57')" onmouseout="out('s57')">         表3：本稿で使用したPlutchik-8（左）とviations、Plutchik-24（右）の略記号。</a><br><br><a id="r58" onmouseover="over('r58', 's58')" onmouseout="out('s58')">グラフィカルな特徴。むしろ、暗黙の感情を捉えるためには、前述の特徴のバランスを取りながら、文脈（どのような出来事があったのかなど）や意味的役割（誰に何が起こったのかなど）を適切に推論する帰納的なバイアスをモデルに持たせる必要があります。</a><br><br><a id="r59" onmouseover="over('r59', 's59')" onmouseout="out('s59')">4.2 細やかな感情表現</a><br><br><a id="r60" onmouseover="over('r60', 's60')" onmouseout="out('s60')">私たちは、データセットに含まれる細かい感情の分析を始めます。次のような質問をします。感情の一般的な分布はどうなっているのか？感情の一般的な分布はどうなっているのか、特定の感情グループが他よりも強調されているのか？図2は、ハリケーン「ハービー」、「イルマ」、「マリア」のPlutchik-24の感情分布を示したものです。この図から、いくつかの傾向が見えてきました。まず、Plutchik-24の感情数は、ADMIRATIONとFEARの顕著な例外を除いて、互いにボールパーク内に収まっています。このことから、ハリケーン災害は、ほとんどの感情カテゴリーにおいて、平均的に、暗黙的、明示的な感情の広がりを引き起こすことがわかります。第二に、ハリケーン災害時には、ユーザーはよりオプティミスティックなコンテンツを投稿する傾向がある。我々は</a><br><br><a id="r61" onmouseover="over('r61', 's61')" onmouseout="out('s61')">  Plutchik-8 Emotion Train Aggressiveness 4,209</a><br><br><a id="r62" onmouseover="over('r62', 's62')" onmouseout="out('s62')">有効なテスト</a><br><br><a id="r63" onmouseover="over('r63', 's63')" onmouseout="out('s63')">526 527 1,488 1,488 321 322 762 762 916 916 741 742 967 967 470 471 楽観主義 愛服従 畏敬の念 不承認 反省 軽蔑</a><br><br><a id="r64" onmouseover="over('r64', 's64')" onmouseout="out('s64')">11,902 2,569 6,092 7,324 5,931 7,732 3,763</a><br><br><a id="r65" onmouseover="over('r65', 's65')" onmouseout="out('s65')"> 図3：ハリケーンごとのPlutchik-8感情共起。マトリックスは対角線上で対称であるため、わかりやすくするためにマトリックスの上対角線をマスクした。Plutchik-8の感情は、表3のコードを使って略されている。</a><br><br><a id="r66" onmouseover="over('r66', 's66')" onmouseout="out('s66')">感情はポジティブとネガティブに分類されます。表4：Plutchik-8の各感情についての訓練、検証、テストの分割。</a><br><br><a id="r67" onmouseover="over('r67', 's67')" onmouseout="out('s67')">他のバケツに入れます。ここで，正と負のサンプルをシャッフルし，80/10/10の分割を行って，トレーニングセット，検証セット，テストセットを作成します6。</a><br><br><a id="r68" onmouseover="over('r68', 's68')" onmouseout="out('s68')">5.1 実験セットアップ</a><br><br><a id="r69" onmouseover="over('r69', 's69')" onmouseout="out('s69')">伝統的なニューラルモデルと事前に訓練された言語モデルの両方を検討します。我々は、PyTorch（Paszke et al., 2019）で我々のmod-elsを実装し、NVIDIA Titan V GPUですべての実験を行う。学習と最適化のハイパーパラメータは、付録Cに詳述した。それぞれ異なるランダムな初期化を行った10回の実行での平均性能を報告します。以下では、我々のモデルについて詳しく説明します。</a><br><br><a id="r70" onmouseover="over('r70', 's70')" onmouseout="out('s70')">従来のニューラルモデル。それぞれ、2Bのツイートで事前に学習した200DのGloVeエンベディングを搭載している（Pennington et al, 2014）。(1) Logistic Re-gression: シーケンス内の各トークンの単語埋め込みを平均化する（Iyyer et al: サイズ[3, 4, 5]の100個のフィルタを持つ単語レベルのCNN (Kim, 2014)が表現を得る。これらは最大プールされ，行ごとに連結される．また，文字レベルのCNNでも実験を行った．(3) GRU: 1層，単方向のGRU (Cho et al., 2014) を用いて，隠れた次元を100とし，特徴量を得て，これを平均プールする．すべてのモデルにおいて，重み行列W∈Rd×2を用いて，最終的な表現を投影しています。</a><br><br><a id="r71" onmouseover="over('r71', 's71')" onmouseout="out('s71')">事前に訓練された言語モデル。Hugging-Face Transformersライブラリ(Wolf et al., 2019)を用いて、BERT(Devlin et al., 2019)とRoBERTa(Liu et al., 2019)のベースバージョンを微調整します。我々は</a><br><br><a id="r72" onmouseover="over('r72', 's72')" onmouseout="out('s72')">6また、ネガティブなサンプルを均等に抽出するのではなく、すべてのネガティブなサンプルを残すという実験も行いました。各バイナリタスクでは，約5～7倍の負のサンプルがあったが，これはモデルの性能を著しく低下させた．クラスインバランスペナルティを適用しても、モデルはほとんど正のサンプルを予測しませんでした。なお，全体としては正と負のサンプル数は一致していますが，訓練，検証，テストの各段階では必ずしも一致していません．</a><br><br><a id="r73" onmouseover="over('r73', 's73')" onmouseout="out('s73')">  例えば、（LOVE ,）は、（（CONTEMPT ,）と同じくらい頻繁に登場します。</a><br><br><a id="r74" onmouseover="over('r74', 's74')" onmouseout="out('s74')">この前提は常に成り立つわけではなく、（{ DISAPPROVAL , REMORSE }, OPTIMISM ）のペアは、すべてのハリケーンで共起する。この現象を象徴するのが、次のようなツイートです。"この現象を象徴するのが、次のようなツイートである。「ハリケーン・マリアがあらゆるものを破壊したので、寄付を募っています。クリックして寄付してください。<URL> via <USER>"。このユーザーは、パトスを喚起することでハリケーンへの不支持を示していますが、救援活動に寄付をすることで楽観的な姿勢も示しています。最後に、これまでの考察（§4.2）と同様に、Harvey → Irmaの順に共起頻度が増加していることがわかります。この増加は、意外にも( AWE , )が最も顕著であるが、({ DISAPPROVAL , }, AWE )の頻度も顕著に増加している。ここでも、ユーザーはCat-4→Cat-5への移行を悲しむと同時に、ハリケーンの被害を受けた人々への連帯感を表現しているのではないかと推測されます。</a><br><br><a id="r75" onmouseover="over('r75', 's75')" onmouseout="out('s75')">5 ベースラインモデリング 次に HURRI- CANEEMO の感情のモデリングを行います。Plutchik-24の感情数は非常に不均衡であるため、それらをPlutchik-8の感情にグループ化し、結果として8つの2項分類タスクを作成しました。</a><br><br><a id="r76" onmouseover="over('r76', 's76')" onmouseout="out('s76')">ツイートは、それぞれのラベルバケットに分類されます。ツイートには複数の感情がラベル付けされている場合があるため、それぞれのバケットは1つ以上のバケットに属します。これらのバケットは、ポジティブなサンプル（その感情でラベル付けされたツイート）を表します。ネガティブなサンプルを作成するには，次のようにして，同量の</a><br><br><a id="r77" onmouseover="over('r77', 's77')" onmouseout="out('s77')">AGGRESSIVENESS</a><br><br><a id="r78" onmouseover="over('r78', 's78')" onmouseout="out('s78')">)はしません)や、しかし</a><br><br><a id="r79" onmouseover="over('r79', 's79')" onmouseout="out('s79')">  LOVE</a><br><br><a id="r80" onmouseover="over('r80', 's80')" onmouseout="out('s80')">,</a><br><br><a id="r81" onmouseover="over('r81', 's81')" onmouseout="out('s81')">オプティミズム</a><br><br><a id="r82" onmouseover="over('r82', 's82')" onmouseout="out('s82')"> AGGRESSIVENESS</a><br><br><a id="r83" onmouseover="over('r83', 's83')" onmouseout="out('s83')">    オプティミズム</a><br><br><a id="r84" onmouseover="over('r84', 's84')" onmouseout="out('s84')">  REMORSE</a><br><br><a id="r85" onmouseover="over('r85', 's85')" onmouseout="out('s85')"> アグリ・オプティム・ラブ・SBM・アウエー・ドスプ・RMR・Cnt・アベレージ</a><br><br><a id="r86" onmouseover="over('r86', 's86')" onmouseout="out('s86')"> Logistic Reg. Char CNN Word CNN GRU BERT RoBERTa</a><br><br><a id="r87" onmouseover="over('r87', 's87')" onmouseout="out('s87')">49.8 74.7 50.9 50.6 50.2 74.3 43.0 47.2 43.6 74.5 44.7 45.4 48.4 74.7 54.0 50.9 67.6 75.0 54.0 67.4 59.7 74.7 54.0 62.3</a><br><br><a id="r88" onmouseover="over('r88', 's88')" onmouseout="out('s88')">48.9 49.7 48.3 44.7 47.1 47.4 44.2 47.0 46.9 50.1 49.9 48.9 68.3 55.7 58.5 56.0 50.9 49.7</a><br><br><a id="r89" onmouseover="over('r89', 's89')" onmouseout="out('s89')">46.8 52.5 48.8 50.3 43.9 48.8 49.2 53.3 66.8 64.1 56.4 58.0</a><br><br><a id="r90" onmouseover="over('r90', 's90')" onmouseout="out('s90')"> 表5：Plutchik-8のバイナリタスクの精度（攻撃性（aggr）、楽観性（opt）、愛（lov）、服従（sbm）、畏怖（aw）、不支持（dsp）、反省（rmr）、軽蔑（cnt）を含む）。また，すべてのバイナリタスクの平均値（avg）も報告する．最良の結果は太字で表示されています。</a><br><br><a id="r91" onmouseover="over('r91', 's91')" onmouseout="out('s91')">は、[CLS]トークンに埋め込まれた文の表現を利用し、それを重み行列W∈Rd×2で投影します。言語モデルと分類パラメータは共同で微調整されます。</a><br><br><a id="r92" onmouseover="over('r92', 's92')" onmouseout="out('s92')">5.2 結果</a><br><br><a id="r93" onmouseover="over('r93', 's93')" onmouseout="out('s93')">表5は、我々の分類結果を示しています。次のような見解を示しています。</a><br><br><a id="r94" onmouseover="over('r94', 's94')" onmouseout="out('s94')">BERT は、ほとんどの感情タスクにおいて、一貫して他のモデルを上回っています。BERT は、従来のニューラルモデルおよび RoBERTa と比較して、8 つのバイナリタスクすべてに おいて高い性能を示しています。ほとんどの伝統的なニューラルモデルとは異なり、BERT の精度はランダムな確率を下回ることはなく、本データセットに存在する複雑な現象の少なくとも一部を捉えていることを示しています。しかし、今回の課題は、どちらのタイプのモデルにとっても難しいものです。従来のモデルでは、単語埋め込みだけでは、感情のコンテクストをモデル化するのに十分な表現力が得られません。GRUはEMONET(Abdul-Mageed and Ungar, 2017)で良好な性能を示していますが、これは単に感情のlex- icons(§4.1)を記憶しているだけで、暗黙的な感情を捉えるための注目すべき戦略ではないと考えられます。それにもかかわらず、BERTは、約64％の平均的な精度しか得られていません。これは、将来の作業のために十分な余地を残しています。この目標に向けたステップとして、包括的なエラー分析を行います（§5.3）。</a><br><br><a id="r95" onmouseover="over('r95', 's95')" onmouseout="out('s95')">"より良い "事前学習済みのモデル（RoBERTaなど）は、必ずしも性能を助けない。GLUE（Wang et al., 2018）のような人気のあるベンチマークでは、事前学習を増やすと単調に性能が向上するのとは異なり、むしろ心強いことに、同じ傾向は見られません。RoBERTaの平均的な性能は、GRUよりも5％程度良いが、BERTよりもまだ6％程度悪い。我々は、この性能低下が、事前訓練と微調整のドメイン不一致に起因すると仮定しています。すなわち、RoBERTa の（追加の）事前訓練データ（例：CC-News）は、短いコンテキス トと独特の方言で知られる Twitter データとは距離がありすぎる可能性がある（Ritter et al.、2011）。後述するように（§6）、タスクに応じた事前学習を行わずに、最先端のモデルを適用することは避けるべきであると考えます。</a><br><br><a id="r96" onmouseover="over('r96', 's96')" onmouseout="out('s96')">5.3 エラー解析</a><br><br><a id="r97" onmouseover="over('r97', 's97')" onmouseout="out('s97')">BERT モデルを用いて、8 つの感情タスクからそれぞれ 25 個のテストエラーを抽出し、合計 200 個のエラーを得た。これらのエラーを以下のカテゴリーに分類しました：語彙および構文上の手掛かり（45%）、不十分な文脈（24%）、エンティティの言及（15%）、主観的なラベリング（10%）、理由不明（6%）。上位3つのカテゴリーについて以下に説明する。BERTは、ほとんどの感情予測モデルと同様に、予測を行うために、表面レベルの語彙的特徴に依存しています。この偏りは、句読点などの特定の構文的特徴にも及びます。pls be safe everyone!!!!」において、BERT は、感嘆符を pos- itive 感情と関連付けているが、ここでは、話者はより心配している。</a><br><br><a id="r98" onmouseover="over('r98', 's98')" onmouseout="out('s98')">コンテキストが不十分。ユーザーは、イベント、公共政策、またはリンクされたコンテンツについてコメントすることが多いが、 これらのコンテンツは、それ自体では超視覚的な学習のための特徴を備えていない。この種のエラーは、必ずしも BERT の欠点ではなく、むしろ我々のデータセットの欠点である。例えば、「for [tracy mcgrady]1, [hall induction]2 muted by effects of [hurricane harvey]3 at home」では、名詞句の間を推論し、潜在的な感情を見極めるために、外部の知識を使用しています。</a><br><br><a id="r99" onmouseover="over('r99', 's99')" onmouseout="out('s99')">エンティティ・メンション（Entity Mentions）。BERT は、特定の実体言及の存在下においても誤った予測を行う。例えば、BERTは、以下のツイートをAGGRESSIVENESSに分類する："NYTIMESWORLD: MEXICO offered aid to texas after harvey. ここでは、このユーザーは単に</a><br><br><a id="r100" onmouseover="over('r100', 's100')" onmouseout="out('s100')"> アグリ・オプティム・ラブ・エスビーエム・アウエー・ドスパー</a><br><br><a id="r101" onmouseover="over('r101', 's101')" onmouseout="out('s101')">RMR CNT AVG</a><br><br><a id="r102" onmouseover="over('r102', 's102')" onmouseout="out('s102')"> NO-PRETRAIN 67.6Supervised TransferEMONET 73.5 SENTIMENT 72.8Unsupervised TransferEMONET 72.1 SENTIMENT 69.1 HURRICANEEXT 73.6</a><br><br><a id="r103" onmouseover="over('r103', 's103')" onmouseout="out('s103')">75.0 54.0 67.4</a><br><br><a id="r104" onmouseover="over('r104', 's104')" onmouseout="out('s104')">75.2 55.2 68.8 75.8 62.7 71.0</a><br><br><a id="r105" onmouseover="over('r105', 's105')" onmouseout="out('s105')">75.1 54.0 61.0 74.9 53.6 66.2 75.4 69.8 68.9</a><br><br><a id="r106" onmouseover="over('r106', 's106')" onmouseout="out('s106')">68.3 55.7</a><br><br><a id="r107" onmouseover="over('r107', 's107')" onmouseout="out('s107')">67.5 53.1 65.6 53.4</a><br><br><a id="r108" onmouseover="over('r108', 's108')" onmouseout="out('s108')">65.1 54.2 67.3 54.3 69.7 57.9</a><br><br><a id="r109" onmouseover="over('r109', 's109')" onmouseout="out('s109')">58.5</a><br><br><a id="r110" onmouseover="over('r110', 's110')" onmouseout="out('s110')">66.8 64.1</a><br><br><a id="r111" onmouseover="over('r111', 's111')" onmouseout="out('s111')">71.7 65.6 67.3 65.7</a><br><br><a id="r112" onmouseover="over('r112', 's112')" onmouseout="out('s112')">69.4 63.9 64.4 63.5 70.2 68.2</a><br><br><a id="r113" onmouseover="over('r113', 's113')" onmouseout="out('s113')">   60.0 57.0 60.7 57.9 60.2</a><br><br><a id="r114" onmouseover="over('r114', 's114')" onmouseout="out('s114')"> 表6：タスクガイドによる事前トレーニングの精度（略語は表5に定義）。教師あり(中)、教師なし(下)の事前学習の順に表示。結果は，NO-PRETRAINを基準にして，青（↑）と赤（↓）で強調されている。カラーでの表示が最適。</a><br><br><a id="r115" onmouseover="over('r115', 's115')" onmouseout="out('s115')">BERT は、NY Times の談話に関する意見を形成するのではなく、ニュース文を作成しました。NY Times に対する感情は、我々のデータセット全体で否定的であるため（NY Times の記事に対す る世間の反発のため）、BERT は、この言及感情の偏りを利用していると考えられます。</a><br><br><a id="r116" onmouseover="over('r116', 's116')" onmouseout="out('s116')">6 タスクガイド付きプレトレーニング</a><br><br><a id="r117" onmouseover="over('r117', 's117')" onmouseout="out('s117')">ベースラインを改善するために、我々は、BERT モデルに暗黙的に破壊的なバイアスを組み込む手段とし て、事前訓練を検討している。我々は、これらの事前訓練作業により、BERT が Twitter ドメインにおいてより頑健になるだけでなく、 最終的な感情予測作業に有用な（抽象的ではあるが）知識を提供することを期待している。簡潔にするために、主に BERT に焦点を当てていますが、我々の方法は、他の事前訓練済みモデルにも一般化できます。</a><br><br><a id="r118" onmouseover="over('r118', 's118')" onmouseout="out('s118')">設定。我々は、教師ありと教師なしの事前訓練タスクを分離して探索します。教師ありの設定については、マルチクラスの感情タスク（EMONET）（Abdul-Mageed and Ungar, 2017）と、バイナリのセンチメント分析タスク（SENTIMENT）（Go et al. 教師なしの設定については、EMONET、SENTIMENT、HURRICANEEXTからの（ラベルのない）サンプルに対して、ダイナミック・マスクド・ランゲージ・モデリング（Liu et al.、2019）で事前学習を行う（§3.1）。どちらのタイプのタスクでも、さらにBERTを一定のエポック数で事前学習した後、HURRICANEEMOタスクで微調整を行う。これらの結果を、NO-PRETRAIN、すなわち、表5のBERTの結果と比較します。10回のプレトレーニング→ファインチューニングの平均性能を報告します。事前トレーニングタスクのサンプルサイズを含むトレーニングの詳細は、付録Dに記載されています。</a><br><br><a id="r119" onmouseover="over('r119', 's119')" onmouseout="out('s119')">結果です。表6にプレトレーニングの結果を示す。教師ありの事前トレーニングは、3-</a><br><br><a id="r120" onmouseover="over('r120', 's120')" onmouseout="out('s120')">4つの感情では、全体的なパフォーマンスが低下しますが、2-4つの感情では、全体的なパフォーマンスが低下します。我々は、SENTIMENTが予測性の高い特徴を持つ感情を補助すると考えています。例えば、"it's literally the size of texas. wtf "の "wtf "はAGGRESSIVENESSと相関がありますが、AWEのサンプルである "not all heros wear capes <3 thank you stanley - homeless #hurricane evacuee grooms lost pets "にはそのような語彙的な手がかりは存在しません。</a><br><br><a id="r121" onmouseover="over('r121', 's121')" onmouseout="out('s121')">また、教師なしの事前学習の結果からは、いくつかの傾向が見られます。まず、EMONETはダウンストリームのパフォーマンスを大きく低下させ、特に</a><br><br><a id="r122" onmouseover="over('r122', 's122')" onmouseout="out('s122')">提出物の精度は6%低下しました。次に、SENTI-MENT（ラベルなしの状態）では、目立った効果は得られませんでした。これは、感情情報の方がより価値があることを意味しますが、もちろん、感情タスクが元々の感情タスクと大きく一致しているという事実に左右されます。3つ目は、HURRICANEEXTによる事前学習の結果です。AGGRESSIVENESSとLOVEで最も顕著な結果が得られましたが、この目的により、教師付き事前学習が苦手なタスクの精度が+1-2%向上しました。</a><br><br><a id="r123" onmouseover="over('r123', 's123')" onmouseout="out('s123')">7 細粒度の教師なしドメインアダプテーション</a><br><br><a id="r124" onmouseover="over('r124', 's124')" onmouseout="out('s124')">新たな災害が発生した場合、先に述べたように（§2）、感情のアノテーションが得られない可能性があります。しかし，このようなアノテーションは，危機の際のユーザの感情プロファイルを理解しようとする組織にとって貴重なものとなるだろう(Fraustino et al., 2012)．このセクションでは、我々のハリケーンの感情データセットにラベルを提供する際に、大規模な感情データセット（例えば、EMONET（Abdul-Mageed and Un- gar, 2017））からのスーパービジョンを活用する方法を探ります。我々はこの問題を教師なしのドメイン適応とし、EMONETをラベル付きのソース・ドメインとし、我々のハリケーン・データセットをラベルなしのターゲット・ドメインとする。以下、詳しく説明します。</a><br><br><a id="r125" onmouseover="over('r125', 's125')" onmouseout="out('s125')"> アグリ・オプティム・ラブ・エスビーエム・アウエー・ドスパー</a><br><br><a id="r126" onmouseover="over('r126', 's126')" onmouseout="out('s126')">RMR CNT AVG</a><br><br><a id="r127" onmouseover="over('r127', 's127')" onmouseout="out('s127')"> src-onlypretrain-srcpretrain-trg pretrain-jointtrg-only</a><br><br><a id="r128" onmouseover="over('r128', 's128')" onmouseout="out('s128')">53.3 42.2</a><br><br><a id="r129" onmouseover="over('r129', 's129')" onmouseout="out('s129')">54.8 43.2 55.0 44.2 52.7 44.2</a><br><br><a id="r130" onmouseover="over('r130', 's130')" onmouseout="out('s130')">67.6 75.0</a><br><br><a id="r131" onmouseover="over('r131', 's131')" onmouseout="out('s131')">43.4 47.1</a><br><br><a id="r132" onmouseover="over('r132', 's132')" onmouseout="out('s132')">45.1 47.8 46.2 48.0 45.5 47.8</a><br><br><a id="r133" onmouseover="over('r133', 's133')" onmouseout="out('s133')">54.0 67.4</a><br><br><a id="r134" onmouseover="over('r134', 's134')" onmouseout="out('s134')">54.7 49.8</a><br><br><a id="r135" onmouseover="over('r135', 's135')" onmouseout="out('s135')">54.4 50.4 55.5 49.9 54.8 49.9</a><br><br><a id="r136" onmouseover="over('r136', 's136')" onmouseout="out('s136')">68.3 55.7</a><br><br><a id="r137" onmouseover="over('r137', 's137')" onmouseout="out('s137')">62.558.5</a><br><br><a id="r138" onmouseover="over('r138', 's138')" onmouseout="out('s138')">56.5 51.2</a><br><br><a id="r139" onmouseover="over('r139', 's139')" onmouseout="out('s139')">57.1 52.0 60.5 52.9 56.3 51.6</a><br><br><a id="r140" onmouseover="over('r140', 's140')" onmouseout="out('s140')">66.8 64.1</a><br><br><a id="r141" onmouseover="over('r141', 's141')" onmouseout="out('s141')">  63.3 63.7 61.6</a><br><br><a id="r142" onmouseover="over('r142', 's142')" onmouseout="out('s142')">  表7：教師なしドメイン適応の精度（略語は表5で定義）。結果はSRC-ONLYを基準に青（↑）と赤（↓）でハイライトされている。カラーでの表示が最適。</a><br><br><a id="r143" onmouseover="over('r143', 's143')" onmouseout="out('s143')">私たちの方法で</a><br><br><a id="r144" onmouseover="over('r144', 's144')" onmouseout="out('s144')">フレームワークです。EMONETはPlutchik-8の感情に対するマルチクラス分類タスクとして考案されました（Abdul-Mageed and Ungar, 2017）。これに対して、我々はPlutchik-8の感情ごとに1つずつのバイナリ分類タスクを導入します。EMONETのマルチクラスタスクを8つのバイナリタスクに分割します。これにより、各ソースドメインタスクとターゲットドメインタスクの間に1対1のアライメントが生まれます。各バイナリタスクに対して、教師なしのドメイン適応を個別に行います。</a><br><br><a id="r145" onmouseover="over('r145', 's145')" onmouseout="out('s145')">方法です。我々は、基礎となる分類器として、我々のBERTモデル（タスクガイド付き事前訓練なし）を使用する。Han and Eisenstein (2019) に倣い、異種のシステム間で効果的な移行を可能にする戦略的な事前学習技術の使用に主に焦点を当てている。比較対象となるシステムは以下の通りです。(1) SRC-オンリー。BERT は、ソース領域で訓練され、ターゲット領域で評価される。(2) TRG-ONLY：BERT は、目標行動領域において訓練および評価される。これらの結果は、表 5 からそのまま借用されている；（3）PRETRAIN-*。BERT は、ドメイン * のデータを使用した動的マスクド言語モデリングの事前訓練を受け、 ソースドメインで訓練され、最終的にターゲットドメインで評価される（Han and Eisenstein, 2019）。PRETRAIN-SRCはソースドメインからの事前訓練サンプルのみを使用し、PRETRAIN-TRGはタールゲットドメインからのサンプルのみを使用し、PRETRAIN-JOINTはソースドメインとターゲットドメインの両方からのサンプルを使用する7。</a><br><br><a id="r146" onmouseover="over('r146', 's146')" onmouseout="out('s146')">結果を示す。表 7 は、教師なしドメイン適応の結果を示しています。全体的に、SRC-ONLY のベースラインと比較して、有意なパフォーマンスの向上は見られませんでした。事前学習を行うことで、一貫して平均精度が+1%向上しますが、PRETRAIN-SRCとTRG-ONLYの間にはまだ大きなギャップがあります。Re-7PRETRAIN-JOINTは、Han and Eisenstein (2019)のADAPT- ABERTと概念的には似ていますが、事前学習データを動的に生成しています(Liu et al., 2019)。</a><br><br><a id="r147" onmouseover="over('r147', 's147')" onmouseout="out('s147')">ガーデニングをしない場合、いくつかの観察結果があります。1つ目は、AWE、DISAPPROVAL、.NETの3つの感情では、パフォーマンスが（相対的に）大きく向上していないことです。これらの感情は，ドメイン適応を可能にするために，より明示的な戦略が必要であると考えられる．このことは、タスクガイド付き事前トレーニングが（比較的）大きな利益をもたらさないという我々の以前の結果（§6）からも支持されている。次に、PRETRAIN-JOINTはPRETRAIN-SRCとPRETRAIN-TRGの両方よりも性能が悪い。これは、我々のエモーションタスクでは、複数のドメインを混合して事前トレーニングを行うことで、ターゲットドメインへのパラメータバイアスと比較して、よりノイズの多いトレーニング信号が得られることを意味しています。</a><br><br><a id="r148" onmouseover="over('r148', 's148')" onmouseout="out('s148')">8 結論</a><br><br><a id="r149" onmouseover="over('r149', 's149')" onmouseout="out('s149')">HURRICANEEMOは、複数のハリケーンから得られた15,000のツイートを対象とした、知覚された感情のアノテーション付きデータセットである。このデータセットでは、ツイートにPlutchik-24という細かな感情がアノテーションされており、そこから暗黙的・明示的な感情を分析し、Plutchik-8の2値分類タスクを構築する。このデータセットは、大規模な事前学習済みの言語モデルにとっても、難しいベンチマークであることが実証されています。このコードとデータセットは、災害中心の領域での研究を促進するための一歩として公開します。</a><br><br><a id="r150" onmouseover="over('r150', 's150')" onmouseout="out('s150')">謝辞</a><br><br><a id="r151" onmouseover="over('r151', 's151')" onmouseout="out('s151')">この原稿の初期版をレビューしてくださったKatrin Erk氏，マスクされた言語モデルの事前学習について議論してくださったYasumasa Onoe氏，そして有益なコメントをいただいた匿名の査読者の方々に感謝します．本研究は，NSF Grants IIS-1850153，IIS-1912887，IIS-1903963 の支援を受けて実施しました．</a><br><br><a id="r152" onmouseover="over('r152', 's152')" onmouseout="out('s152')">リファレンス</a><br><br><a id="r153" onmouseover="over('r153', 's153')" onmouseout="out('s153')">Muhammad Abdul-MageedとLyle Ungar。2017. エモネット。ゲーテッド・リカレント・ニューラル・ネットワークによるきめ細かな感情検出。論文集にて</a><br><br><a id="r154" onmouseover="over('r154', 's154')" onmouseout="out('s154')">  サブミッション</a><br><br><a id="r155" onmouseover="over('r155', 's155')" onmouseout="out('s155')">REMORSE</a><br><br><a id="r156" onmouseover="over('r156', 's156')" onmouseout="out('s156')">of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 718-728, Vancouver, Canada. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r157" onmouseover="over('r157', 's157')" onmouseout="out('s157')">Firoj Alam, Shafiq Joty, and Muhammad Imran. 2018. Adversarial Training and Graph EmbeddingsによるDomain Adaptation. In Proceedings of the 56th An-nual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1077- 1087, Melbourne, Australia. 計算言語学協会.</a><br><br><a id="r158" onmouseover="over('r158', 's158')" onmouseout="out('s158')">Saima AmanとStan Szpakowicz。2007. テキスト内の感情表現の識別". In Text, Speech and Dialogue, pages 196-205, Berlin, Heidelberg. Springer Berlin Heidelberg.</a><br><br><a id="r159" onmouseover="over('r159', 's159')" onmouseout="out('s159')">Ron Artstein, Massimo Poesio. 2008. 計算言語学のための Inter-coder Agreement. Compu-tational Linguistics, 34(4):555-596.</a><br><br><a id="r160" onmouseover="over('r160', 's160')" onmouseout="out('s160')">ジョナサン・ベルス 2017. 2017年大西洋ハリケーン・シーズンの総括。17 Moments We'll Never Forget. Weather.com.</a><br><br><a id="r161" onmouseover="over('r161', 's161')" onmouseout="out('s161')">Felipe Bravo-Marquez, Marcelo Mendoza, and Bar- bara Poblete. 2014. ビッグソーシャルデータ分析のためのメタレベルのセンチメントモデル. Knowledge-Based Systems, 69:86-99.</a><br><br><a id="r162" onmouseover="over('r162', 's162')" onmouseout="out('s162')">Cornelia Caragea, Adrian Silvescu, and Andrea H. Tapia. 2016. 畳み込みニューラルネットワークを用いた災害イベントにおける有益なメッセージの識別。In Proceedings of the 13th International Conference on Information Systems for Crisis Response and Management (ISCRAM).</a><br><br><a id="r163" onmouseover="over('r163', 's163')" onmouseout="out('s163')">Kyunghyun Cho, Bart van Merriënboer, Caglar Gul- cehre, Dzmitry Bahdanau, Fethi Bougares, Hol- ger Schwenk, and Yoshua Bengio. 2014. 統計的機械翻訳のためのRNNエンコーダー-デコーダーを用いたフレーズ表現の学習。2014年の自然言語処理における経験的手法（EMNLP）に関する会議の議事録、ページ1724-1734、ドーハ、カタール。Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r164" onmouseover="over('r164', 's164')" onmouseout="out('s164')">Michael Robert Dennis, Adrianne Kunkel, Gillian Woods, and Paul Schrodt. 2006. Making Sense of New Orleans Flood Trauma Recovery: 2006. Making Sense of New Orleans Flood Trauma Recovery: Ethics, Re-search Design, and Policy Considerations for Future Disasters. 社会問題と公共政策の分析』6(1):191-213.</a><br><br><a id="r165" onmouseover="over('r165', 's165')" onmouseout="out('s165')">Shrey Desai, Hongyuan Zhan, and Ahmed Aly. 2019. Distributional Shiftsの下での宝くじの評価（Evaluating Lottery Tickets under Distributional Shifts）。In Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019), pages 153-162, Hong Kong, China. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r166" onmouseover="over('r166', 's166')" onmouseout="out('s166')">Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Un- derstanding. In Proceedings of the 2019 Conferenceof the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.</a><br><br><a id="r167" onmouseover="over('r167', 's167')" onmouseout="out('s167')">ポール・エックマン 1992. 基本的な感情の論拠。Cognition and Emotion, 6(3-4):169-200.</a><br><br><a id="r168" onmouseover="over('r168', 's168')" onmouseout="out('s168')">Julia Daisy Fraustino, Brooke Fisher Liu, and Yan Xian Jin. 2012. 災害時のソーシャル・メディア利用。A Review of the Knowledge Base and Gaps. 2012年、「災害時におけるソーシャルメディアの利用：知識ベースとギャップのレビュー」（Na- tional Consortium for the Study of Terrorism and Re-sponses to Terrorism）。</a><br><br><a id="r169" onmouseover="over('r169', 's169')" onmouseout="out('s169')">チャールズ・フリッツとイーライ・マークス 1954. The NORC Studies of Human Behavior in Disaster（災害時の人間行動に関するNORC研究）．社会問題研究』10(3):26-41。</a><br><br><a id="r170" onmouseover="over('r170', 's170')" onmouseout="out('s170')">Jessica Fritze, Grant Blashki, Susie Burke, and John Wiseman. 2008. Hope, Despair and Transforma-tion: Hope, Despair and Transforma- tion: Climate Change and the Promotion of Men- tal Health and Wellbeing. International Journal of Mental Health Systems, 2(1):13.</a><br><br><a id="r171" onmouseover="over('r171', 's171')" onmouseout="out('s171')">Maria Giatsoglou, Manolis Vozalis, Konstantinos Dia- mantaras, Athena Vakali, George Sarigiannidis, and Konstantinos Chatzisavvas. 2017. Sentiment Anal- ysis Leveraging Emotions and Word Embeddings. Expert Systems with Applications, 69:214-224.</a><br><br><a id="r172" onmouseover="over('r172', 's172')" onmouseout="out('s172')">Alec Go, Richa Bhayani, and Lei Huang. 2009. Distant Supervisionを用いたTwitterセンチメント分類．Stanford University CS224N Project Report.</a><br><br><a id="r173" onmouseover="over('r173', 's173')" onmouseout="out('s173')">Xiaochuang HanとJacob Eisensteinです。2019. シーケンスラベリングのための文脈化されたエム・ベディングのUnsu-pervised Domain Adaptation of Contextualized Em-beddings. In Proceedings of the 2019 Conference on Empirical Methods in Nat- ural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 4237-4247, Hong Kong, China. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r174" onmouseover="over('r174', 's174')" onmouseout="out('s174')">Muhammad Imran, Carlos Castillo, Fernando Diaz, and Sarah Vieweg. 2015. 大規模な緊急事態におけるソーシャルメディアメッセージの処理。A Survey. Associ- ation for Computing Machinery (ACM) Computing Surveys, 47(4):67:1-67:38.</a><br><br><a id="r175" onmouseover="over('r175', 's175')" onmouseout="out('s175')">Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, and Patrick Meier. 2013. ソーシャルメディアから災害関連情報を実用的に抽出する。本論文では、このような問題を解決するための方法を紹介します。Association for Computing Machinery (ACM).</a><br><br><a id="r176" onmouseover="over('r176', 's176')" onmouseout="out('s176')">Muhammad Imran, Prasenjit Mitra, and Jaideep Srivas- tava. 2016. 危機関連のショートメッセージを分類するための言語間ドメイン適応。In 13th Proceedings of the International Conference on In- formation Systems for Crisis Response and Manage- ment, Rio de Janeiro, Brasil, May 22-25, 2016.</a><br><br><a id="r177" onmouseover="over('r177', 's177')" onmouseout="out('s177')">Mohit Iyyer, Varun Manjunatha, Jordan Boyd-Graber, and Hal Daumé III. 2015. Deep Unordered Com-position Rivals Syntactic Methods for Text Classi- fication. In Proceedings of the 53rd Annual Meet-ing of the Association for Computational Linguistics and the 7th International Joint Conference on Natu- ral Language Processing (Volume 1: Long Papers), pages 1681-1691, Beijing, China. Association for Computational Linguistics（計算言語学協会）.</a><br><br><a id="r178" onmouseover="over('r178', 's178')" onmouseout="out('s178')">Phil Katz, Matthew Singleton, and Richard Wicen- towski. 2007. SWAT-MP: SemEval-2007 タスク5とタスク14のためのシステム。このように、SemEval-2007では、タスク5とタスク14のためのシステムを構築した。</a><br><br><a id="r179" onmouseover="over('r179', 's179')" onmouseout="out('s179')">Hamed Khanpour、Cornelia Caragea。2018. 健康関連のオンライン投稿におけるきめ細かな感情検出。In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1160-1166, Brussels, Belgium. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r180" onmouseover="over('r180', 's180')" onmouseout="out('s180')">Yoon Kim. 2014. 文章分類のための畳み込みニューラルネットワーク．In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1746-1751, Doha, Qatar. 計算言語学協会.</a><br><br><a id="r181" onmouseover="over('r181', 's181')" onmouseout="out('s181')">ウォーレン・キンストン、レイチェル・ロッサー 1974. 災害。心身の状態への影響。精神医学研究、18(6):437-456。</a><br><br><a id="r182" onmouseover="over('r182', 's182')" onmouseout="out('s182')">Hongmin Li, Doina Caragea, and Cornelia Caragea. 2017. Towards Practical Usage of a Domain Adap-tation Algorithm in the Early Hours of a Disaster. In Proceedings of the 14th International Conference on Information Systems for Crisis Response and Man- agement (ISCRAM).</a><br><br><a id="r183" onmouseover="over('r183', 's183')" onmouseout="out('s183')">Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretrain-ing Approach. arXiv preprint arXiv:1907.11692.</a><br><br><a id="r184" onmouseover="over('r184', 's184')" onmouseout="out('s184')">Navonil Majumder, Soujanya Poria, Alexander Gel- bukh, and Erik Cambria. 2017. Deep Learning-Based Document Modeling for Personality Detec- tion from Text. IEEE Intelligent Systems, 32(2):74-79.</a><br><br><a id="r185" onmouseover="over('r185', 's185')" onmouseout="out('s185')">Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Cor- rado, and Jeffrey Dean. 2013. このような状況下では、単語やフレーズの分散型レプリーションとその位置関係が重要になります。本論文では、このようにして得られた情報をもとに、今後の研究の方向性を探る。Curran Associates Inc.</a><br><br><a id="r186" onmouseover="over('r186', 's186')" onmouseout="out('s186')">Saif Mohammad. 2012. #感情的なつぶやき。In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics - Volume 1: Proceedings of the main conference and the shared task, and Vol-ume 2: Proceedings of the Sixth International Work-shop on Semantic Evaluation (SemEval 2012), pages246-255, Montréal, Canada. 米国商業言語学会（Association for Com-putational Linguistics）。</a><br><br><a id="r187" onmouseover="over('r187', 's187')" onmouseout="out('s187')">Saif Mohammad、Svetlana Kiritchenko。2015. ハッシュタグを使ってツイートから細かい感情の分類を捉える。Computational Intelligence, 31(2):301-326.</a><br><br><a id="r188" onmouseover="over('r188', 's188')" onmouseout="out('s188')">Saif MohammadとPeter Turney。2013. 単語と感情の関連付け辞書のクラウドソース化。Compu-tational Intelligence, 29(3):436-465.</a><br><br><a id="r189" onmouseover="over('r189', 's189')" onmouseout="out('s189')">Dat Nguyen, Kamela Ali Al Mannai, Shafiq Joty, Has- san Sajjad, Muhammad Imran, and Prasenjit Mi- tra. 2017. 畳み込み式ニューラルネットワークを用いたソーシャルネットワーク上の危機関連データのロバストな分類。Web and Social Mediaに関する国際AAAI会議（ICWSM 2017）の議事録にて。</a><br><br><a id="r190" onmouseover="over('r190', 's190')" onmouseout="out('s190')">Emily Öhman、Kaisla Kajava、Jörg Tiedemann、Timo Honkela. 2018. Creating a Dataset for Multilingual Fine-grained Emotion-detection Using Gamification-based Annotation. In Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24-30, Brussels, Belgium. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r191" onmouseover="over('r191', 's191')" onmouseout="out('s191')">Leysia PalenとKenneth Anderson。2016. Crisis In-formatics-New Data for Extraordinary Times. Sci- ence, 353(6296):224-225.</a><br><br><a id="r192" onmouseover="over('r192', 's192')" onmouseout="out('s192')">レベッカ・パッソノー 2004. Coreference Annotationのための信頼性の計算。2004年には、言語資源協会(ELRA)が主催する「言語資源の信頼性に関する国際会議(LREC 2004)」が開催されました。ヨーロッパ言語資源協会（ELRA）。</a><br><br><a id="r193" onmouseover="over('r193', 's193')" onmouseout="out('s193')">Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Te- jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. 2019. PyTorch: An Imperative Style, High-Performance Deep Learn-ing Library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Álché-Buc, E. Fox, and R. Gar-nett, editors, Advances in Neural Information Pro-cessing Systems 32, pages 8024-8035. Curran Asso ciates, Inc.</a><br><br><a id="r194" onmouseover="over('r194', 's194')" onmouseout="out('s194')">Jeffrey Pennington, Richard Socher, and Christopher Manning. 2014. GloVe: Global Vectors for Word Representation. 2014年に開催された自然言語処理における経験的手法に関する会議（EMNLP）の議事録、ページ1532-1543、ドーハ、カタール。Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r195" onmouseover="over('r195', 's195')" onmouseout="out('s195')">Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke</a><br><br><a id="r196" onmouseover="over('r196', 's196')" onmouseout="out('s196')">ゼットルモイア 2018. Deep Contextualized Word Rep- resentations. In Proceedings of the 2018 Confer- ence of the North American Chapter of the Associ- ation for Computational Linguistics: Human Lan- guage Technologies, Volume 1 (Long Papers), pages 2227-2237, New Orleans, Louisiana. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r197" onmouseover="over('r197', 's197')" onmouseout="out('s197')">ロバート・プラーチク 2001. 感情の本質。この事実は、その複雑さを説明し、臨床のためのツールを提供するかもしれない。American Scientist, 89(4):344-350.</a><br><br><a id="r198" onmouseover="over('r198', 's198')" onmouseout="out('s198')">Jishnu Ray Chowdhury, Cornelia Caragea, and Doina Caragea. 2019. 災害関連ツイートからのキーフレーズ抽出。In The World Wide Web Confer- ence, WWW 2019, pages 1555-1566, New York, NY, USA. Association for Computing Machinery (ACM).</a><br><br><a id="r199" onmouseover="over('r199', 's199')" onmouseout="out('s199')">ハンナ・リッチーとマックス・ローザー 2020. Natural Disas- ters. データで見る私たちの世界。</a><br><br><a id="r200" onmouseover="over('r200', 's200')" onmouseout="out('s200')">Alan Ritter，Sam Clark，Mausam，Oren Etzioni．2011. ツイートにおける名前付きエンティティ認識．実証的研究. このようにして、自然言語処理における経験的手法に関する2011年の会議の議事録、ページ1524-1534、Edinburgh, Scotland, UK。計算言語学協会（Association for Computational Linguistics）。</a><br><br><a id="r201" onmouseover="over('r201', 's201')" onmouseout="out('s201')">Axel Schulz, Tung Dang Thanh, Heiko Paulheim, and Immanuel Schweizer. 2013. A Fine-Grained Sen-timent Analysis Approach for Detecting Crisis Re-lated Microposts. Information Systems for Crisis Response and Management (ISCRAM).</a><br><br><a id="r202" onmouseover="over('r202', 's202')" onmouseout="out('s202')">Carlo Strapparava、Rada Mihalcea。2007. SemEval-2007 タスク 14: Affective Text. このようにして得られた成果は、今後も継続していきます。計算言語学協会（Association for Computational Linguis- tics）。</a><br><br><a id="r203" onmouseover="over('r203', 's203')" onmouseout="out('s203')">Carlo Strapparava, Rada Mihalcea, and Alberto Battoc- chi. 2012. 感情が注釈された音楽と歌詞の並列コーパス。また、このようにして得られた成果は、今後の言語開発に活かされることでしょう。European Language Re-sources Association (ELRA).</a><br><br><a id="r204" onmouseover="over('r204', 's204')" onmouseout="out('s204')">Sudha Verma, Sarah Vieweg, William Corvey, Leysia Palen, James Martin, Martha Palmer, Aaron Schram, and Kenneth Anderson. 2011. Natural Language Processing to the Rescue? 大規模な緊急事態における「状況認識」ツイートの抽出。In Proceedings of the International AAAI Conference on Web and Social Media (ICWSM 2017).</a><br><br><a id="r205" onmouseover="over('r205', 's205')" onmouseout="out('s205')">スヴィトラーナ・ヴォルコヴァ、ヨーラム・バッハラーチ 2016. Inferring Perceived Demographics from User Emotional Tone and User-Environmental Emotional Contrast. In Pro- ceedings of the 54th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: LongPapers), pages 1567-1578, Berlin, Germany. 計算言語学協会.</a><br><br><a id="r206" onmouseover="over('r206', 's206')" onmouseout="out('s206')">Alex Wang, Amanpreet Singh, Julian Michael, Fe-lix Hill, Omer Levy, and Samuel Bowman. 2018. GLUE: A Multi-Task Benchmark and Analysis Plat-form for Natural Language Understanding. In Proceedings of the 2018 EMNLP Workshop Black- boxNLP: Analyzing and Interpreting Neural Net- works for NLP, pages 353-355, Brussels, Belgium. Association for Computational Linguistics（計算言語学協会）。</a><br><br><a id="r207" onmouseover="over('r207', 's207')" onmouseout="out('s207')">Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan, and Amit Sheth. 2012. Twitterの "ビッグデータ "を活用した感情の自動識別. 2012年に開催された「2012 ASE/IEEE International Con-ference on Social Computing and 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust, SOCIALCOM-PASSAT 2012」のPro-ceedings of the 2012 ASE/IEEE International Con-ference on Social Computing and 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust, pages 587-592, Washington, DC, USA. IEEE Computer Society.</a><br><br><a id="r208" onmouseover="over('r208', 's208')" onmouseout="out('s208')">Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, Rél'mi Louf, Morgan Funtow- icz, and Jamie Brew. 2019. HuggingFace's Trans-formers: Stat-of-the-art Natural Language Process-ing. arXiv preprint arXiv:1910.03771.</a><br><br><a id="r209" onmouseover="over('r209', 's209')" onmouseout="out('s209')">イアン・ウッド、ジョン・マクレー、ウラジミール・アンドリューシェチキン、ポール・ブイトラー。2018. A Comparison Of Emo-tion Annotation Schemes And A New Annotated Data Set（エモーションアノテーションスキームの比較と新しいアノテーションデータセット）。In Proceedings of the Eleventh Interna- tional Conference on Language Resources and Eval- uation (LREC 2018), Miyazaki, Japan. 欧州言語資源協会（ELRA）。</a><br><br><a id="r210" onmouseover="over('r210', 's210')" onmouseout="out('s210')"> 図4: EMONET（左）とHURRICANEEMO（右）のトップ1000（共通）ワードピース密度。デンシタイは、ワードピースの出現回数をカウントし、出現回数の合計で正規化することで算出される。</a><br><br><a id="r211" onmouseover="over('r211', 's211')" onmouseout="out('s211')">ドメインの移行</a><br><br><a id="r212" onmouseover="over('r212', 's212')" onmouseout="out('s212')">Desai et al. (2019)に概説されている方法論に従い、EMONETとHURRICANEEMOの語彙分布の間のJenson-Shannon Divergence (JSD)を用いてドメイン・ダイバージェンスを定量化する。JSDは0.199であり，Desai et al. (2019)で報告されたものよりも約1e5大きい。図4は、両ドメイン間の上位1000の共通語の密度を示している。コムモン単語集の中でも視覚的な違いが顕著であることから、入力分布に大きな食い違いがあることがわかります。</a><br><br><a id="r213" onmouseover="over('r213', 's213')" onmouseout="out('s213')">Bプラッチック・エモーション・アグリーメント</a><br><br><a id="r214" onmouseover="over('r214', 's214')" onmouseout="out('s214')">解釈可能なスケール PEAスコアに解釈可能な尺度を与えるために、ランダムに生成されたアノテーションと我々が得たアノテーションを比較します。ランダムなアノテーションを作成するプロセスを詳しく説明します。まず、ワーカーが1つのツイートに割り当てる感情の平均数を計算し、すべてのハリケーンについて3と評価します。次に、Plutchik-8ホイールからランダムな感情を3つ選び、5000件のアノテーションを作成します。図5は、この2種類のアノテーションを比較したものです。ランダムアノテーションのワーカーごとのPEAスコアは平均値（0.5）付近に集まりますが、これは大数の法則により予想されます。一方、我々のアノテーションのワーカーごとのPEAスコアは、右にシフトしており、ランダムベースラインよりも良い一致を示しています。したがって，我々のアノテーションは，PEA指標の下で「中程度の一致」を示していると解釈している．</a><br><br><a id="r215" onmouseover="over('r215', 's215')" onmouseout="out('s215')">人間による評価。3つのハリケーンすべてのワーカーのアノテーションを使用して、3人のワーカーのための2つの表記ペア、すなわち、A: (w1 , w2 ) および B: (w1,w3) を作成します（AとBはワーカーw1を共有します）。このフォーマットでは、A/B合計で73,418組のペアが貸し出されています。このプールから500組のA/Bペアをサンプリングし、各HITを10組で初期化し、HITごとに合計5人のワーカーを割り当てます。</a><br><br><a id="r216" onmouseover="over('r216', 's216')" onmouseout="out('s216')">C ベースラインモデリング</a><br><br><a id="r217" onmouseover="over('r217', 's217')" onmouseout="out('s217')">表 8 は、ハイパーパラメータを示しています。事前に訓練されたモデル（BERT および RoBERTa など）では、自己注意層でデフォルトのドロップアウト率（0.1） を使用していますが、最上位の線形層では追加のドロップアウトは使用していません。さらに、より大きなミニバッチでの学習を可能にするために、勾配累積を使用しています。</a><br><br><a id="r218" onmouseover="over('r218', 's218')" onmouseout="out('s218')">D タスクガイド付きプレトレーニング</a><br><br><a id="r219" onmouseover="over('r219', 's219')" onmouseout="out('s219')">マスクド言語モデリング。De-vlinら（2019）に倣い、マスクドランゲージモデリングタスクの予測対象として、入力の15％を無作為に一斉に選択する（[CLS]と[SEP]を除く）。対応する入力から、80%は[MASK]に、10%はランダムなトークンに、10%は元のトークンに設定されます。ただし、Liuら（2019）に倣って、事前学習データは静的にではなく動的に作成しています。これは単に、データをフィットさせるのが難しくなるため、収束時間が遅くなるだけです。バッチサイズを16、学習率を2e-5とし、10回のエポックで事前トレーニングデータの微調整を行います。事前訓練が終了したら、これらの重みで BERT モデルを初期化し、表 8 のハイパーパラメータを使用して、学習率 3e-5 で感情タスクで微調整を行います。</a><br><br><a id="r220" onmouseover="over('r220', 's220')" onmouseout="out('s220')">事前学習用コーパス 事前学習用コーパスは、シャッフルされたツイートx1, x2, - - , xnを[SEP]で区切って連結したものである。このコーパスは、512サイズのセグメントに分割され、それぞれに[CLS]が付加される。わかりやすくするために、トークン xi, - - , xj からなる各バッチは [CLS] xi [SEP] - - [SEP] xj [SEP] のように構成される。ここでは、2つの設計上の決定について詳しく説明します。1つ目は、各バッチの前に[CLS]を付けることで、各ツイートの前に付けるのと同様に、より良い結果を得ることができます。2つ目は、計算上の理由から、バラバラのツイートを同じバッチにまとめることです。</a><br><br><a id="r221" onmouseover="over('r221', 's221')" onmouseout="out('s221')">E Extended Pre-training Experiments E.1 EmoNet Binary Task Pre-training</a><br><br><a id="r222" onmouseover="over('r222', 's222')" onmouseout="out('s222')">セクション6では、EMONETのマルチクラス分類タスクで事前学習を行いました。本節では、きめ細かな事前学習スキームを紹介します。EMONETからPlutchik-8バイナリタスクを作成し、各感情モデルをそれぞれのHURRICANEEMOタスクで個別に微調整します。表9は</a><br><br><a id="r223" onmouseover="over('r223', 's223')" onmouseout="out('s223')">  図5：ランダムなアノテーション（上）と我々のアノテーション（下）のPEAスコア分布に対応するヒストグラム。</a><br><br><a id="r224" onmouseover="over('r224', 's224')" onmouseout="out('s224')">Logistic Reg. Word CNN Char CNN GRU BERT RoBERTa Epochs 5 5 5 5 3 3</a><br><br><a id="r225" onmouseover="over('r225', 's225')" onmouseout="out('s225')">  64 64 1e-4 1e-3 0 00 0.5</a><br><br><a id="r226" onmouseover="over('r226', 's226')" onmouseout="out('s226')">表8：ベースライン・モデリング実験（§5）のハイパーパラメータ。</a><br><br><a id="r227" onmouseover="over('r227', 's227')" onmouseout="out('s227')">Batch Size Learning Rate Weight Decay Dropout64 64 16 16 5e-5 1e-4 2e-5 2e-5 0 0 0 1e-3</a><br><br><a id="r228" onmouseover="over('r228', 's228')" onmouseout="out('s228')">0.7 0.7 -</a><br><br><a id="r229" onmouseover="over('r229', 's229')" onmouseout="out('s229')">- の結果を見てみましょう。EMONET-BINARYはEMONET-MULTIよりも著しく性能が悪く、平均的な精度を-2%低下させる結果となりました。したがって、マルチクラスの事前学習は、他の事前学習手法（マスクド・ランゲージ・モデリングなど）に比べてまだ効果的ではないものの、下流の評価に向けてより良い表現を作り出します。</a><br><br><a id="r230" onmouseover="over('r230', 's230')" onmouseout="out('s230')">E.2 事前学習データの量の変化</a><br><br><a id="r231" onmouseover="over('r231', 's231')" onmouseout="out('s231')">SENTIMENTとHURRICANEEXTのデータセットには、現在使用されているものよりもかなり多くのサンプルが含まれています。このセクションでは、様々な量の事前学習データがダウンストリームのHURRICANEEMOのパフォーマンスに与える影響を調査します。どちらの事前学習データセットも160万サンプルを使用しています。表10は，教師ありのSENTIMENTの結果を示している．表11と表12は、それぞれ教師なしのSENTIMENTとHURRICANEEXTの結果を示しています。どちらのタイプの事前学習タスクにおいても、事前学習データをより多く使用することによる特筆すべきメリットはありません。教師ありのSENTIMENTと教師なしのHURRICA-NEEXTの結果は、論文で報告している20万サンプルあたりで飽和してしまいました。特に、教師なしのHURRICANEEXTの事前学習の結果は、ラベル付きのデータがなくても、強力なダウンストリームの結果を得ることができることを示しており、説得力があります。最後に、教師なしのSENTI- M E N Tタスクでは、ほとんどの感情で利益が得られず、マスクされた言語のモデリングに使用するデータの種類が重要であることを示しています。並べて比較してみると、SENTIMENT サンプルは長さが短く、HURRICANEEXT サンプルはハリケーン特有のハッシュタグなど、より関連性の高いコンテンツを含んでいることがわかりました。</a><br><br><a id="r232" onmouseover="over('r232', 's232')" onmouseout="out('s232')"> アグリ・オプティム・ラブ・SBM・アウエー・ドスプ・RMR・Cnt・アベレージ</a><br><br><a id="r233" onmouseover="over('r233', 's233')" onmouseout="out('s233')"> ノープレトラインマルチバイナリー</a><br><br><a id="r234" onmouseover="over('r234', 's234')" onmouseout="out('s234')">67.6 75.0 54.0 67.4 68.3</a><br><br><a id="r235" onmouseover="over('r235', 's235')" onmouseout="out('s235')">73.5 75.2 55.2 68.8 67.5 67.7 74.9 53.7 64.7 67.5</a><br><br><a id="r236" onmouseover="over('r236', 's236')" onmouseout="out('s236')">55.7 58.5 66.8 64.1</a><br><br><a id="r237" onmouseover="over('r237', 's237')" onmouseout="out('s237')">53.1 71.7 65.6 54.5 63.6 62.8</a><br><br><a id="r238" onmouseover="over('r238', 's238')" onmouseout="out('s238')"> 60.055.8</a><br><br><a id="r239" onmouseover="over('r239', 's239')" onmouseout="out('s239')"> 表9：マルチクラスおよびバイナリのEMONETタスクを用いた事前学習。スタイリングの考慮点については表6を参照。</a><br><br><a id="r240" onmouseover="over('r240', 's240')" onmouseout="out('s240')"> AGR OPT LOV</a><br><br><a id="r241" onmouseover="over('r241', 's241')" onmouseout="out('s241')">67.6 75.0 54.0 67.4</a><br><br><a id="r242" onmouseover="over('r242', 's242')" onmouseout="out('s242')">RMR CNT AVG</a><br><br><a id="r243" onmouseover="over('r243', 's243')" onmouseout="out('s243')"> no-pretrain50k 100 k 200 k 400 k 800 ksbm awe dsp 68.3 55.7 67.1 51.358.5</a><br><br><a id="r244" onmouseover="over('r244', 's244')" onmouseout="out('s244')">66.8 64.1</a><br><br><a id="r245" onmouseover="over('r245', 's245')" onmouseout="out('s245')">  55.2 57.0 57.1 57.2 57.1 56.1</a><br><br><a id="r246" onmouseover="over('r246', 's246')" onmouseout="out('s246')">73.5 75.3 60.7 69.7</a><br><br><a id="r247" onmouseover="over('r247', 's247')" onmouseout="out('s247')">72.8 75.8 62.7 71.0 73.4 75.6 69.1 69.8 73.1 75.4 67.2 70.1 73.5 75.3 56.2 69.4 71.2 75.2 64.8 68.8</a><br><br><a id="r248" onmouseover="over('r248', 's248')" onmouseout="out('s248')">65.6 53.4 66.5 53.3 65.7 53.2 65.1 54.4 64.7 55.1</a><br><br><a id="r249" onmouseover="over('r249', 's249')" onmouseout="out('s249')">66.3 64.9 67.3 65.7 69.8 66.8 67.4 66.2 68.2 64.9 70.7 65.8</a><br><br><a id="r250" onmouseover="over('r250', 's250')" onmouseout="out('s250')">1600 K</a><br><br><a id="r251" onmouseover="over('r251', 's251')" onmouseout="out('s251')">表10：SENTIMENTの50-1600Kのラベル付きサンプルを使ったプレトレーニング。スタイリングの考慮点については表6を参照。</a><br><br><a id="r252" onmouseover="over('r252', 's252')" onmouseout="out('s252')">  AGR OPT LOV</a><br><br><a id="r253" onmouseover="over('r253', 's253')" onmouseout="out('s253')">67.6 75.0 54.0 67.4</a><br><br><a id="r254" onmouseover="over('r254', 's254')" onmouseout="out('s254')">RMR CNT AVG</a><br><br><a id="r255" onmouseover="over('r255', 's255')" onmouseout="out('s255')"> no-pretrain50k 100 k 200 k 400 k 800 k1600 ksbm awe dsp 68.3 55.7 67.0 53.958.5</a><br><br><a id="r256" onmouseover="over('r256', 's256')" onmouseout="out('s256')">66.8 64.1</a><br><br><a id="r257" onmouseover="over('r257', 's257')" onmouseout="out('s257')">65.8 64.0 62.3 63.8 64.4 63.5 64.5 64.5 63.4 64.0 65.0 64.0</a><br><br><a id="r258" onmouseover="over('r258', 's258')" onmouseout="out('s258')">  59.3 57.4 57.9 60.1 59.4 59.3</a><br><br><a id="r259" onmouseover="over('r259', 's259')" onmouseout="out('s259')">70.7 74.9 54.6 66.3</a><br><br><a id="r260" onmouseover="over('r260', 's260')" onmouseout="out('s260')">71.6 75.0 54.0 66.3 69.1 74.9 53.6 66.2 70.0 74.9 53.8 69.0 70.5 74.9 55.1 66.2 69.1 74.9 55.3 66.5</a><br><br><a id="r261" onmouseover="over('r261', 's261')" onmouseout="out('s261')">68.6 55.1 67.3 54.3 68.8 54.5 69.0 53.3 67.2 54.6</a><br><br><a id="r262" onmouseover="over('r262', 's262')" onmouseout="out('s262')"> 表11：SENTIMENTの50-1600Kのラベルなしサンプルを用いた事前学習。スタイリングについては、表6を参照してください。</a><br><br><a id="r263" onmouseover="over('r263', 's263')" onmouseout="out('s263')"> AGR OPT LOV</a><br><br><a id="r264" onmouseover="over('r264', 's264')" onmouseout="out('s264')">67.6 75.0 54.0 67.4</a><br><br><a id="r265" onmouseover="over('r265', 's265')" onmouseout="out('s265')">RMR CNT AVG</a><br><br><a id="r266" onmouseover="over('r266', 's266')" onmouseout="out('s266')"> no-pretrain50k 100 k 200 k 400 k 800 k1600 ksbm awe dsp 68.3 55.7 69.0 56.458.5</a><br><br><a id="r267" onmouseover="over('r267', 's267')" onmouseout="out('s267')">66.8 64.1</a><br><br><a id="r268" onmouseover="over('r268', 's268')" onmouseout="out('s268')">72.2 66.6 65.3 65.8 70.2 68.2 63.6 65.5 71.3 66.3 64.1 64.3</a><br><br><a id="r269" onmouseover="over('r269', 's269')" onmouseout="out('s269')">  60.4 62.4 60.2 60.7 60.3 61.0</a><br><br><a id="r270" onmouseover="over('r270', 's270')" onmouseout="out('s270')">72.7 75.0 60.0 67.2</a><br><br><a id="r271" onmouseover="over('r271', 's271')" onmouseout="out('s271')">71.8 75.1 57.4 69.1 73.6 75.4 69.8 68.9 71.4 75.2 59.7 69.7 71.4 75.3 58.9 69.4 73.3 75.7 50.7 68.3</a><br><br><a id="r272" onmouseover="over('r272', 's272')" onmouseout="out('s272')">70.3 55.2 69.7 57.9 68.8 55.2 69.6 54.0 65.5 55.8</a><br><br><a id="r273" onmouseover="over('r273', 's273')" onmouseout="out('s273')"> 表12：HURRICANEEXTの50-1600Kのラベル無しサンプルを用いた事前学習。スタイリングに関する考察は表6を参照。</a><br><br><a id="r274" onmouseover="over('r274', 's274')" onmouseout="out('s274')"> 図 6：Hurricane Irma のサンプルに対する BERT の自己言及の視覚化。特に、このヘッドは、エンティティ「ハリケーン・イルマ」、「フロリダ」、「みんな」、および動詞フレーズ「crane collapses」を捉えています。</a><br>
</div>
</div><style>
:root {
--main-text: #452b15;
--main-bg: #f8f1e2;
--highlight-text: #db8e3c;
}
:root[theme="dark"] {
--main-text: #b0b0b0;
--main-bg: #121212;
--highlight-text: #fd8787;
}
h1 {
color: var(--main-text);
}
input {
position: absolute;
top: 1%;
right: 1%;
}
#source {
width: 43%;
height: 90%;
padding: 0 2%;
float: left;
border-right:1px solid #ccc;
margin: 1%;
overflow: auto;
}
#result {
width: 43%;
height: 90%;
padding: 0 2%;
float: right;
margin: 1%;
overflow: auto;
}
a,
a:hover,
a:visited,
a:link,
a:active {
color: var(--main-text);
text-decoration: none;
}
body {
background-color: var(--main-bg);
}
</style>
<script>
var a = document.getElementsByTagName("a");
function over(s,o) {
var elements = document.getElementById(s);
var elemento = document.getElementById(o);
var rects = elements.getBoundingClientRect();
var recto = elemento.getBoundingClientRect();
var x = recto.left;
var y = recto.top - rects.top;
elemento.parentNode.scrollBy(x, y);
elemento.style.color = getComputedStyle(elemento).getPropertyValue("--highlight-text");
}
function out(e) {
document.getElementById(e).style.color = getComputedStyle(document.getElementById(e)).getPropertyValue("--main-text");
}
const btn = document.querySelector("#btn-mode");
btn.addEventListener("change", () => {
if (btn.checked == true) {
document.documentElement.setAttribute("theme", "dark");
} else {
document.documentElement.setAttribute("theme", "light");
}
for (var i = 0; i < a.length; i++) {
a[i].style.color = getComputedStyle(a[i]).getPropertyValue("--main-text");
}
});
</script>
</body>