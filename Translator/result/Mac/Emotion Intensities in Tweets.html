<meta charset="utf-8"/><h1 align="center">Emotion Intensities in Tweets</h1>
<input id="btn-mode" type="checkbox">
<hr>
<body>
<div class="parent">
<div id="source">
<br><a id="s0" onmouseover="over('s0', 'r0')" onmouseout="out('r0')">Saif M. Mohammad</a><br><br><a id="s1" onmouseover="over('s1', 'r1')" onmouseout="out('r1')">Information and Communications Technologies National Research Council Canada Ottawa, Canada saif.mohammad@nrc-cnrc.gc.ca</a><br><br><a id="s2" onmouseover="over('s2', 'r2')" onmouseout="out('r2')">Felipe Bravo-Marquez</a><br><br><a id="s3" onmouseover="over('s3', 'r3')" onmouseout="out('r3')">Department of Computer Science The University of Waikato Hamilton, New Zealand fbravoma@waikato.ac.nz</a><br><br><a id="s4" onmouseover="over('s4', 'r4')" onmouseout="out('r4')">Abstract</a><br><br><a id="s5" onmouseover="over('s5', 'r5')" onmouseout="out('r5')">This paper examines the task of detecting intensity of emotion from text. We cre- ate the first datasets of tweets annotated for anger, fear, joy, and sadness intensities. We use a technique called best–worst scal- ing (BWS) that improves annotation con- sistency and obtains reliable fine-grained scores. We show that emotion-word hash- tags often impact emotion intensity, usu- ally conveying a more intense emotion. Fi- nally, we create a benchmark regression system and conduct experiments to deter- mine: which features are useful for detect- ing emotion intensity; and, the extent to which two emotions are similar in terms of how they manifest in language.</a><br><br><a id="s6" onmouseover="over('s6', 'r6')" onmouseout="out('r6')">1 Introduction</a><br><br><a id="s7" onmouseover="over('s7', 'r7')" onmouseout="out('r7')">We use language to communicate not only the emotion we are feeling but also the intensity of the emotion. For example, our utterances can con- vey that we are very angry, slightly sad, absolutely elated, etc. Here, intensity refers to the degree or amount of an emotion such as anger or sad- ness.1 Natural language applications can benefit from knowing both the class of emotion and its intensity. For example, a commercial customer satisfaction system would prefer to focus first on instances of significant frustration or anger, as op- posed to instances of minor inconvenience. How- ever, most work on automatic emotion detection has focused on categorical classification (presence of anger, joy, sadness, etc.). A notable obstacle in developing automatic affect intensity systems is the lack of suitable annotated data. Existing af- fect datasets are predominantly categorical. Anno-1Intensity is different from arousal, which refers to the extent to which an emotion is calming or exciting.</a><br><br><a id="s8" onmouseover="over('s8', 'r8')" onmouseout="out('r8')">tating instances for degrees of affect is a substan- tially more difficult undertaking: respondents are presented with greater cognitive load and it is par- ticularly hard to ensure consistency (both across responses by different annotators and within the responses produced by an individual annotator).</a><br><br><a id="s9" onmouseover="over('s9', 'r9')" onmouseout="out('r9')">Best–Worst Scaling (BWS) is an annotation scheme that addresses these limitations (Louviere, 1991; Louviere et al., 2015; Kiritchenko and Mo- hammad, 2016, 2017). Annotators are given n items (an n-tuple, where n > 1 and commonly n = 4). They are asked which item is the best (highest in terms of the property of inter- est) and which is the worst (lowest in terms of the property of interest). When working on 4- tuples, best–worst annotations are particularly ef- ficient because each best and worst annotation will reveal the order of five of the six item pairs. For example, for a 4-tuple with items A, B, C, and D, if A is the best, and D is the worst, then A > B, A >C,A>D,B>D,andC>D.</a><br><br><a id="s10" onmouseover="over('s10', 'r10')" onmouseout="out('r10')">BWS annotations for a set of 4-tuples can be easily converted into real-valued scores of associ- ation between the items and the property of inter- est (Orme, 2009; Flynn and Marley, 2014). It has been empirically shown that annotations for 2N 4-tuples is sufficient for obtaining reliable scores (where N is the number of items) (Louviere, 1991; Kiritchenko and Mohammad, 2016).2 The lit- tle work using BWS in computational linguistics has focused on words (Jurgens et al., 2012; Kir- itchenko and Mohammad, 2016). It is unclear whether the approach can be scaled up to larger textual units such as sentences.</a><br><br><a id="s11" onmouseover="over('s11', 'r11')" onmouseout="out('r11')">Twitter has a large and diverse user base, which entails rich textual content, including non- standard language such as emoticons, emojis, cre-2At its limit, when n = 2, BWS becomes a paired com- parison (Thurstone, 1927; David, 1963), but then a much larger set of tuples need to be annotated (closer to N 2 ).</a><br><br><a id="s12" onmouseover="over('s12', 'r12')" onmouseout="out('r12')">Emotion Intensities in Tweets  arXiv:1708.03696v1 [cs.CL] 11 Aug 2017</a><br><br><a id="s13" onmouseover="over('s13', 'r13')" onmouseout="out('r13')">atively spelled words (happee), and hashtagged words (#luvumom). Tweets are often used to con- vey one’s emotions, opinions towards products, and stance over issues. Thus, automatically de- tecting emotion intensities in tweets has many ap- plications, including: tracking brand and product perception, tracking support for issues and poli- cies, tracking public health and well-being, and disaster/crisis management.</a><br><br><a id="s14" onmouseover="over('s14', 'r14')" onmouseout="out('r14')">In this paper, we present work on detecting intensities (or degrees) of emotion in tweets. Specifically, given a tweet and an emotion X, the goal is to determine the intensity or degree of emotion X felt by the speaker—a real-valued score between 0 and 1.3 A score of 1 means that the speaker feels the highest amount of emotion X. A score of 0 means that the speaker feels the lowest amount of emotion X. We annotate a dataset of tweets for intensity of emotion using best–worst scaling and crowdsourcing. The main contributions of this work are summarized below:</a><br><br><a id="s15" onmouseover="over('s15', 'r15')" onmouseout="out('r15')">• We formulate and develop the task of detecting emotion intensities in tweets.</a><br><br><a id="s16" onmouseover="over('s16', 'r16')" onmouseout="out('r16')">• We create four datasets of tweets annotated for intensity of anger, joy, sadness, and fear, respectively. These are the first of their kind.4</a><br><br><a id="s17" onmouseover="over('s17', 'r17')" onmouseout="out('r17')">• We show that Best–Worst Scaling can be suc- cessfully applied for annotating sentences (and not just words). We hope that this will encour- age the use of BWS more widely, producing more reliable natural language annotations.</a><br><br><a id="s18" onmouseover="over('s18', 'r18')" onmouseout="out('r18')">• We annotate both tweets and a hashtag-removed version of the tweets. We analyse the impact of hashtags on emotion intensity.</a><br><br><a id="s19" onmouseover="over('s19', 'r19')" onmouseout="out('r19')">• We create a regression system, AffectiveTweets Package, to automatically determine emotion intensity.5 We show the extent to which various features help determine emotion intensity. The system is released as an open-source package for the Weka workbench.</a><br><br><a id="s20" onmouseover="over('s20', 'r20')" onmouseout="out('r20')">• We conduct experiments to show the extent to which two emotions are similar as per their manifestation in language, by showing how predictive the features for one emotion are of another emotion’s intensity.</a><br><br><a id="s21" onmouseover="over('s21', 'r21')" onmouseout="out('r21')">3Identifying intensity of emotion evoked in the reader, or intensity of emotion felt by an entity mentioned in the tweet, are also useful, and left for future work.</a><br><br><a id="s22" onmouseover="over('s22', 'r22')" onmouseout="out('r22')">4We have also begun work on creating similar datasets annotated for other emotion categories. We are also creating a dataset annotated for valence, arousal, and dominance.</a><br><br><a id="s23" onmouseover="over('s23', 'r23')" onmouseout="out('r23')">5 https://github.com/felipebravom/AffectiveTweets</a><br><br><a id="s24" onmouseover="over('s24', 'r24')" onmouseout="out('r24')">• We provide data for a new shared task WASSA- 2017 Shared Task on Emotion Intensity.6 The competition is organized on a CodaLab website, where participants can upload their submis- sions, and the leaderboard reports the results.7 Twenty-two teams participated. A description of the task, details of participating systems, and results are available in Mohammad and Bravo-Marquez (2017).8</a><br><br><a id="s25" onmouseover="over('s25', 'r25')" onmouseout="out('r25')">All of the data, annotation questionnaires, evalua- tion scripts, regression code, and interactive visu- alizations of the data are made freely available on the shared task website.6</a><br><br><a id="s26" onmouseover="over('s26', 'r26')" onmouseout="out('r26')">2 Related Work</a><br><br><a id="s27" onmouseover="over('s27', 'r27')" onmouseout="out('r27')">Psychologists have argued that some emotions are more basic than others (Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988). However, they disagree on which emotions (and how many) should be classified as basic emotions—some pro- pose 6, some 8, some 20, and so on. Thus, most ef- forts in automatic emotion detection have focused on a handful of emotions, especially since manu- ally annotating text for a large number of emotions is arduous. Apart from these categorical models of emotions, certain dimensional models of emotion have also been proposed. The most popular among them, Russell’s circumplex model, asserts that all emotions are made up of two core dimensions: va- lence and arousal (Russell, 2003). In this paper, we describe work on four emotions that are the most common amongst the many proposals for ba- sic emotions: anger, fear, joy, and sadness. How- ever, we have also begun work on other affect cat- egories, as well as on valence and arousal.</a><br><br><a id="s28" onmouseover="over('s28', 'r28')" onmouseout="out('r28')">The vast majority of emotion annotation work provides discrete binary labels to the text instances (joy–nojoy, fear–nofear, and so on) (Alm et al., 2005; Aman and Szpakowicz, 2007; Brooks et al., 2013; Neviarouskaya et al., 2009; Bollen et al., 2009). The only annotation effort that provided scores for degree of emotion is by Strapparava and Mihalcea (2007) as part of one of the SemEval- 2007 shared task. Annotators were given newspa- per headlines and asked to provide scores between</a><br><br><a id="s29" onmouseover="over('s29', 'r29')" onmouseout="out('r29')">6 http://saifmohammad.com/WebPages/EmotionIntensity- SharedTask.html7 https://competitions.codalab.org/competitions/16380</a><br><br><a id="s30" onmouseover="over('s30', 'r30')" onmouseout="out('r30')">8Even though the 2017 WASSA shared task has con- cluded, the CodaLab competition website is kept open. Thus the best results obtained by any system on the 2017 test set can be found on the CodaLab leaderboard.</a><br><br><a id="s31" onmouseover="over('s31', 'r31')" onmouseout="out('r31')">0 and 100 via slide bars in a web interface. It is dif- ficult for humans to provide direct scores at such fine granularity. A common problem is inconsis- tency in annotations. One annotator might assign a score of 79 to a piece of text, whereas another an- notator may assign a score of 62 to the same text. It is also common that the same annotator assigns different scores to the same text instance at differ- ent points in time. Further, annotators often have a bias towards different parts of the scale, known as scale region bias.</a><br><br><a id="s32" onmouseover="over('s32', 'r32')" onmouseout="out('r32')">Best–Worst Scaling (BWS) was developed by Louviere (1991), building on some ground- breaking research in the 1960s in mathemati- cal psychology and psychophysics by Anthony A. J. Marley and Duncan Luce. Kiritchenko and Mohammad (2017) show through empiri- cal experiments that BWS produces more re- liable fine-grained scores than scores obtained using rating scales. Within the NLP commu- nity, Best–Worst Scaling (BWS) has thus far been used only to annotate words: for exam- ple, for creating datasets for relational similar- ity (Jurgens et al., 2012), word-sense disambigua- tion (Jurgens, 2013), word–sentiment intensity (Kiritchenko et al., 2014), and phrase sentiment composition (Kiritchenko and Mohammad, 2016). However, in this work we use BWS to annotate whole tweets for degree of emotion. With BWS we address the challenges of direct scoring, and produce more reliable emotion intensity scores. Further, this will be the first dataset with emotion scores for tweets.</a><br><br><a id="s33" onmouseover="over('s33', 'r33')" onmouseout="out('r33')">Automatic emotion classification has been pro- posed for many different kinds of texts, including tweets (Summa et al., 2016; Mohammad, 2012; Bollen et al., 2009; Aman and Szpakowicz, 2007; Brooks et al., 2013). However, there is little work on emotion regression other than the three submis- sions to the 2007 SemEval task (Strapparava and Mihalcea, 2007).</a><br><br><a id="s34" onmouseover="over('s34', 'r34')" onmouseout="out('r34')">3 Data</a><br><br><a id="s35" onmouseover="over('s35', 'r35')" onmouseout="out('r35')">For each of the four focus emotions, our goal was to create a dataset of tweets such that:</a><br><br><a id="s36" onmouseover="over('s36', 'r36')" onmouseout="out('r36')">• The tweets are associated with various intensi- ties (or degrees) of emotion.</a><br><br><a id="s37" onmouseover="over('s37', 'r37')" onmouseout="out('r37')">• Some tweets have words clearly indicative of the focus emotion and some tweets do not.</a><br><br><a id="s38" onmouseover="over('s38', 'r38')" onmouseout="out('r38')">A random collection of tweets is likely to have a large proportion of tweets not associated with thefocus emotion, and thus annotating all of them for intensity of emotion is sub-optimal. To create a dataset of tweets rich in a particular emotion, we use the following methodology.</a><br><br><a id="s39" onmouseover="over('s39', 'r39')" onmouseout="out('r39')">For each emotion X, we select 50 to 100 terms that are associated with that emotion at differ- ent intensity levels. For example, for the anger dataset, we use the terms: angry, mad, frustrated, annoyed, peeved, irritated, miffed, fury, antago- nism, and so on. For the sadness dataset, we use the terms: sad, devastated, sullen, down, crying, dejected, heartbroken, grief, weeping, and so on. We will refer to these terms as the query terms.</a><br><br><a id="s40" onmouseover="over('s40', 'r40')" onmouseout="out('r40')">We identified the query words for an emotion by first searching the Roget’s Thesaurus to find categories that had the focus emotion word (or a close synonym) as the head word.9 We chose all words listed within these categories to be the query terms for the corresponding focus emotion. We polled the Twitter API for tweets that included the query terms. We discarded retweets (tweets that start with RT) and tweets with urls. We created a subset of the remaining tweets by:</a><br><br><a id="s41" onmouseover="over('s41', 'r41')" onmouseout="out('r41')">• selecting at most 50 tweets per query term.</a><br><br><a id="s42" onmouseover="over('s42', 'r42')" onmouseout="out('r42')">• selecting at most 1 tweet for every tweeter–</a><br><br><a id="s43" onmouseover="over('s43', 'r43')" onmouseout="out('r43')">query term combination.</a><br><br><a id="s44" onmouseover="over('s44', 'r44')" onmouseout="out('r44')">Thus, the master set of tweets is not heavily skewed towards some tweeters or query terms.</a><br><br><a id="s45" onmouseover="over('s45', 'r45')" onmouseout="out('r45')">To study the impact of emotion word hashtags on the intensity of the whole tweet, we identified tweets that had a query term in hashtag form towards the end of the tweet—specifically, within the trailing portion of the tweet made up solely of hashtagged words. We created copies of these tweets and then removed the hashtag query terms from the copies. The updated tweets were then added to the master set. Finally, our master set of 7,097 tweets includes:</a><br><br><a id="s46" onmouseover="over('s46', 'r46')" onmouseout="out('r46')">1. Hashtag Query Term Tweets (HQT Tweets): 1030 tweets with a query term in the form of a hashtag (#<query term>) in the trailing portion of the tweet;</a><br><br><a id="s47" onmouseover="over('s47', 'r47')" onmouseout="out('r47')">2. No Query Term Tweets (NQT Tweets):</a><br><br><a id="s48" onmouseover="over('s48', 'r48')" onmouseout="out('r48')">1030 tweets that are copies of ‘1’, but with the hashtagged query term removed;</a><br><br><a id="s49" onmouseover="over('s49', 'r49')" onmouseout="out('r49')">9The Roget’s Thesaurus groups words into about 1000 categories. The head word is the word that best represents the meaning of the words within the category. The categories chosen were: 900 Resentment (for anger), 860 Fear (for fear), 836 Cheerfulness (for joy), and 837 Dejection (for sadness).</a><br><br><a id="s50" onmouseover="over('s50', 'r50')" onmouseout="out('r50')"> 3. Query Term Tweets (QT Tweets):5037 tweets that include:a. tweets that contain a query term in the form of a word (no #<query term>)b. tweets with a query term in hashtag form followed by at least one non-hashtag word.</a><br><br><a id="s51" onmouseover="over('s51', 'r51')" onmouseout="out('r51')">The master set of tweets was then manually an- notated for intensity of emotion. Table 1 shows a breakdown by emotion.</a><br><br><a id="s52" onmouseover="over('s52', 'r52')" onmouseout="out('r52')">3.1 Annotating with Best–Worst Scaling</a><br><br><a id="s53" onmouseover="over('s53', 'r53')" onmouseout="out('r53')">We followed the procedure described in Kir- itchenko and Mohammad (2016) to obtain BWS annotations. For each emotion, the annotators were presented with four tweets at a time (4- tuples) and asked to select the speakers of the tweets with the highest and lowest emotion inten- sity. 2 × N (where N is the number of tweets in the emotion set) distinct 4-tuples were randomly generated in such a manner that each item is seen in eight different 4-tuples, and no pair of items occurs in more than one 4-tuple. We will re- fer to this as random maximum-diversity selection (RMDS). RMDS maximizes the number of unique items that each item co-occurs with in the 4-tuples. After BWS annotations, this in turn leads to di- rect comparative ranking information for the max- imum number of pairs of items.10It is desirable for an item to occur in sets of 4- tuples such that the maximum intensities in those 4-tuples are spread across the range from low in- tensity to high intensity, as then the proportion of times an item is chosen as the best is indicative of its intensity score. Similarly, it is desirable for an item to occur in sets of 4-tuples such that the minimum intensities are spread from low to high intensity. However, since the intensities of items are not known beforehand, RMDS is used.</a><br><br><a id="s54" onmouseover="over('s54', 'r54')" onmouseout="out('r54')">Every 4-tuple was annotated by three indepen- dent annotators.11 The questionnaires used were developed through internal discussions and pilot</a><br><br><a id="s55" onmouseover="over('s55', 'r55')" onmouseout="out('r55')">10 In combinatorial mathematics, balanced incomplete block design refers to creating blocks (or tuples) of a handful items from a set of N items such that each item occurs in the same number of blocks (say x) and each pair of distinct items occurs in the same number of blocks (say y), where x and y are integers ge 1 (Yates, 1936). The set of tuples we create have similar properties, except that since we create only 2N tuples, pairs of distinct items either never occur together in a 4-tuple or they occur in exactly one 4-tuple.</a><br><br><a id="s56" onmouseover="over('s56', 'r56')" onmouseout="out('r56')">11Kiritchenko and Mohammad (2016) showed that using just three annotations per 4-tuple produces highly reliable re- sults. Note that since each tweet is seen in eight different 4-tuples, we obtain 8 × 3 = 24 judgments over each tweet.</a><br><br><a id="s57" onmouseover="over('s57', 'r57')" onmouseout="out('r57')">Emotion Train</a><br><br><a id="s58" onmouseover="over('s58', 'r58')" onmouseout="out('r58')">anger 857 fear 1147 joy 823 sadness 786 All 3613</a><br><br><a id="s59" onmouseover="over('s59', 'r59')" onmouseout="out('r59')">Dev. Test All</a><br><br><a id="s60" onmouseover="over('s60', 'r60')" onmouseout="out('r60')">84 760 1701 110 995 2252 74 714 1611 74 673 1533 342 3142 7097   Table 1: The number of instances in the Tweet Emotion Intensity dataset.</a><br><br><a id="s61" onmouseover="over('s61', 'r61')" onmouseout="out('r61')">annotations. A sample questionnaire is shown in the Appendix (A.1).</a><br><br><a id="s62" onmouseover="over('s62', 'r62')" onmouseout="out('r62')">The 4-tuples of tweets were uploaded on the crowdsourcing platform, CrowdFlower. About 5% of the data was annotated internally before- hand (by the authors). These questions are referred to as gold questions. The gold questions are inter- spersed with other questions. If one gets a gold question wrong, they are immediately notified of it. If one’s accuracy on the gold questions falls be- low 70%, they are refused further annotation, and all of their annotations are discarded. This serves as a mechanism to avoid malicious annotations.12The BWS responses were translated into scores by a simple calculation (Orme, 2009; Flynn and Marley, 2014): For each item, the score is the per- centage of times the item was chosen as having the most intensity minus the percentage of times the item was chosen as having the least intensity.13 The scores range from −1 to 1. Since degree of emotion is a unipolar scale, we linearly transform the the −1 to 1 scores to scores in the range 0 to 1.</a><br><br><a id="s63" onmouseover="over('s63', 'r63')" onmouseout="out('r63')">3.2 Training, Development, and Test Sets</a><br><br><a id="s64" onmouseover="over('s64', 'r64')" onmouseout="out('r64')">We refer to the newly created emotion-intensity la- beled data as the Tweet Emotion Intensity Dataset. The dataset is partitioned into training, develop- ment, and test sets for machine learning experi- ments (see Table 1). For each emotion, we chose to include about 50% of the tweets in the training set, about 5% in the development set, and about 45% in the test set. Further, we made sure that an NQT tweet is in the same partition as the HQT tweet it was created from. See Appendix (A.4) for details of an interactive visualization of the data.</a><br><br><a id="s65" onmouseover="over('s65', 'r65')" onmouseout="out('r65')">12In case more than one item can be reasonably chosen as the best (or worst) item, then more than one acceptable gold answers are provided. The goal with the gold annotations is to identify clearly poor or malicious annotators. In case where two items are close in intensity, we want the crowd of annotators to indicate, through their BWS annotations, the relative ranking of the items.</a><br><br><a id="s66" onmouseover="over('s66', 'r66')" onmouseout="out('r66')">13 Kiritchenko and Mohammad (2016) provide code for generating tuples from items using RMDS, as well as code for generating scores from BWS annotations: http://saifmohammad.com/WebPages/BestWorst.html</a><br><br><a id="s67" onmouseover="over('s67', 'r67')" onmouseout="out('r67')"> 4 Reliability of Annotations</a><br><br><a id="s68" onmouseover="over('s68', 'r68')" onmouseout="out('r68')">One cannot use standard inter-annotator agree- ment measures to determine quality of BWS anno- tations because the disagreement that arises when a tuple has two items that are close in emotion in- tensity is a useful signal for BWS. For a given 4- tuple, if respondents are not able to consistently identify the tweet that has highest (or lowest) emo- tion intensity, then the disagreement will lead to the two tweets obtaining scores that are close to each other, which is the desired outcome. Thus a different measure of quality of annotations must be utilized.</a><br><br><a id="s69" onmouseover="over('s69', 'r69')" onmouseout="out('r69')">A useful measure of quality is reproducibility of the end result—if repeated independent man- ual annotations from multiple respondents result in similar intensity rankings (and scores), then one can be confident that the scores capture the true emotion intensities. To assess this reproducibility, we calculate average split-half reliability (SHR), a commonly used approach to determine consis- tency (Kuder and Richardson, 1937; Cronbach, 1946). The intuition behind SHR is as follows. All annotations for an item (in our case, tuples) are randomly split into two halves. Two sets of scores are produced independently from the two halves. Then the correlation between the two sets of scores is calculated. If the annotations are of good quality, then the correlation between the two halves will be high.</a><br><br><a id="s70" onmouseover="over('s70', 'r70')" onmouseout="out('r70')">Since each tuple in this dataset was annotated by three annotators (odd number), we calculate SHR by randomly placing one or two annotations per tuple in one bin and the remaining (two or one) annotations for the tuple in another bin. Then two sets of intensity scores (and rankings) are calcu- lated from the annotations in each of the two bins. The process is repeated 100 times and the correla- tions across the two sets of rankings and intensity scores are averaged. Table 2 shows the split-half reliabilities for the anger, fear, joy, and sadness tweets in the Tweet Emotion Intensity Dataset.14 Observe that for fear, joy, and sadness datasets, both the Pearson correlations and the Spearman rank correlations lie between 0.84 and 0.88, indi- cating a high degree of reproducibility. However,14Past work has found the SHR for sentiment intensity an- notations for words, with 8 annotations per tuple, to be 0.98 (Kiritchenko et al., 2014). In contrast, here SHR is calculated from 3 annotations, for emotions, and from whole sentences. SHR determined from a smaller number of annotations and on more complex annotation tasks are expected to be lower.</a><br><br><a id="s71" onmouseover="over('s71', 'r71')" onmouseout="out('r71')">Emotion Spearman Pearson anger 0.779 fear 0.845 joy 0.881 sadness 0.847</a><br><br><a id="s72" onmouseover="over('s72', 'r72')" onmouseout="out('r72')">0.797 0.850 0.882 0.847</a><br><br><a id="s73" onmouseover="over('s73', 'r73')" onmouseout="out('r73')"> Table 2:</a><br><br><a id="s74" onmouseover="over('s74', 'r74')" onmouseout="out('r74')">Pearson correlation and Spearman rank correla- tion) for the anger, fear, joy, and sadness tweets in the Tweet Emotion Intensity Dataset.</a><br><br><a id="s75" onmouseover="over('s75', 'r75')" onmouseout="out('r75')">the correlations are slightly lower for anger indi- cating that it is relative more difficult to ascertain the degrees of anger of speakers from their tweets. Note that SHR indicates the quality of annotations obtained when using only half the number of an- notations. The correlations obtained when repeat- ing the experiment with three annotations for each 4-tuple is expected to be even higher. Thus the numbers shown in Table 2 are a lower bound on the quality of annotations obtained with three an- notations per 4-tuple.</a><br><br><a id="s76" onmouseover="over('s76', 'r76')" onmouseout="out('r76')">5 Impact of Emotion Word Hashtags on Emotion Intensity</a><br><br><a id="s77" onmouseover="over('s77', 'r77')" onmouseout="out('r77')">Some studies have shown that emoticons tend to be redundant in terms of the sentiment (Go et al., 2009; Mohammad et al., 2013). That is, if we remove a smiley face, ‘:)’, from a tweet, we find that the rest of the tweet still conveys a positive sentiment. Similarly, it has been shown that hashtag emotion words are also somewhat redundant in terms of the class of emotion being conveyed by the rest of the tweet (Mohammad, 2012). For example, removal of ‘#angry’ from the tweet below leaves a tweet that still conveys anger.</a><br><br><a id="s78" onmouseover="over('s78', 'r78')" onmouseout="out('r78')">This mindless support of a demagogue needs to stop. #racism #grrr #angry</a><br><br><a id="s79" onmouseover="over('s79', 'r79')" onmouseout="out('r79')">However, it is unclear what impact such emotion word hashtags have on the intensity of emotion. In fact, there exists no prior work to systematically study this. One of the goals of creating this dataset and including HQT–NQT tweet pairs, is to allow for exactly such an investigation.15We analyzed the scores in our dataset to cre- ate scatter plots where each point corresponds to a HQT–NQT tweet pair, the x-axis is the emotion intensity score of the HQT tweet, and the y-axis is the score of the NQT tweet. Figure 1 shows the scatter plot for the fear data. We observe that15See Appendix (A.2) for further discussion on how emo- tion word hashtags have been used in prior research.</a><br><br><a id="s80" onmouseover="over('s80', 'r80')" onmouseout="out('r80')">Split-half reliabilities (as measured by</a><br><br><a id="s81" onmouseover="over('s81', 'r81')" onmouseout="out('r81')"> No. of HQT–NQT Emotion Tweet Pairs anger 282 fear 454 joy 204 sadness 90 All 1030</a><br><br><a id="s82" onmouseover="over('s82', 'r82')" onmouseout="out('r82')">% Tweets Pairs</a><br><br><a id="s83" onmouseover="over('s83', 'r83')" onmouseout="out('r83')">Drop Rise None 76.6 19.9 3.4 86.1 13.9 4.4 71.6 26.5 1.9 85.6 11,1 3.3 78.6 17.8 3.6Average Emotion Intensity ScoreHQT tweets 0.58 0.57 0.59 0.65 0.58NQT tweets 0.48 0.43 0.50 0.49 0.47Drop Rise 0.15 0.07 0.18 0.07 0.15 0.09 0.19 0.05 0.17 0.08   Table3: Theimpactofremovalofemotionwordhashtagsontheemotionintensitiesoftweets.</a><br><br><a id="s84" onmouseover="over('s84', 'r84')" onmouseout="out('r84')"> Figure 1: The scatter plot of fear intensity of HQT tweet vs. corresponding NQT tweet. As per space availability, some points are labeled with the rele- vant hashtag.</a><br><br><a id="s85" onmouseover="over('s85', 'r85')" onmouseout="out('r85')">in a majority of the cases, the points are on the lower-right side of the diagonal, indicating that the removal of the emotion word hashtag causes the emotion intensity of the tweet to drop. However, we do see a number of points on the upper-left side of the diagonal (indicating a rise), and some ex- actly on the diagonal (indicating no impact), due to the removal of a hashtag. Also observe that the removal of a hashtag can result in a drop in emo- tion scores for some tweets, but a rise for others (e.g., see the three labeled points for #nervous in the plot). We observe a similar pattern for other emotions as well (plots not shown here). Table 3 summarizes these results by showing the percent- age of times the three outcomes occur for each of the emotions.</a><br><br><a id="s86" onmouseover="over('s86', 'r86')" onmouseout="out('r86')">The table also shows that the average scores of HQT tweets and NQT tweets. The difference be- tween 0.58 and 0.47 is statistically significant.16 The last two columns show that when there is a drop in score on removal of the hashtag, the aver-16Wilcoxon signed-rank test at 0.05 significance level.</a><br><br><a id="s87" onmouseover="over('s87', 'r87')" onmouseout="out('r87')">age drop is about 0.17 (17% of the total range 0– 1), whereas when there is a rise, the average rise is 0.08 (8% of the total range). These results show that emotion word hashtags are often not redun- dant with the rest of tweet in terms of what they bring to bear at the overall emotion intensity. Fur- ther, even though it is common for many of these hashtags to increase the emotion intensity, there is a more complex interplay between the text of the tweet and the hashtag which determines the di- rectionality and magnitude of the impact on emo- tion intensity. For instance, we often found that if the rest of the tweet clearly indicated the pres- ence of an emotion (through another emotion word hashtag, emojis, or through the non-hashtagged words), then the emotion word hashtag had only a small impact on the score.17However, if the rest of the tweet is under- specified in terms of the emotion of the speaker, then the emotion word hashtag markedly in- creased the perceived emotion intensity. We also observed patterns unique to particular emotions. For example, when judging degree of fear of a speaker, lower scores were assigned when the speaker used a hashtag that indicated some outward judgment.</a><br><br><a id="s88" onmouseover="over('s88', 'r88')" onmouseout="out('r88')">@RocksNRopes Can’t believe how rude your cashier was. fear: 0.48@RocksNRopes Can’t believe how rude your cashier was. #terrible fear: 0.31</a><br><br><a id="s89" onmouseover="over('s89', 'r89')" onmouseout="out('r89')">We believe that not vocalizing an outward judg- ment of the situation made the speaker appear more fearful. The HQT–NQT subset of our dataset will also be made separately, and freely, available as it may be of interest on its own, especially for the psychology and social sciences communities.</a><br><br><a id="s90" onmouseover="over('s90', 'r90')" onmouseout="out('r90')">17Unless the hashtag word itself is associated with very low emotion intensity (e.g., #peeved with anger), in which case, there was a drop in perceived emotion intensity.</a><br><br><a id="s91" onmouseover="over('s91', 'r91')" onmouseout="out('r91')"> Twitter Annotation</a><br><br><a id="s92" onmouseover="over('s92', 'r92')" onmouseout="out('r92')">Scope Sentiment Sentiment Sentiment Emotions Emotions Emotions EmotionsSentiment Sentiment Sentiment SentimentLabel Numeric Nominal Nominal Numeric Nominal Numeric NumericNumeric Numeric Numeric Numeric</a><br><br><a id="s93" onmouseover="over('s93', 'r93')" onmouseout="out('r93')"> AFINN (Nielsen, 2011) Yes BingLiu (Hu and Liu, 2004) No MPQA (Wilson et al., 2005) No NRC Affect Intensity Lexicon (NRC-Aff-Int) (Mohammad, 2017) Yes NRC Word-Emotion Assn. Lexicon (NRC-EmoLex) (Mohammad and Turney, 2013) No NRC10 Expanded (NRC10E) (Bravo-Marquez et al., 2016) Yes NRC Hashtag Emotion Association Lexicon (NRC-Hash-Emo) Yes</a><br><br><a id="s94" onmouseover="over('s94', 'r94')" onmouseout="out('r94')">(Mohammad and Kiritchenko, 2015)</a><br><br><a id="s95" onmouseover="over('s95', 'r95')" onmouseout="out('r95')">NRC Hashtag Sentiment Lexicon (NRC-Hash-Sent) (Mohammad et al., 2013) Yes Sentiment140 (Mohammad et al., 2013) Yes SentiWordNet (Esuli and Sebastiani, 2006) No SentiStrength (Thelwall et al., 2012) YesManual Manual Manual Manual Manual Automatic AutomaticAutomatic Automatic Automatic Manual 6 Automatically Determining Tweet Emotion IntensityWe now describe our regression system, which we use for obtaining benchmark prediction results on the new Tweet Emotion Intensity Dataset (Section 6.1) and for determining the extent to which two emotions are correlated (Section 6.2).</a><br><br><a id="s96" onmouseover="over('s96', 'r96')" onmouseout="out('r96')">Regression System We implemented a pack- age called AffectiveTweets for the Weka machine learning workbench (Hall et al., 2009) that pro- vides a collection of filters for extracting state-of- the-art features from tweets for sentiment classifi- cation and other related tasks. These include fea- tures used in Kiritchenko et al. (2014) and Mo- hammad et al. (2017).18 We use the package for calculating feature vectors from our emotion- intensity-labeled tweets and train Weka regression models on this transformed data. We used an L2- regularized L2 -loss SVM regression model with the regularization parameter C set to 1, imple- mented in LIBLINEAR19. The features used:20a. Word N-grams (WN): presence or absence of word n-grams from n = 1 to n = 4.</a><br><br><a id="s97" onmouseover="over('s97', 'r97')" onmouseout="out('r97')">b. Character N-grams (CN): presence or absence of character n-grams from n = 3 to n = 5.</a><br><br><a id="s98" onmouseover="over('s98', 'r98')" onmouseout="out('r98')">c. Word Embeddings (WE): an average of the word embeddings of all the words in a tweet. We calculate individual word embeddings using the negative sampling skip-gram model implemented in Word2Vec (Mikolov et al., 2013). Word vectors are trained from ten million English tweets taken from the Edinburgh Twitter Corpus (Petrovic ́ et al., 2010). We set Word2Vec parameters:18Kiritchenko et al. (2014) describes the NRC-Canada system which ranked first in three sentiment shared tasks: SemEval-2013 Task 2, SemEval-2014 Task 9, and SemEval- 2014 Task 4. Mohammad et al. (2017) describes a stance- detection system that outperformed submissions from all 19 teams that participated in SemEval-2016 Task 6.</a><br><br><a id="s99" onmouseover="over('s99', 'r99')" onmouseout="out('r99')">19 http://www.csie.ntu.edu.tw/∼cjlin/liblinear/20See Appendix (A.3) for further implementation details.</a><br><br><a id="s100" onmouseover="over('s100', 'r100')" onmouseout="out('r100')">window size: 5; number of dimensions: 400.21d. Affect Lexicons (L): we use the lexicons shown in Table 4, by aggregating the information for all the words in a tweet. If the lexicon provides nominal association labels (e.g, positive, anger, etc.), then the number of words in the tweet matching each class are counted. If the lexicon provides numerical scores, the individual scores for each class are summed. These resources differ according to: whether the lexicon includes Twitter-specific terms, whether the words were manually or automatically annotated, whether the words were annotated for sentiment or emotions, and whether the affective associations provided are nominal or numeric. (See Table 4.)Evaluation We calculate the Pearson correla- tion coefficient (r) between the scores produced by the automatic system on the test sets and the gold intensity scores to determine the extent to which the output of the system matches the re- sults of human annotation.22 Pearson coefficient, which measures linear correlations between two variables, produces scores from -1 (perfectly in- versely correlated) to 1 (perfectly correlated). A score of 0 indicates no correlation.</a><br><br><a id="s101" onmouseover="over('s101', 'r101')" onmouseout="out('r101')">6.1 Supervised Regression and Ablation</a><br><br><a id="s102" onmouseover="over('s102', 'r102')" onmouseout="out('r102')">We developed our system by training on the offi- cial training sets and applying the learned models to the development sets. Once system parameters were frozen, the system trained on the combined training and development corpora. These models were applied to the official test sets. Table 5 shows the results obtained on the test sets using various features, individually and in combination. The last column ‘avg.’ shows the macro-average of the cor- relations for all of the emotions.</a><br><br><a id="s103" onmouseover="over('s103', 'r103')" onmouseout="out('r103')">21Optimized for the task of word–emotion classification on an independent dataset (Bravo-Marquez et al., 2016).</a><br><br><a id="s104" onmouseover="over('s104', 'r104')" onmouseout="out('r104')">22We also determined Spearman rank correlations but these were inline with the results obtained using Pearson.</a><br><br><a id="s105" onmouseover="over('s105', 'r105')" onmouseout="out('r105')">Table 4: Affect lexicons used in our experiments.</a><br><br><a id="s106" onmouseover="over('s106', 'r106')" onmouseout="out('r106')"> anger fear joysad. avg.</a><br><br><a id="s107" onmouseover="over('s107', 'r107')" onmouseout="out('r107')">0.49 0.48 0.49 0.48 0.60 0.55 0.68 0.63</a><br><br><a id="s108" onmouseover="over('s108', 'r108')" onmouseout="out('r108')">0.28 0.36 0.23 0.31 0.12 0.20 0.32 0.30 0.23 0.26 0.37 0.37 0.54 0.53 0.39 0.34 0.48 0.41 0.16 0.19 0.61 0.46</a><br><br><a id="s109" onmouseover="over('s109', 'r109')" onmouseout="out('r109')">0.49 0.48 0.63 0.61 0.71 0.66 0.65 0.65 0.63 0.62 0.63 0.62</a><br><br><a id="s110" onmouseover="over('s110', 'r110')" onmouseout="out('r110')">Among the lexicons, NRC-Hash-Emo is the most predictive single lexicon. Lexicons that in- clude Twitter-specific entries, lexicons that in- clude intensity scores, and lexicons that label emotions and not just sentiment, tend to be more predictive on this task–dataset combination. NRC-Aff-Int has real-valued fine-grained word– emotion association scores for all the words in NRC-EmoLex that were marked as being associ- ated with anger, fear, joy, and sadness.25 Improve- ment in scores obtained using NRC-Aff-Int over the scores obtained using NRC-EmoLex also show that using fine intensity scores of word-emotion association are beneficial for tweet-level emotion intensity detection. The correlations for anger, fear, and joy are similar (around 0.65), but the cor- relation for sadness is markedly higher (0.71). We can observe from Table 5 that this boost in perfor- mance for sadness is to some extent due to word embeddings, but is more so due to lexicon fea- tures, especially those from SentiStrength. Sen- tiStrength focuses solely on positive and negative classes, but provides numeric scores for each.</a><br><br><a id="s111" onmouseover="over('s111', 'r111')" onmouseout="out('r111')">6.1.1 Moderate-to-High Intensity Prediction</a><br><br><a id="s112" onmouseover="over('s112', 'r112')" onmouseout="out('r112')">In some applications, it may be more important for a system to correctly determine emotion inten- sities in the higher range of the scale than in the lower range of the scale. To assess performance in the moderate-to-high range of the intensity scale, we calculated correlation scores over a subset of the test data formed by taking only those instances with gold emotion intensity scores ≥ 0.5.</a><br><br><a id="s113" onmouseover="over('s113', 'r113')" onmouseout="out('r113')">Table 6 shows the results. Firstly, the correla- tion scores are in general lower here in the 0.5 to 1 range of intensity scores than in the experi- ments over the full intensity range. This is sim- ply because this is a harder task as now the sys- tems do not benefit by making coarse distinctions over whether a tweet is in the lower range or in the higher range. Nonetheless, we observe that many of the broad patterns of results stay the same, with some differences. Lexicons still play a crucial role, however, now embeddings and word ngrams are not far behind. SentiStrength seems to be less useful in this range, suggesting that its main bene- fit was separating low- and high-intensity sadness words. NRC-Hash-Emo is still the source of the most predictive lexicon features.</a><br><br><a id="s114" onmouseover="over('s114', 'r114')" onmouseout="out('r114')">25 http://saifmohammad.com/WebPages/AffectIntensity.htm</a><br><br><a id="s115" onmouseover="over('s115', 'r115')" onmouseout="out('r115')"> Individual feature setsword ngrams (WN) char. ngrams (CN) word embeds. (WE) all lexicons (L) Individual Lexicons</a><br><br><a id="s116" onmouseover="over('s116', 'r116')" onmouseout="out('r116')">AFINN BingLiu</a><br><br><a id="s117" onmouseover="over('s117', 'r117')" onmouseout="out('r117')">MPQA NRC-Aff-Int NRC-EmoLex NRC10E NRC-Hash-Emo NRC-Hash-Sent Sentiment140 SentiWordNet SentiStrengthCombinationsWN + CN + WE WN + CN + LWE + LWN + WE + L</a><br><br><a id="s118" onmouseover="over('s118', 'r118')" onmouseout="out('r118')">CN + WE + L WN+CN+WE+L</a><br><br><a id="s119" onmouseover="over('s119', 'r119')" onmouseout="out('r119')">0.42 0.49 0.52 0.50 0.48 0.45 0.48 0.54 0.57 0.62 0.60 0.60</a><br><br><a id="s120" onmouseover="over('s120', 'r120')" onmouseout="out('r120')">0.48 0.27 0.40 0.33 0.31 0.37 0.18 0.20 0.28 0.24 0.28 0.37 0.18 0.26 0.36 0.35 0.34 0.43 0.55 0.55 0.46 0.33 0.24 0.41 0.33 0.41 0.40 0.14 0.19 0.26 0.43 0.34 0.46</a><br><br><a id="s121" onmouseover="over('s121', 'r121')" onmouseout="out('r121')">0.50 0.48 0.45 0.61 0.61 0.61 0.64 0.63 0.65 0.63 0.65 0.65 0.61 0.61 0.62 0.61 0.61 0.61</a><br><br><a id="s122" onmouseover="over('s122', 'r122')" onmouseout="out('r122')"> Table 5: Pearson correlations (r) of emotion inten- sity predictions with gold scores. Best results for each column are shown in bold: highest score by a feature set, highest score using a single lexicon, and highest score using feature set combinations.</a><br><br><a id="s123" onmouseover="over('s123', 'r123')" onmouseout="out('r123')">Using just character or just word n-grams leads to results around 0.48, suggesting that they are reasonably good indicators of emotion intensity by themselves. (Guessing the intensity scores at random between 0 and 1 is expected to get correlations close to 0.) Word embeddings pro- duce statistically significant improvement over the ngrams (avg. r = 0.55).23 Using features drawn from affect lexicons produces results ranging from avg. r = 0.19 with SentiWordNet to avg. r = 0.53 with NRC-Hash-Emo. Combining all the lexicons leads to statistically significant improvement over individual lexicons (avg. r = 0.63). Combining the different kinds of features leads to even higher scores, with the best overall result obtained us- ing word embedding and lexicon features (avg. r = 0.66).24 The feature space formed by all the lexicons together is the strongest single feature category. The results also show that some fea- tures such as character ngrams are redundant in the presence of certain other features.</a><br><br><a id="s124" onmouseover="over('s124', 'r124')" onmouseout="out('r124')">23We used the Wilcoxon signed-rank test at 0.05 signifi- cance level calculated from ten random partitions of the data, for all the significance tests reported in this paper.</a><br><br><a id="s125" onmouseover="over('s125', 'r125')" onmouseout="out('r125')">24The increase from 0.63 to 0.66 is statistically significant.</a><br><br><a id="s126" onmouseover="over('s126', 'r126')" onmouseout="out('r126')">  anger fearword ngrams (WN)char. ngrams (CN)word embeds. (WE)all lexicons (L)Individual Lexicons(some low-score rows not shown to save space)Test Onfear joy 0.37 -0.37 0.65 -0.39-0.23 0.65 0.47 -0.32joy sad.</a><br><br><a id="s127" onmouseover="over('s127', 'r127')" onmouseout="out('r127')">0.38 0.40 0.38</a><br><br><a id="s128" onmouseover="over('s128', 'r128')" onmouseout="out('r128')">avg.</a><br><br><a id="s129" onmouseover="over('s129', 'r129')" onmouseout="out('r129')"> Individual feature setssadness 0.45 0.63 -0.41 0.65Pearson corre-another, the predictive power needin the other direction. We also found that train- ing on a simple combination of both the fear and sadness data and using the model to predict sad- ness obtained a correlation of 0.67 (exceeding the score obtained with just the sadness training set).27 Domain adaptation may provide further gains.</a><br><br><a id="s130" onmouseover="over('s130', 'r130')" onmouseout="out('r130')">To summarize, the experiments in this section show the extent to which two emotion are simi- lar as per their manifestation in language. For the four emotions studied here, the similarities vary from small (joy with fear) to considerable (fear with sadness). Also, the similarities are asymmet- ric. We also show that in some cases it is bene- ficial to use the training data for another emotion to supplement the training data for the emotion of interest. A promising avenue of future work is to test theories of emotion composition: e.g, whether optimism is indeed a combination of joy and an- ticipation, whether awe if fear and surprise, and so on, as some have suggested (Plutchik, 1980).</a><br><br><a id="s131" onmouseover="over('s131', 'r131')" onmouseout="out('r131')">7 Conclusions</a><br><br><a id="s132" onmouseover="over('s132', 'r132')" onmouseout="out('r132')">We created the first emotion intensity dataset for tweets. We used best–worst scaling to improve annotation consistency and obtained fine-grained scores. We showed that emotion-word hashtags often impact emotion intensity, often conveying a more intense emotion. We created a benchmark regression system and conducted experiments to show that affect lexicons, especially those with fine word–emotion association scores, are use- ful in determining emotion intensity. Finally, we showed the extent to which emotion pairs are cor- related, and that the correlations are asymmetric— e.g., fear is strongly indicative of sadness, but sad- ness is only moderately indicative of fear.</a><br><br><a id="s133" onmouseover="over('s133', 'r133')" onmouseout="out('r133')">Acknowledgment</a><br><br><a id="s134" onmouseover="over('s134', 'r134')" onmouseout="out('r134')">We thank Svetlana Kiritchenko and Tara Small for helpful discussions.</a><br><br><a id="s135" onmouseover="over('s135', 'r135')" onmouseout="out('r135')">270.67–0.63 difference is statistically significantly differ- ent, but 0.67–0.65 and 0.65–0.63 differences are not.</a><br><br><a id="s136" onmouseover="over('s136', 'r136')" onmouseout="out('r136')">Train On anger anger 0.63 fear 0.46 joy -0.41 sadness 0.39 0.36 0.39 0.39 0.36 0.41 0.42 0.48 0.47</a><br><br><a id="s137" onmouseover="over('s137', 'r137')" onmouseout="out('r137')">0.34 0.34 0.36 0.37 0.51 0.43 0.29 0.51 0.44</a><br><br><a id="s138" onmouseover="over('s138', 'r138')" onmouseout="out('r138')"> AFINN BingLiu NRC10E NRC-Hash-Emo Sentiment140 SentiStrengthCombinationsWN + CN + WE WN + CN + LWE + LWN + WE + L</a><br><br><a id="s139" onmouseover="over('s139', 'r139')" onmouseout="out('r139')">CN + WE + L WN+CN+WE+L</a><br><br><a id="s140" onmouseover="over('s140', 'r140')" onmouseout="out('r140')">0.31 0.06 0.31 0.06 0.27 0.14 0.43 0.39 0.18 0.24 0.23 0.04</a><br><br><a id="s141" onmouseover="over('s141', 'r141')" onmouseout="out('r141')">0.37 0.35 0.44 0.45 0.51 0.49 0.51 0.51 0.45 0.45 0.44 0.45</a><br><br><a id="s142" onmouseover="over('s142', 'r142')" onmouseout="out('r142')">0.11 0.05 0.13 0.11 0.05 0.13 0.25 0.30 0.24 0.15 0.44 0.35 0.09 0.32 0.21</a><br><br><a id="s143" onmouseover="over('s143', 'r143')" onmouseout="out('r143')">Table 7: Emotion intensity transfer lation on all target tweets.</a><br><br><a id="s144" onmouseover="over('s144', 'r144')" onmouseout="out('r144')">Table 6: Pearson correlations on a subset of the test set where gold scores ≥ 0.5.</a><br><br><a id="s145" onmouseover="over('s145', 'r145')" onmouseout="out('r145')">6.2 Similarity of Emotion Pairs</a><br><br><a id="s146" onmouseover="over('s146', 'r146')" onmouseout="out('r146')">Humans are capable of hundreds of emotions, and some are closer to each other than others. One rea- son why certain emotion pairs may be perceived as being close is that their manifestation in language is similar, for example, similar words and expres- sion are used when expressing both emotions. We quantify this similarity of linguistic manifestation by using the Tweet Emotion Intensity dataset for the following experiment: we train our regression system (with features WN + WE + L) on the train- ing data for one emotion and evaluate predictions on the test data for a different emotion.</a><br><br><a id="s147" onmouseover="over('s147', 'r147')" onmouseout="out('r147')">Table 7 shows the results. The numbers in the diagonal are results obtained using training and test data pertaining to the same emotion. These results are upperbound benchmarks for the non- diagonal results, which are expected to be lower. We observe that negative emotions are positively correlated with each other and negatively corre- lated with the only positive emotion (joy). The absolute values of these correlations go from r = 0.23 to r = 0.65. This shows that all of the emo- tion pairs are correlated at least to some extent, but that in some cases, for example, when learning from fear data and predicting sadness scores, one can obtain results (r = 0.63) close to the upper- bound benchmark (r = 0.65).26 Note also that the correlations are asymmetric. This means that even though one emotion may be strongly predictive of260.63 and 0.65 are not statistically significantly different.</a><br><br><a id="s148" onmouseover="over('s148', 'r148')" onmouseout="out('r148')">0.19 0.34</a><br><br><a id="s149" onmouseover="over('s149', 'r149')" onmouseout="out('r149')">0.20</a><br><br><a id="s150" onmouseover="over('s150', 'r150')" onmouseout="out('r150')">0.33 0.34 0.35 0.34 0.43 0.41 0.38 0.54 0.48</a><br><br><a id="s151" onmouseover="over('s151', 'r151')" onmouseout="out('r151')">0.40 0.49</a><br><br><a id="s152" onmouseover="over('s152', 'r152')" onmouseout="out('r152')">0.34 0.43 0.42 0.34 0.43 0.42</a><br><br><a id="s153" onmouseover="over('s153', 'r153')" onmouseout="out('r153')">0.47not be similar</a><br><br><a id="s154" onmouseover="over('s154', 'r154')" onmouseout="out('r154')">References</a><br><br><a id="s155" onmouseover="over('s155', 'r155')" onmouseout="out('r155')">Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005. Emotions from text: Machine learn- ing for text-based emotion prediction. In Proceed- ings of the Joint Conference on HLT–EMNLP. Van- couver, Canada.</a><br><br><a id="s156" onmouseover="over('s156', 'r156')" onmouseout="out('r156')">Saima Aman and Stan Szpakowicz. 2007. Identifying expressions of emotion in text. In Text, Speech and Dialogue, volume 4629 of Lecture Notes in Com- puter Science, pages 196–205.</a><br><br><a id="s157" onmouseover="over('s157', 'r157')" onmouseout="out('r157')">Johan Bollen, Huina Mao, and Alberto Pepe. 2009. Modeling public mood and emotion: Twitter senti- ment and socio-economic phenomena. In Proceed- ings of the Fifth International Conference on We- blogs and Social Media. pages 450–453.</a><br><br><a id="s158" onmouseover="over('s158', 'r158')" onmouseout="out('r158')">Felipe Bravo-Marquez, Eibe Frank, Saif M Moham- mad, and Bernhard Pfahringer. 2016. Determining word–emotion associations from tweets by multi- label classification. In Proceedings of the 2016 IEEE/WIC/ACM International Conference on Web Intelligence. Omaha, NE, USA, pages 536–539.</a><br><br><a id="s159" onmouseover="over('s159', 'r159')" onmouseout="out('r159')">Michael Brooks, Katie Kuksenok, Megan K Torkild- son, Daniel Perry, John J Robinson, Taylor J Scott, Ona Anicello, Ariana Zukowski, and Harris. 2013. Statistical affect detection in collaborative chat. In Proceedings of the 2013 conference on Computer supported cooperative work. San Antonio, Texas, USA, pages 317–328.</a><br><br><a id="s160" onmouseover="over('s160', 'r160')" onmouseout="out('r160')">LJ Cronbach. 1946. A case study of the splithalf relia- bility coefficient. Journal of educational psychology 37(8):473.</a><br><br><a id="s161" onmouseover="over('s161', 'r161')" onmouseout="out('r161')">Herbert Aron David. 1963. The method of paired com- parisons. Hafner Publishing Company, New York.</a><br><br><a id="s162" onmouseover="over('s162', 'r162')" onmouseout="out('r162')">Paul Ekman. 1992. An argument for basic emotions. Cognition and Emotion 6(3):169–200.</a><br><br><a id="s163" onmouseover="over('s163', 'r163')" onmouseout="out('r163')">Andrea Esuli and Fabrizio Sebastiani. 2006. SENTI- WORDNET: A publicly available lexical resource for opinion mining. In Proceedings of the 5th Conference on Language Resources and Evaluation (LREC). Genoa, Italy, pages 417–422.</a><br><br><a id="s164" onmouseover="over('s164', 'r164')" onmouseout="out('r164')">T. N. Flynn and A. A. J. Marley. 2014. Best-worst scal- ing: theory and methods. In Stephane Hess and An- drew Daly, editors, Handbook of Choice Modelling, Edward Elgar Publishing, pages 178–201.</a><br><br><a id="s165" onmouseover="over('s165', 'r165')" onmouseout="out('r165')">Nico H Frijda. 1988. The laws of emotion. American psychologist 43(5):349.</a><br><br><a id="s166" onmouseover="over('s166', 'r166')" onmouseout="out('r166')">Kevin Gimpel, Nathan Schneider, et al. 2011. Part- of-speech tagging for Twitter: Annotation, features, and experiments. In Proceedings of the Annual Meeting of the Association for Computational Lin- guistics (ACL). Portland, OR, USA.</a><br><br><a id="s167" onmouseover="over('s167', 'r167')" onmouseout="out('r167')">Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit- ter sentiment classification using distant supervision. CS224N Project Report, Stanford 1(12).</a><br><br><a id="s168" onmouseover="over('s168', 'r168')" onmouseout="out('r168')">Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: An update. SIGKDD Explor. Newsl. 11(1):10–18. https://doi.org/10.1145/1656274.1656278.</a><br><br><a id="s169" onmouseover="over('s169', 'r169')" onmouseout="out('r169')">Minqing Hu and Bing Liu. 2004. Mining and summa- rizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowl- edge discovery and data mining. ACM, New York, NY, USA, pages 168–177.</a><br><br><a id="s170" onmouseover="over('s170', 'r170')" onmouseout="out('r170')">David Jurgens. 2013. Embracing ambiguity: A com- parison of annotation methodologies for crowd- sourcing word sense labels. In Proceedings of the Annual Conference of the North American Chap- ter of the Association for Computational Linguistics. Atlanta, GA, USA.</a><br><br><a id="s171" onmouseover="over('s171', 'r171')" onmouseout="out('r171')">David Jurgens, Saif M. Mohammad, Peter Turney, and Keith Holyoak. 2012. Semeval-2012 task 2: Mea- suring degrees of relational similarity. In Proceed- ings of the 6th International Workshop on Semantic Evaluation. Montre ́al, Canada, pages 356–364.</a><br><br><a id="s172" onmouseover="over('s172', 'r172')" onmouseout="out('r172')">Svetlana Kiritchenko and Saif M. Mohammad. 2016. Capturing reliable fine-grained sentiment associa- tions by crowdsourcing and best–worst scaling. In Proceedings of The 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech- nologies (NAACL). San Diego, California.</a><br><br><a id="s173" onmouseover="over('s173', 'r173')" onmouseout="out('r173')">Svetlana Kiritchenko and Saif M. Mohammad. 2017. Best-worst scaling more reliable than rating scales: A case study on sentiment intensity annotation. In Proceedings of The Annual Meeting of the Associa- tion for Computational Linguistics (ACL). Vancou- ver, Canada.</a><br><br><a id="s174" onmouseover="over('s174', 'r174')" onmouseout="out('r174')">Svetlana Kiritchenko, Xiaodan Zhu, and Saif M. Mo- hammad. 2014. Sentiment analysis of short infor- mal texts. Journal of Artificial Intelligence Research 50:723–762.</a><br><br><a id="s175" onmouseover="over('s175', 'r175')" onmouseout="out('r175')">G Frederic Kuder and Marion W Richardson. 1937. The theory of the estimation of test reliability. Psy- chometrika 2(3):151–160.</a><br><br><a id="s176" onmouseover="over('s176', 'r176')" onmouseout="out('r176')">FA Kunneman, CC Liebrecht, and APJ van den Bosch. 2014. The (un) predictability of emotional hashtags in twitter. In Proceedings of the 5th Workshop on Language Analysis for Social Media. Gothenburg, Sweden, pages 26–34.</a><br><br><a id="s177" onmouseover="over('s177', 'r177')" onmouseout="out('r177')">Jordan J. Louviere. 1991. Best-worst scaling: A model for the largest difference judgments. Working Paper.</a><br><br><a id="s178" onmouseover="over('s178', 'r178')" onmouseout="out('r178')">Jordan J. Louviere, Terry N. Flynn, and A. A. J. Mar- ley. 2015. Best-Worst Scaling: Theory, Methods and Applications. Cambridge University Press.</a><br><br><a id="s179" onmouseover="over('s179', 'r179')" onmouseout="out('r179')">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word represen- tations in vector space. In Proceedings of Workshop at ICLR.</a><br><br><a id="s180" onmouseover="over('s180', 'r180')" onmouseout="out('r180')">Saif M. Mohammad. 2012. #Emotional tweets. In Pro- ceedings of the First Joint Conference on Lexical andComputationalSemantics.Montre ́al,Canada, SemEval ’12, pages 246–255.</a><br><br><a id="s181" onmouseover="over('s181', 'r181')" onmouseout="out('r181')">Saif M Mohammad. 2017. Word affect intensities. arXiv preprint arXiv:1704.08798 .</a><br><br><a id="s182" onmouseover="over('s182', 'r182')" onmouseout="out('r182')">Saif M. Mohammad and Felipe Bravo-Marquez. 2017. WASSA-2017 shared task on emotion intensity. In Proceedings of the Workshop on Computational Ap- proaches to Subjectivity, Sentiment and Social Me- dia Analysis (WASSA). Copenhagen, Denmark.</a><br><br><a id="s183" onmouseover="over('s183', 'r183')" onmouseout="out('r183')">Saif M. Mohammad and Svetlana Kiritchenko. 2015.</a><br><br><a id="s184" onmouseover="over('s184', 'r184')" onmouseout="out('r184')">Using hashtags to capture fine emotion cate- gories from tweets. Computational Intelligence 31(2):301–326. https://doi.org/10.1111/coin.12024.</a><br><br><a id="s185" onmouseover="over('s185', 'r185')" onmouseout="out('r185')">Saif M. Mohammad, Svetlana Kiritchenko, and Xiao- dan Zhu. 2013. NRC-Canada: Building the state- of-the-art in sentiment analysis of tweets. In Pro- ceedings of the International Workshop on Semantic Evaluation. Atlanta, GA, USA.</a><br><br><a id="s186" onmouseover="over('s186', 'r186')" onmouseout="out('r186')">Saif M. Mohammad, Parinaz Sobhani, and Svetlana Kiritchenko. 2017. Stance and sentiment in tweets. Special Section of the ACM Transactions on Inter- net Technology on Argumentation in Social Media 17(3).</a><br><br><a id="s187" onmouseover="over('s187', 'r187')" onmouseout="out('r187')">Saif M. Mohammad and Peter D. Turney. 2013. Crowdsourcing a word–emotion association lexicon. Computational Intelligence 29(3):436–465.</a><br><br><a id="s188" onmouseover="over('s188', 'r188')" onmouseout="out('r188')">Saif M. Mohammad, Xiaodan Zhu, Svetlana Kir- itchenko, and Joel Martin. July 2015. Sentiment, emotion, purpose, and style in electoral tweets. In- formation Processing and Management 51(4):480– 499.</a><br><br><a id="s189" onmouseover="over('s189', 'r189')" onmouseout="out('r189')">Alena Neviarouskaya, Helmut Prendinger, and Mit- suru Ishizuka. 2009. Compositionality principle in recognition of fine-grained emotions from text. In Proceedings of the Proceedings of the Third Inter- national Conference on Weblogs and Social Media (ICWSM-09). San Jose, California, pages 278–281.</a><br><br><a id="s190" onmouseover="over('s190', 'r190')" onmouseout="out('r190')">FinnA ̊rupNielsen.2011.AnewANEW:Evaluation of a word list for sentiment analysis in microblogs. In Proceedings of the ESWC Workshop on ’Mak- ing Sense of Microposts’: Big things come in small packages. Heraklion, Crete, pages 93–98.</a><br><br><a id="s191" onmouseover="over('s191', 'r191')" onmouseout="out('r191')">Bryan Orme. 2009. Maxdiff analysis: Simple count- ing, individual-level logit, and HB. Sawtooth Soft- ware, Inc.</a><br><br><a id="s192" onmouseover="over('s192', 'r192')" onmouseout="out('r192')">Alexander Pak and Patrick Paroubek. 2010. Twitter as a corpus for sentiment analysis and opinion mining. In Proceedings of the Conference on Language Re- sources and Evaluation (LREC). Malta.</a><br><br><a id="s193" onmouseover="over('s193', 'r193')" onmouseout="out('r193')">W Parrot. 2001. Emotions in Social Psychology. Psy- chology Press.</a><br><br><a id="s194" onmouseover="over('s194', 'r194')" onmouseout="out('r194')">Sasˇa Petrovic ́, Miles Osborne, and Victor Lavrenko. 2010. The Edinburgh Twitter corpus. In Proceed- ings of the NAACL HLT 2010 Workshop on Com- putational Linguistics in a World of Social Media. Association for Computational Linguistics, Strouds- burg, PA, USA, pages 25–26.</a><br><br><a id="s195" onmouseover="over('s195', 'r195')" onmouseout="out('r195')">Robert Plutchik. 1980. A general psychoevolutionary theory of emotion. Emotion: Theory, research, and experience 1(3):3–33.</a><br><br><a id="s196" onmouseover="over('s196', 'r196')" onmouseout="out('r196')">Ashequl Qadir and Ellen Riloff. 2013. Bootstrapped learning of emotion hashtags# hashtags4you. In Proceedings of the 4th workshop on computational approaches to subjectivity, sentiment and social me- dia analysis. Atlanta, GA, USA, pages 2–11.</a><br><br><a id="s197" onmouseover="over('s197', 'r197')" onmouseout="out('r197')">Ashequl Qadir and Ellen Riloff. 2014. Learning emo- tion indicators from tweets: Hashtags, hashtag pat- terns, and phrases. In Proceedings of the EMNLP Workshop on Arabic Natural Langauge Processing (EMNLP). Doha, Qatar, pages 1203–1209.</a><br><br><a id="s198" onmouseover="over('s198', 'r198')" onmouseout="out('r198')">Kirk Roberts, Michael A Roach, Joseph Johnson, Josh Guthrie, and Sanda M Harabagiu. 2012. Em- patweet: Annotating and detecting emotions on Twitter. In Proceedings of the Conference on Lan- guage Resources and Evaluation. pages 3806–3813.</a><br><br><a id="s199" onmouseover="over('s199', 'r199')" onmouseout="out('r199')">James A Russell. 2003. Core affect and the psycholog- ical construction of emotion. Psychological review 110(1):145.</a><br><br><a id="s200" onmouseover="over('s200', 'r200')" onmouseout="out('r200')">Carlo Strapparava and Rada Mihalcea. 2007. Semeval- 2007 task 14: Affective text. In Proceedings of SemEval-2007. Prague, Czech Republic, pages 70– 74.</a><br><br><a id="s201" onmouseover="over('s201', 'r201')" onmouseout="out('r201')">Anja Summa, Bernd Resch, Geoinformatics-Z GIS, and Michael Strube. 2016. Microblog emotion clas- sification by computing similarity in text, time, and space. In Proceedings of the PEOPLES Workshop at COLING. Osaka, Japan, pages 153–162.</a><br><br><a id="s202" onmouseover="over('s202', 'r202')" onmouseout="out('r202')">Jared Suttles and Nancy Ide. 2013. Distant supervision for emotion classification with discrete binary val- ues. In Computational Linguistics and Intelligent Text Processing, Springer, pages 121–136.</a><br><br><a id="s203" onmouseover="over('s203', 'r203')" onmouseout="out('r203')">Mike Thelwall, Kevan Buckley, and Georgios Pal- toglou. 2012. Sentiment strength detection for the social web. Journal of the American Society for In- formation Science and Technology 63(1):163–173.</a><br><br><a id="s204" onmouseover="over('s204', 'r204')" onmouseout="out('r204')">Louis L. Thurstone. 1927. A law of comparative judg- ment. Psychological review 34(4):273.</a><br><br><a id="s205" onmouseover="over('s205', 'r205')" onmouseout="out('r205')">Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase- level sentiment analysis. In Proceedings of the Joint Conference on HLT and EMNLP. Stroudsburg, PA, USA, pages 347–354.</a><br><br><a id="s206" onmouseover="over('s206', 'r206')" onmouseout="out('r206')">Frank Yates. 1936. Incomplete randomized blocks. Annals of Human Genetics 7(2):121–140.</a><br><br><a id="s207" onmouseover="over('s207', 'r207')" onmouseout="out('r207')">A Appendix</a><br><br><a id="s208" onmouseover="over('s208', 'r208')" onmouseout="out('r208')">A.1 Best–Worst Scaling Questionnaire used to Obtain Emotion Intensity ScoresThe BWS questionnaire used for obtaining fear annotations is shown below.</a><br><br><a id="s209" onmouseover="over('s209', 'r209')" onmouseout="out('r209')">Degree Of Fear In English Language Tweets</a><br><br><a id="s210" onmouseover="over('s210', 'r210')" onmouseout="out('r210')">The scale of fear can range from not fearful at all (zero amount of fear) to extremely fearful. One can often infer the degree of fear felt or expressed by a person from what they say. The goal of this task is to determine this degree of fear. Since it is hard to give a numerical score indicating the de- gree of fear, we will give you four different tweets and ask you to indicate to us:</a><br><br><a id="s211" onmouseover="over('s211', 'r211')" onmouseout="out('r211')">• Which of the four speakers is likely to be the MOST fearful, and</a><br><br><a id="s212" onmouseover="over('s212', 'r212')" onmouseout="out('r212')">• Which of the four speakers is likely to be the LEAST fearful.</a><br><br><a id="s213" onmouseover="over('s213', 'r213')" onmouseout="out('r213')">Important Notes</a><br><br><a id="s214" onmouseover="over('s214', 'r214')" onmouseout="out('r214')">• This task is about fear levels of the speaker (and not about the fear of someone else mentioned or spoken to).</a><br><br><a id="s215" onmouseover="over('s215', 'r215')" onmouseout="out('r215')">• If the answer could be either one of two or more speakers (i.e., they are likely to be equally fearful), then select any one of them as the answer.</a><br><br><a id="s216" onmouseover="over('s216', 'r216')" onmouseout="out('r216')">• Most importantly, try not to over-think the answer. Let your instinct guide you.</a><br><br><a id="s217" onmouseover="over('s217', 'r217')" onmouseout="out('r217')">EXAMPLE</a><br><br><a id="s218" onmouseover="over('s218', 'r218')" onmouseout="out('r218')">Speaker 1: Don’t post my picture on FB #grrr Speaker 2: If the teachers are this incompetent, I am afraid what the results will be.</a><br><br><a id="s219" onmouseover="over('s219', 'r219')" onmouseout="out('r219')">Speaker 3: Results of medical test today #terrified Speaker 4: Having to speak in front of so many people is making me nervous.</a><br><br><a id="s220" onmouseover="over('s220', 'r220')" onmouseout="out('r220')">Q1. Which of the four speakers is likely to be the MOST fearful?– Multiple choice options: Speaker 1, 2, 3, 4 – Ans: Speaker 3Q2. Which of the four speakers is likely to be the LEAST fearful?– Multiple choice options: Speaker 1, 2, 3, 4 – Ans: Speaker 1</a><br><br><a id="s221" onmouseover="over('s221', 'r221')" onmouseout="out('r221')">The questionnaires for other emotions are similar in structure. In a post-annotation survey, the re- spondents gave the task high scores for clarity of instruction (4.2/5) despite noting that the task it- self requires some non-trivial amount of thought (3.5 out of 5 on ease of task).</a><br><br><a id="s222" onmouseover="over('s222', 'r222')" onmouseout="out('r222')">A.2 Use of Emotion Word Hashtags</a><br><br><a id="s223" onmouseover="over('s223', 'r223')" onmouseout="out('r223')">Emotion word hashtags (e.g., #angry, #fear) have been used to search and compile sets of tweets that are likely to convey the emotions of interest. Often, these tweets are used in one of two ways: 1. As noisy training data for distant supervision (Pak and Paroubek, 2010; Mohammad, 2012; Sut- tles and Ide, 2013). 2. As data that is manually annotated for emotions to create training and test datasets suitable for machine learning (Roberts et al., 2012; Qadir and Riloff, 2014; Mohammad et al., July 2015).28 We use emotion word hashtag to create annotated data similar to ‘2’, however, we use them to create separate emotion intensity datasets for each emotion. We also examine the impact of emotion word hashtags on emotion in- tensity. This has not been studied before, even though there is work on learning hashtags asso- ciated with particular emotions (Qadir and Riloff, 2013), and on showing that some emotion word hashtags are strongly indicative of the presence of an emotion in the rest of the tweet, whereas others are not (Kunneman et al., 2014).</a><br><br><a id="s224" onmouseover="over('s224', 'r224')" onmouseout="out('r224')">A.3 AffectiveTweets Weka Package</a><br><br><a id="s225" onmouseover="over('s225', 'r225')" onmouseout="out('r225')">AffectiveTweets includes five filters for converting tweets into feature vectors that can be fed into the large collection of machine learning algorithms implemented within Weka. The package is installed using the WekaPackageManager and can be used from the Weka GUI or the command line interface. It uses the TweetNLP library (Gimpel et al., 2011) for tokenization and POS tagging. The filters are described as follows.</a><br><br><a id="s226" onmouseover="over('s226', 'r226')" onmouseout="out('r226')">• TweetToSparseFeatureVector filter: calculates the following sparse features: word n-grams (adding a NEG prefix to words occurring in negated contexts), character n-grams (CN), POS tags, and Brown word clusters.29</a><br><br><a id="s227" onmouseover="over('s227', 'r227')" onmouseout="out('r227')">28Often, the query term is removed from the tweet so as to erase obvious cues for a classification task.</a><br><br><a id="s228" onmouseover="over('s228', 'r228')" onmouseout="out('r228')">29The scope of negation was determined by a simple heuristic: from the occurrence of a negator word up until a punctuation mark or end of sentence. We used a list of 28 negator words such as no, not, won’t and never.</a><br><br><a id="s229" onmouseover="over('s229', 'r229')" onmouseout="out('r229')"> Figure 2: Screenshot of the interactive visualization to explore the Tweet Emotion Intensity Dataset. Available at: http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html</a><br><br><a id="s230" onmouseover="over('s230', 'r230')" onmouseout="out('r230')">• TweetToLexiconFeatureVector filter: calculates features from a fixed list of affective lexicons. • TweetToInputLexiconFeatureVector: calculates</a><br><br><a id="s231" onmouseover="over('s231', 'r231')" onmouseout="out('r231')">features from any lexicon. The input lexicon can have multiple numeric or nominal word– affect associations.</a><br><br><a id="s232" onmouseover="over('s232', 'r232')" onmouseout="out('r232')">• TweetToSentiStrengthFeatureVector filter: calculates positive and negative sentiment intensities for a tweet using the SentiStrength lexicon-based method (Thelwall et al., 2012)</a><br><br><a id="s233" onmouseover="over('s233', 'r233')" onmouseout="out('r233')">• TweetToEmbeddingsFeatureVector filter: calcu- lates a tweet-level feature representation us- ing pre-trained word embeddings supporting the following aggregation schemes: average of word embeddings; addition of word embed- dings; and concatenation of the first k word em- beddings in the tweet. The package also pro- vides Word2Vec’s pre-trained word embeddings.</a><br><br><a id="s234" onmouseover="over('s234', 'r234')" onmouseout="out('r234')">Additional filters for creating affective lexicons from tweets and support for distant supervision are currently under development.</a><br><br><a id="s235" onmouseover="over('s235', 'r235')" onmouseout="out('r235')">A.4 An Interactive Visualization to Explore the Tweet Emotion Intensity Dataset</a><br><br><a id="s236" onmouseover="over('s236', 'r236')" onmouseout="out('r236')">We created an interactive visualization to allow ease of exploration of this new dataset. The visualization has several components:</a><br><br><a id="s237" onmouseover="over('s237', 'r237')" onmouseout="out('r237')">1. Tables showing the percentage of instances in</a><br><br><a id="s238" onmouseover="over('s238', 'r238')" onmouseout="out('r238')">each of the emotion partitions (train, dev, test). Hovering over a row shows the corresponding number of instances. Clicking on an emotion filters out data from all other emotions, in all visualization components. Similarly, one can click on just the train, dev, or test partitions to view information just for that data. Clicking again deselects the item.</a><br><br><a id="s239" onmouseover="over('s239', 'r239')" onmouseout="out('r239')">2. A histogram of emotion intensity scores. A slider that one can use to view only those tweets within a certain score range.</a><br><br><a id="s240" onmouseover="over('s240', 'r240')" onmouseout="out('r240')">3. The list of tweets, emotion label, and emotion intensity scores.</a><br><br><a id="s241" onmouseover="over('s241', 'r241')" onmouseout="out('r241')">One can use filters in combination. For e.g., click- ing on fear, test data, and setting the slider for the 0.5 to 1 range, shows information for only those fear–testdata instances with scores ≥ 0.5.</a><br>
</div>
<div id="result">
<br><a id="r0" onmouseover="over('r0', 's0')" onmouseout="out('s0')">Saif M. Mohammad</a><br><br><a id="r1" onmouseover="over('r1', 's1')" onmouseout="out('s1')">Information and Communications Technologies National Research Council Canada Ottawa, Canada saif.mohammad@nrc-cnrc.gc.ca</a><br><br><a id="r2" onmouseover="over('r2', 's2')" onmouseout="out('s2')">フェリペ・ブラボ-マルケス</a><br><br><a id="r3" onmouseover="over('r3', 's3')" onmouseout="out('s3')">Department of Computer Science The University of Waikato Hamilton, New Zealand fbravoma@waikato.ac.nz.</a><br><br><a id="r4" onmouseover="over('r4', 's4')" onmouseout="out('s4')">アブストラクト</a><br><br><a id="r5" onmouseover="over('r5', 's5')" onmouseout="out('s5')">本論文では、テキストから感情の強さを検出するタスクを検討する。本論文では、怒り、恐怖、喜び、悲しみの感情の強さを示すツイートを集めた初のデータセットを作成した。本研究では、Best-Worst Scal-ing (BWS)と呼ばれる手法を用いて、アノテーションの一貫性を向上させ、信頼性の高い細分化されたスコアを取得する。また、感情を表す単語のハッシュタグは、感情の強さに影響を与えることが多く、通常はより強い感情を伝えることになることを示している。最後に、ベンチマークとなる回帰システムを構築し、感情の強さを検出するためにどのような特徴が有用であるか、また、2つの感情が言語にどのように現れるかという点でどの程度類似しているかを明らかにする実験を行った。</a><br><br><a id="r6" onmouseover="over('r6', 's6')" onmouseout="out('s6')">1 はじめに</a><br><br><a id="r7" onmouseover="over('r7', 's7')" onmouseout="out('s7')">私たちは言語を使って、自分が感じている感情だけでなく、その感情の強さも伝えます。例えば、「とても怒っている」、「少し悲しんでいる」、「とても興奮している」などを表現することができます。ここでいう「強さ」とは、怒りや悲しみなどの感情の度合いや量のことである1。自然言語処理アプリケーションは、感情のクラスとその強さの両方を知ることで恩恵を受けることができる。例えば、商業用の顧客満足システムでは、些細な不便さよりも、大きな不満や怒りを感じている事例にまず注目したいと思うでしょう。しかし、これまでの自動感情検出では、怒り、喜び、悲しみなどのカテゴリー分類が中心でした。感情の自動検出システムを開発する上での大きな障害は、適切なアノテーションデータがないことである。既存の情動データは主にカテゴリー分類されています。Anno-1感情の強さは、感情がどの程度落ち着くか、または興奮するかを意味するarousalとは異なります。</a><br><br><a id="r8" onmouseover="over('r8', 's8')" onmouseout="out('s8')">回答者にはより大きな認知的負荷がかかり、（異なるアノテーターによる回答間や、個々のアノテーターが作成した回答内での）一貫性を確保することが特に難しいのです。</a><br><br><a id="r9" onmouseover="over('r9', 's9')" onmouseout="out('s9')">Best-Worst Scaling（BWS）は、これらの制限に対処するアノテーション方式である（Louviere, 1991; Louviere et al., 2015; Kiritchenko and Mo- hammad, 2016, 2017）。アノテーターにはn個のアイテム（n-タプル、ここではn＞1、一般的にはn＝4）が与えられる。どのアイテムがベスト（inter-estのプロパティの観点から最も高い）で、どのアイテムがワースト（interestのプロパティの観点から最も低い）であるかを尋ねられる。4タプルの場合、ベストワーストアノテーションは特に有効である。なぜなら、ベストとワーストのアノテーションはそれぞれ、6つのアイテムペアのうち5つの順番を明らかにするからである。例えば、アイテムA、B、C、Dを持つ4タプルの場合、Aが最も良く、Dが最も悪い場合、A > B、A > C、A>D、B>D、C>Dとなります。</a><br><br><a id="r10" onmouseover="over('r10', 's10')" onmouseout="out('s10')">4タプルの集合に対するBWSのアノテーションは，項目とinter-estの特性との間の関連性を示す実数値のスコアに容易に変換できる（Orme, 2009; Flynn and Marley, 2014）。信頼性の高いスコアを得るためには，2N 4タプルのアノテーションで十分であることが経験的に示されている（Nはアイテムの数）（Louviere, 1991; Kiritchenko and Mohammad, 2016）2 計算言語学におけるBWSを用いた研究は，単語に焦点を当てている（Jurgens et al. このアプローチが、文のようなより大きなテキスト単位にスケールアップできるかどうかは不明である。</a><br><br><a id="r11" onmouseover="over('r11', 's11')" onmouseout="out('s11')">Twitterには大規模で多様なユーザーが存在し、顔文字や絵文字、CRE-2などの非標準的な言語を含む豊富なテキストコンテンツが含まれています。その限界であるn = 2の場合、BWSはペアの比較（Thurstone, 1927; David, 1963）になりますが、その場合、より大きなタプルセットをアノテーションする必要があります（N 2に近い）。</a><br><br><a id="r12" onmouseover="over('r12', 's12')" onmouseout="out('s12')">ツイートにおける感情の強さ arXiv:1708.03696v1 [cs.CL] 2017年8月11日</a><br><br><a id="r13" onmouseover="over('r13', 's13')" onmouseout="out('s13')">また、「happee」のように綴られた言葉や、「#luvumom」のようにハッシュタグが付けられた言葉もあります。つぶやきは、自分の感情や商品に対する意見、問題に対する姿勢などを確認するために使われることが多い。そのため、ツイートに含まれる感情の強さを自動的に検出することは、ブランドや製品の認知度の追跡、問題や政治への支持の追跡、国民の健康や幸福の追跡、災害や危機管理など、多くの応用が考えられます。</a><br><br><a id="r14" onmouseover="over('r14', 's14')" onmouseout="out('s14')">本論文では，ツイートに含まれる感情の強さ（または程度）を検出する研究を紹介する．具体的には，あるツイートと感情Xが与えられたときに，発言者が感じている感情Xの強さや度合いを，0から1の間の実数値のスコアで判定することを目的としている．本研究の主な貢献は、以下の通りである:...</a><br><br><a id="r15" onmouseover="over('r15', 's15')" onmouseout="out('s15')">- 私たちは、ツイートの中の感情の強さを検出するというタスクを定式化し、開発しました。</a><br><br><a id="r16" onmouseover="over('r16', 's16')" onmouseout="out('s16')">- 私たちは、怒り、喜び、悲しみ、恐れの強さについてそれぞれアノテーションされたツイートの4つのデータセットを作成しました。これらはこの種のものとしては初めてのものである4。</a><br><br><a id="r17" onmouseover="over('r17', 's17')" onmouseout="out('s17')">- 我々は、Best-Worst Scalingが（単語だけでなく）文章のアノテーションにうまく適用できることを示す。これにより、BWSの使用がより広く普及し、より信頼性の高い自然言語アノテーションが作成されることを期待しています。</a><br><br><a id="r18" onmouseover="over('r18', 's18')" onmouseout="out('s18')">- つぶやきと、そのつぶやきからハッシュタグを削除したバージョンの両方にアノテーションを行います。感情の強さに対するハッシュタグの影響を分析します。</a><br><br><a id="r19" onmouseover="over('r19', 's19')" onmouseout="out('s19')">- 感情の強さを自動的に判定する回帰システム「AffectiveTweets Package」を作成し、様々な特徴が感情の強さの判定にどの程度役立つかを示しています。このシステムは、Wekaワークベンチのオープンソースパッケージとしてリリースされています。</a><br><br><a id="r20" onmouseover="over('r20', 's20')" onmouseout="out('s20')">- 私たちは、ある感情の特徴が別の感情の強さをどれだけ予測できるかを示すことで、2つの感情が言語での表れ方によってどの程度似ているかを示す実験を行います。</a><br><br><a id="r21" onmouseover="over('r21', 's21')" onmouseout="out('s21')">3読み手の感情の強さや、ツイートに登場する人物の感情の強さなどを把握することも有効ですが、今後の課題とします。</a><br><br><a id="r22" onmouseover="over('r22', 's22')" onmouseout="out('s22')">4他の感情カテゴリーについても同様のデータセットを作成する作業を開始しています。価数、喚起、優位性についてアノテーションされたデータセットの作成も進めています。</a><br><br><a id="r23" onmouseover="over('r23', 's23')" onmouseout="out('s23')">5 https://github.com/felipebravom/AffectiveTweets</a><br><br><a id="r24" onmouseover="over('r24', 's24')" onmouseout="out('s24')">- このコンペティションはCodaLabのウェブサイト上で開催され，参加者は提出物をアップロードし，リーダーボードが結果を報告します7。タスクの説明、参加システムの詳細、結果はMohammad and Bravo-Marquez (2017)に掲載されています8。</a><br><br><a id="r25" onmouseover="over('r25', 's25')" onmouseout="out('s25')">すべてのデータ、アノテーション・アンケート、評価スクリプト、回帰コード、およびデータのインタラクティブな可視化は、シェアード・タスクのウェブサイトで自由に利用できるようになっています6。</a><br><br><a id="r26" onmouseover="over('r26', 's26')" onmouseout="out('s26')">2 関連作品</a><br><br><a id="r27" onmouseover="over('r27', 's27')" onmouseout="out('s27')">心理学者たちは、ある種の感情は他の感情よりも基本的であると主張してきた(Ekman, 1992; Plutchik, 1980; Parrot, 2001; Frijda, 1988)。しかし，どのような感情を（いくつ）基本的な感情として分類すべきかについては，意見が分かれています。そのため、自動感情検出の多くは、少数の感情に焦点を当てています。特に、多数の感情のためにテキストに人為的にアノテーションを行うことは困難です。このようなカテゴライズされた感情モデルとは別に、ある種の感情の次元モデルも提案されています。その中でも最もよく知られているRussellのcircumplexモデルは，すべての情動がva- lenceとarousalという2つの中核的な次元から構成されていると主張している(Russell, 2003)。この論文では、多くの感情モデルが提案されている中で、最も一般的な4つの感情、すなわち怒り、恐れ、喜び、悲しみに関する研究を紹介する。しかし、私たちは、他の感情の分類や、価動と覚醒についても研究を始めています。</a><br><br><a id="r28" onmouseover="over('r28', 's28')" onmouseout="out('s28')">感情のアノテーションの大部分は、テキストインスタンスに個別のバイナリラベル（joy-nojoy、fear-noofearなど）を提供しています（Alm et al. 感情の度合いのスコアを提供した唯一のアノテーション作業は、Strapparava and Mihalcea (2007)によるSemEval-2007共有タスクの一環として行われました。アノテーターには新聞の見出しが与えられ、以下のスコアを提供するよう求められた。</a><br><br><a id="r29" onmouseover="over('r29', 's29')" onmouseout="out('s29')">6 http://saifmohammad.com/WebPages/EmotionIntensity- SharedTask.html7 https://competitions.codalab.org/competitions/16380.</a><br><br><a id="r30" onmouseover="over('r30', 's30')" onmouseout="out('s30')">82017年のWASSA共有タスクが終了しても、CodaLabコンペティションのウェブサイトはオープンになっています。そのため、2017年のテストセットでどのシステムが得た最良の結果も、CodaLabのリーダーボードで確認することができます。</a><br><br><a id="r31" onmouseover="over('r31', 's31')" onmouseout="out('s31')">ウェブインターフェースのスライドバーで0と100を選択することができます。人間がこのような細かい粒度のスコアを直接提供することは困難です。よくある問題は、アノテーションの一貫性のなさです。あるアノテーターがあるテキストに79点をつけたとすると、別のアノテーターは同じテキストに62点をつけることがあります。また、同じアノテーターが、同じテキストインスタンスに対して、異なる時点で異なるスコアを付けることもよくあります。さらに、アノテーターはスケールの異なる部分に偏りを持つことが多く、スケール領域バイアスと呼ばれています。</a><br><br><a id="r32" onmouseover="over('r32', 's32')" onmouseout="out('s32')">Best-Worst Scaling（BWS）は、Anthony A. J. MarleyとDuncan Luceによる1960年代の数学的心理学と心理物理学における画期的な研究を基に、Louviere（1991）によって開発された。KiritchenkoとMohammad(2017)は、BWSが評価尺度を用いて得られたスコアよりも、より責任を持って細かいスコアを生成することを経験的な実験を通して示しています。NLPコミュニティでは、Best-Worst Scaling (BWS)はこれまで単語のアノテーションにのみ使用されてきた。例えば、relational similar-ity (Jurgens et al., 2012)、word-sense disambigua- tion (Jurgens, 2013)、word-sentiment intensity (Kiritchenko et al., 2014)、および phrase sentiment composition (Kiritchenko and Mohammad, 2016)のデータセットを作成するために使用されてきた。しかし、本研究では、BWSを用いてツイート全体に感情の度合いをアノテーションします。BWSを用いることで、直接スコアリングの課題に対処し、より信頼性の高い感情強度スコアを生成します。また、本研究は、ツイートの感情スコアを持つ最初のデータセットとなります。</a><br><br><a id="r33" onmouseover="over('r33', 's33')" onmouseout="out('s33')">自動感情分類は、ツイートを含む多くの異なる種類のテキストに対してプロポーズされています（Summa et al. しかし、2007年のSemEvalタスクへの3つのサブミッション以外の感情回帰に関する研究はほとんどありません（Strapparava and Mihalcea, 2007）。</a><br><br><a id="r34" onmouseover="over('r34', 's34')" onmouseout="out('s34')">3 データ</a><br><br><a id="r35" onmouseover="over('r35', 's35')" onmouseout="out('s35')">私たちが目指したのは、4つの感情のそれぞれについて、以下のようなツイートのデータセットを作ることでした。</a><br><br><a id="r36" onmouseover="over('r36', 's36')" onmouseout="out('s36')">- このツイートには、さまざまな感情の強さ（または程度）が関連しています。</a><br><br><a id="r37" onmouseover="over('r37', 's37')" onmouseout="out('s37')">- 焦点となる感情を明らかに示す言葉があるツイートと、そうでないツイートがあります。</a><br><br><a id="r38" onmouseover="over('r38', 's38')" onmouseout="out('s38')">無作為に集められたツイートには、焦点となる感情に関連しないツイートが大きな割合で含まれている可能性が高く、そのため、すべてのツイートに感情の強さをアノテーションすることは最適ではありません。そこで、特定の感情を持つツイートを集めたデータセットを作成するために、次のような方法を用います。</a><br><br><a id="r39" onmouseover="over('r39', 's39')" onmouseout="out('s39')">各感情Xに対して，その感情に関連する50から100の用語を，異なる強度レベルで選択します。例えば、怒りのデータセットでは、「怒る」「怒る」「悔しい」「イライラする」「ムッとする」「怒る」「反感を覚える」などの用語を使用する。悲しみのデータセットでは，sad, devastated, sullen, down, crying, dejected, heartbroken, grief, weeping などの用語を使用した．これらの用語を「クエリ用語」と呼ぶことにします。</a><br><br><a id="r40" onmouseover="over('r40', 's40')" onmouseout="out('s40')">まず，Roget's Thesaurusを検索して，焦点となる感情の単語（またはそれに近い同義語）を見出し語とするカテゴリーを見つけました9。そして，これらのカテゴリーに掲載されているすべての単語を，対応する焦点となる感情の問い合わせ語としました。これらのカテゴリーに掲載されているすべての単語を、対応するフォーカスエモーションの検索語とし、Twitter APIを用いて、検索語を含むツイートを検索しました。その際，リツイート（RTで始まるツイート）とURLを含むツイートは除外した．残ったツイートの中から、以下の方法でサブセットを作成しました。</a><br><br><a id="r41" onmouseover="over('r41', 's41')" onmouseout="out('s41')">- は、1つのクエリ用語に対して最大50のツイートを選択します。</a><br><br><a id="r42" onmouseover="over('r42', 's42')" onmouseout="out('s42')">- 各ツイート主に対して、最大で1つのツイートを選択します。</a><br><br><a id="r43" onmouseover="over('r43', 's43')" onmouseout="out('s43')">クエリ用語の組み合わせ。</a><br><br><a id="r44" onmouseover="over('r44', 's44')" onmouseout="out('s44')">そのため、マスターセットのツイートは、一部のツイーターやクエリ用語に大きく偏ることはありません。</a><br><br><a id="r45" onmouseover="over('r45', 's45')" onmouseout="out('s45')">感情を表す単語のハッシュタグがツイート全体の強度に与える影響を調べるために、ツイートの最後にハッシュタグ形式の問い合わせ語があるツイートを特定しました。これらのツイートのコピーを作成し、コピーからハッシュタグのクエリ用語を削除しました。そして、更新されたツイートをマスターセットに追加しました。最終的に、7,097件のツイートをマスターセットとしました。</a><br><br><a id="r46" onmouseover="over('r46', 's46')" onmouseout="out('s46')">1. ハッシュタグ付きクエリストームツイート（HQTツイート）：ツイートの末尾にハッシュタグ（#<クエリストーム>）の形でクエリストームが付けられた1030件のツイート。</a><br><br><a id="r47" onmouseover="over('r47', 's47')" onmouseout="out('s47')">2. No Query Term Tweets（NQTツイート）。</a><br><br><a id="r48" onmouseover="over('r48', 's48')" onmouseout="out('s48')">1」のコピーだが、ハッシュタグ付きのクエリ用語を削除した1030ツイート。</a><br><br><a id="r49" onmouseover="over('r49', 's49')" onmouseout="out('s49')">9「ロジェのシソーラス」では、単語を約1000のカテゴリーに分類しています。カテゴリー内の単語の意味を最もよく表す単語を見出し語としています。選ばれたカテゴリーは 900 Resentment（怒り）、860 Fear（恐れ）、836 Cheerfulness（喜び）、837 Dejection（悲しみ）。</a><br><br><a id="r50" onmouseover="over('r50', 's50')" onmouseout="out('s50')"> 3. クエリ用語ツイート（QTツイート）：5037件のツイートのうち、以下のものを含む：a. クエリ用語を単語の形で含むツイート（#<クエリ用語>は含まない）b. クエリ用語をハッシュタグの形で含み、その後に少なくとも1つのハッシュタグ以外の単語が続くツイート。</a><br><br><a id="r51" onmouseover="over('r51', 's51')" onmouseout="out('s51')">そして、このマスターセットのツイートを、手作業で感情の強さを表記しました。表1に感情別の内訳を示します。</a><br><br><a id="r52" onmouseover="over('r52', 's52')" onmouseout="out('s52')">3.1 Best-Worst Scalingによるアノテーション</a><br><br><a id="r53" onmouseover="over('r53', 's53')" onmouseout="out('s53')">Kir- itchenko and Mohammad (2016)に記載されている手順で、BWSのアノテーションを取得しました。感情ごとに，アノテーターは一度に4つのツイート（4-タプル）を提示され，感情のinten- sityが最も高いツイートと最も低いツイートの話者を選択するように求められました。2×N（Nは感情セットのツイート数）の異なる4-タプルをランダムに生成し，1つのアイテムが8つの異なる4-タプルに出現し，2つ以上の4-タプルにアイテムのペアが出現しないようにした。ここでは，この方法をRMDS（Random Maximum-Diversity Selection）と呼ぶことにする．RMDSは、各アイテムが4タプルの中で共起するユニークなアイテムの数を最大化する。RMDSでは、各アイテムが4つのタプルで共起するユニークなアイテムの数を最大化し、BWSによるアノテーションを経て、最大数のアイテムペアの比較ランキング情報を得ることができる10。同様に、最小の強度が低強度から高強度までの範囲に広がるような4つのタプルのセットにアイテムが出現することが好ましい。しかし、アイテムの強度は事前にわからないので、RMDSを使用します。</a><br><br><a id="r54" onmouseover="over('r54', 's54')" onmouseout="out('s54')">使用された質問票は、社内での議論やパイロットテストを経て作成されたものです11。</a><br><br><a id="r55" onmouseover="over('r55', 's55')" onmouseout="out('s55')">10 組合せ数学では、バランス型不完全ブロック設計とは、N個のアイテムのセットから、各アイテムが同じ数のブロック（xとする）に出現し、異なるアイテムのペアが同じ数のブロック（yとする）に出現するように、一握りのアイテムのブロック（またはタプル）を作成することである（xとyは整数Ge1）。私たちが作成するタプルのセットも同様の特性を持っていますが、2N個のタプルしか作成しないので、異なるアイテムのペアは4つのタプルに一緒に出現することはないか、または正確に1つの4つのタプルに出現することになります。</a><br><br><a id="r56" onmouseover="over('r56', 's56')" onmouseout="out('s56')">11Kiritchenko and Mohammad (2016) は、4-tupleごとにわずか3つのアノテーションを使用すると、信頼性の高い再結果が得られることを示しました。なお、各ツイートは8つの異なる4-tupleで見られるため、各ツイートに対する8×3＝24の判定が得られることになります。</a><br><br><a id="r57" onmouseover="over('r57', 's57')" onmouseout="out('s57')">Emotion Train</a><br><br><a id="r58" onmouseover="over('r58', 's58')" onmouseout="out('s58')">怒り 857 恐れ 1147 喜び 823 悲しみ 786 すべて 3613</a><br><br><a id="r59" onmouseover="over('r59', 's59')" onmouseout="out('s59')">Dev. テスト 全て</a><br><br><a id="r60" onmouseover="over('r60', 's60')" onmouseout="out('s60')">84 760 1701 110 995 2252 74 714 1611 74 673 1533 342 3142 7097 表1：Tweet Emotion Intensityデータセットのインスタンス数。</a><br><br><a id="r61" onmouseover="over('r61', 's61')" onmouseout="out('s61')">の注釈があります。調査票のサンプルを付録（A.1）に示します。</a><br><br><a id="r62" onmouseover="over('r62', 's62')" onmouseout="out('s62')">4タプルのツイートは、クラウドソーシングのプラットフォームであるCrowdFlowerにアップロードされました。データの約5％は、事前に内部で（著者が）アノテーションを行った。これらの質問は、金の質問と呼ばれています。金の質問は、他の質問と相互に関連付けられています。金の質問を間違えた場合は、すぐにその旨が通知されます。金の質問の精度が70%以下になると、さらなるアノテーションを拒否され、すべてのアノテーションが破棄されます。これは、悪意のあるアノテーションを避けるためのメカニズムとして機能している。感情の度合いは単極性の尺度であるため、-1から1のスコアを0から1のスコアに線形変換した。</a><br><br><a id="r63" onmouseover="over('r63', 's63')" onmouseout="out('s63')">3.2 トレーニング、開発、およびテストセット</a><br><br><a id="r64" onmouseover="over('r64', 's64')" onmouseout="out('s64')">新たに作成した感情強度ラベリングデータをTweet Emotion Intensity Datasetと呼ぶことにする。このデータセットは、機械学習の実験のために、トレーニングセット、開発セット、テストセットに分けられています（表1参照）。それぞれの感情について、トレーニングセットには約50%、開発セットには約5%、テストセットには約45%のツイートが含まれるようにしました。さらに、NQTツイートが、その元となったHQTツイートと同じパーティションにあることを確認しました。データのインタラクティブな可視化の詳細については、付録（A.4）を参照してください。</a><br><br><a id="r65" onmouseover="over('r65', 's65')" onmouseout="out('s65')">複数のアイテムがベストアイテム（またはワーストアイテム）として合理的に選択できる場合、複数の受け入れ可能なゴールドアンサーが提供されます。ゴールドアノテーションの目的は、質の悪いアノテーターや悪意のあるアノテーターを明らかに特定することです。2つのアイテムの強度が近い場合、アノテーターの群衆がBWSアノテーションによってアイテムの相対的な順位を示すことを期待しています。</a><br><br><a id="r66" onmouseover="over('r66', 's66')" onmouseout="out('s66')">13 Kiritchenko and Mohammad (2016) は、RMDSを使ってアイテムからタプルを生成するコードと、BWSアノテーションからスコアを生成するコードを提供しています。http://saifmohammad.com/WebPages/BestWorst.html</a><br><br><a id="r67" onmouseover="over('r67', 's67')" onmouseout="out('s67')"> 4 アノテーションの信頼性</a><br><br><a id="r68" onmouseover="over('r68', 's68')" onmouseout="out('s68')">感情の強さが近い2つの項目がある場合に生じる意見の相違は、BWSにとって有用なシグナルであるため、標準的なアノテーター間の同意度を使ってBWSアノテーションの品質を判断することはできません。ある4つのタプルについて、回答者が感情の強さが最も高い（または最も低い）ツイートを一貫して特定できない場合、意見の相違により2つのツイートが互いに近いスコアを得ることになり、これが望ましい結果となります。そのため、アノテーションの質を測るための別の尺度を利用する必要があります...。</a><br><br><a id="r69" onmouseover="over('r69', 's69')" onmouseout="out('s69')">複数の回答者から独立したマニュアルアノテーションを繰り返すことで、同じような強度のランキング（およびスコア）が得られれば、そのスコアが真の感情の強さを表していると確信できます。この再現性を評価するために、平均分割半減信頼性(SHR)を計算しました。これは一貫性を判断するための一般的なアプローチです(Kuder and Richardson, 1937; Cronbach, 1946)。SHRは次のような考え方に基づいています。あるアイテム（ここではタプル）のすべてのアノテーションをランダムに2つに分割する。2つのスコアセットが2つのハーフから独立して生成される。そして、2つのスコアセットの相関が計算されます。アノテーションの質が高ければ、2つのハーフの間の相関は高くなります。</a><br><br><a id="r70" onmouseover="over('r70', 's70')" onmouseout="out('s70')">このデータセットの各タプルは3人のアノテーター（奇数）によってアノテーションされているため、タプルごとに1つまたは2つのアノテーションを1つのビンに、残り（2つまたは1つ）のアノテーションを別のビンにランダムに配置してSHRを計算します。そして、2つのビンのそれぞれのアノテーションから2組の強度スコア（およびランキング）を計算します。このプロセスを100回繰り返し、2組のランキングと強度スコアの相関関係を平均します。表2は、Tweet Emotion Intensity Datasetに含まれる怒り、恐怖、喜び、悲しみのツイートの半分ずつの信頼性を示しています。しかし，過去の研究では，単語に対する感情強度のアノテーション（1タプルあたり8個のアノテーション）のSHRは0.98であった（Kiritchenko et al.，2014）。これに対して、ここでは、SHRは、感情についての3つのアノテーションと、文全体から計算されています。より少ない数のアノテーションから、より複雑なアノテーションタスクで決定されたSHRは、より低くなることが予想されます。</a><br><br><a id="r71" onmouseover="over('r71', 's71')" onmouseout="out('s71')">Emotion Spearman Pearson 怒り 0.779 恐れ 0.845 喜び 0.881 悲しみ 0.847</a><br><br><a id="r72" onmouseover="over('r72', 's72')" onmouseout="out('s72')">0.797 0.850 0.882 0.847</a><br><br><a id="r73" onmouseover="over('r73', 's73')" onmouseout="out('s73')"> 表2:</a><br><br><a id="r74" onmouseover="over('r74', 's74')" onmouseout="out('s74')">Tweet Emotion Intensity Datasetに含まれる怒り、恐怖、喜び、悲しみのツイートについて、ピアソン相関とスピアマン順位相関を求めた。</a><br><br><a id="r75" onmouseover="over('r75', 's75')" onmouseout="out('s75')">これは、話し手の怒りの度合いをツイートから把握することが相対的に困難であることを示しています。なお，SHRは，半分の数のアノテーションで得られたアノテーションの質を示しています。4つのタプルに対して3つのアノテーションを用いて実験を繰り返すと、さらに高い相関が得られることが予想されます。したがって、表2に示した数値は、4タプルごとに3つのアノテーションを使用した場合のアノテーションの質の下限となる。</a><br><br><a id="r76" onmouseover="over('r76', 's76')" onmouseout="out('s76')">5 情動語ハッシュタグの情動強度への影響</a><br><br><a id="r77" onmouseover="over('r77', 's77')" onmouseout="out('s77')">いくつかの研究では，顔文字は感情の面で冗長になる傾向があることが示されています(Go et al., 2009; Mohammad et al., 2013)。つまり，あるツイートからスマイリーフェイス「:)」を削除しても，そのツイートの残りの部分はポジティブな感情を伝えていることがわかります。同様に，ハッシュタグの感情語も，ツイートの残りの部分で伝えられている感情のクラスから見ると，やや冗長であることが示されています(Mohammad, 2012)。例えば、以下のツイートから「#angry」を削除しても、怒りを伝えるツイートになります。</a><br><br><a id="r78" onmouseover="over('r78', 's78')" onmouseout="out('s78')">このようなデマゴーグへの心ない支持はやめるべきです。#racism #grrr #angry.</a><br><br><a id="r79" onmouseover="over('r79', 's79')" onmouseout="out('s79')">しかし、このような感情ワードのハッシュタグが、感情の強さにどのような影響を与えるのかは不明です。実際、これを体系的に調査した先行研究はありません。私たちは、データセットのスコアを分析して散布図を作成しました。この散布図では、各点がHQTとNQTのツイートペアに対応し、X軸がHQTツイートの感情強度スコア、Y軸がNQTツイートのスコアとなっています。図1は、恐怖データの散布図です。感情表現のハッシュタグが先行研究でどのように使われているかについては、付録（A.2）を参照してください。</a><br><br><a id="r80" onmouseover="over('r80', 's80')" onmouseout="out('s80')">スプリット・ハーフ・リライアビリティー（測定方法は</a><br><br><a id="r81" onmouseover="over('r81', 's81')" onmouseout="out('s81')"> HQT-NQT感情ツイートペア数 怒り 282 恐れ 454 喜び 204 悲しみ 90 すべて 1030</a><br><br><a id="r82" onmouseover="over('r82', 's82')" onmouseout="out('s82')">% Tweets Pairs</a><br><br><a id="r83" onmouseover="over('r83', 's83')" onmouseout="out('s83')">ドロップライズ なし 76.6 19.9 3.4 86.1 13.9 4.4 71.6 26.5 1.9 85.6 11,1 3.3 78.6 17.8 3.6平均感情強度スコアHQTのツイート 0. 58 0.57 0.59 0.65 0.58NQTツイート 0.48 0.43 0.50 0.49 0.47Drop Rise 0.15 0.07 0.18 0.07 0.15 0.09 0.19 0.05 0.17 0.08 Table3: 感情表現のハッシュタグを削除した場合のツイートの感情密度への影響。</a><br><br><a id="r84" onmouseover="over('r84', 's84')" onmouseout="out('s84')"> 図1：HQTツイートとそれに対応するNQTツイートの恐怖強度の散布図。スペースの都合上、いくつかの点には関連するハッシュタグが付けられている。</a><br><br><a id="r85" onmouseover="over('r85', 's85')" onmouseout="out('s85')">ほとんどの場合、ポイントは対角線の右下に位置しており、感情を表す単語であるハッシュタグが削除されたことで、ツイートの感情強度が低下したことを示しています。しかし、ハッシュタグの削除によって、対角線の左上に位置するポイント（上昇を示す）や、対角線の外側に位置するポイント（影響なしを示す）もいくつか見られます。また、ハッシュタグが削除されたことで、エモティオンスコアが低下するツイートもあれば、上昇するツイートもあることがわかります（例：#nervousのラベルが貼られた3つのポイントを参照）。また、他の感情についても同様のパターンが見られます（プロットはここでは示していません）。表3は、これらの結果をまとめたもので、それぞれの感情について、3つの結果が発生する回数の割合を示しています。</a><br><br><a id="r86" onmouseover="over('r86', 's86')" onmouseout="out('s86')">また、この表は、HQT のツイートと NQT のツイートの平均スコアを示しています。最後の2列は、ハッシュタグを削除したときにスコアが低下した場合、0.05の有意水準で平均-16Wilcoxon signed-rank testを行ったことを示しています。</a><br><br><a id="r87" onmouseover="over('r87', 's87')" onmouseout="out('s87')">一方、上昇した場合の平均上昇値は0.08（全体の8％）でした。これらの結果から、感情を表す単語のハッシュタグは、全体の感情の強さに影響を与えるという点で、他のツイートと比較して劣っていることが多いことがわかります。さらに、これらのハッシュタグの多くが感情の強さを増加させることは一般的ですが、ツイートのテキストとハッシュタグの間にはより複雑な相互作用があり、感情の強さへの影響の度合いや大きさを決定しています。例えば、ツイートの他の部分が（別の感情語のハッシュタグや絵文字、ハッシュタグの付いていない単語によって）感情の予兆を明確に示している場合、感情語のハッシュタグがスコアに与える影響はわずかであることがよくわかりました17。また、特定の感情に特有のパターンも観察されました。例えば、発言者の恐怖度を判断する際、発言者が何らかの判断を示すハッシュタグを使用している場合には、低いスコアが割り当てられました。</a><br><br><a id="r88" onmouseover="over('r88', 's88')" onmouseout="out('s88')">恐怖: 0.48@RocksNRopes あなたのレジ係がどれほど無礼だったか、信じられないほどです。#恐怖：0.31</a><br><br><a id="r89" onmouseover="over('r89', 's89')" onmouseout="out('s89')">状況に対する判断を声に出さないことで、話し手がより恐怖を感じているように見えたと考えられます。このデータセットのHQT-NQTサブセットは、単独でも、特に心理学や社会科学のコミュニティにとって興味深いものであるため、別途、自由に利用できるようにする予定です。</a><br><br><a id="r90" onmouseover="over('r90', 's90')" onmouseout="out('s90')">17ただし、ハッシュタグの単語自体が非常に低い感情の強さと関連している場合（例：#peevedは怒り）、その場合は、知覚された感情の強さが低下しています。</a><br><br><a id="r91" onmouseover="over('r91', 's91')" onmouseout="out('s91')"> Twitterアノテーション</a><br><br><a id="r92" onmouseover="over('r92', 's92')" onmouseout="out('s92')">Scope Sentiment Sentiment Sentiment Emotions EmotionsSentiment Sentiment SentimentLabel Numeric Nominal Nominal Numeric Numeric NumericNumeric Numeric Numeric Numeric</a><br><br><a id="r93" onmouseover="over('r93', 's93')" onmouseout="out('s93')"> AFINN (Nielsen, 2011) Yes BingLiu (Hu and Liu, 2004) No MPQA (Wilson et al., 2005) No NRC Affect Intensity Lexicon (NRC-Aff-Int) (Mohammad, 2017) Yes NRC Word-Emotion Assn. Lexicon (NRC-EmoLex) (Mohammad and Turney, 2013) No NRC10 Expanded (NRC10E) (Bravo-Marquez et al., 2016) Yes NRC Hashtag Emotion Association Lexicon (NRC-Hash-Emo) Yes</a><br><br><a id="r94" onmouseover="over('r94', 's94')" onmouseout="out('s94')">(Mohammad and Kiritchenko, 2015)</a><br><br><a id="r95" onmouseover="over('r95', 's95')" onmouseout="out('s95')">NRC Hashtag Sentiment Lexicon (NRC-Hash-Sent) (Mohammad et al., 2013) はい Sentiment140 (Mohammad et al., 2013) はい SentiWordNet (Esuli and Sebastiani, 2006) いいえ SentiStrength (Thelwall et al, この回帰システムは、新しいTweet Emotion Intensity Datasetのベンチマーク予測結果を得るため（セクション6.1）と、2つの感情がどの程度相関しているかを判定するため（セクション6.2）に使用します。</a><br><br><a id="r96" onmouseover="over('r96', 's96')" onmouseout="out('s96')">我々は、感情の分類やその他の関連するタスクのためにツイートから最先端の特徴を抽出するためのフィルタのコレクションを提供するWeka機械学習ワークベンチ(Hall et al., 2009)のAffectiveTweetsと呼ばれるパッケージを実装しました。このパッケージを使用して、感情の強さがラベル付けされたツイートから特徴ベクトルを計算し、この変換されたデータでWeka回帰モデルを学習します。LIBLINEAR19で実装されている正則化パラメータCを1に設定したL2正則化L2-loss SVM回帰モデルを使用しました。使用した特徴は以下の通りです：20a. 単語N-grams (WN): n = 1からn = 4までの単語N-gramsの有無。</a><br><br><a id="r97" onmouseover="over('r97', 's97')" onmouseout="out('s97')">b. 文字N-gram（CN）：n＝3からn＝5までの文字N-gramの存在の有無。</a><br><br><a id="r98" onmouseover="over('r98', 's98')" onmouseout="out('s98')">c. Word Embeddings (WE): ツイートに含まれるすべての単語の単語埋め込み量の平均値。Word2Vec (Mikolov et al., 2013) に実装されているネガティブサンプリング・スキップグラムモデルを用いて，個々の単語エンベッディングを計算する．単語ベクトルは，Edinburgh Twitter Corpus (Petrovic ́ et al., 2010)から取得した1,000万件の英語のツイートから学習したものです．Word2Vecのパラメータを18Kiritchenko et al. (2014)は、3つの感情共有タスクで1位を獲得したNRC-Canadaシステムについて述べている。SemEval-2013タスク2、SemEval-2014タスク9、SemEval-2014タスク4です。Mohammadら(2017)は、SemEval-2016タスク6に参加した全19チームの提出物を凌駕したスタンス検出システムについて述べています。</a><br><br><a id="r99" onmouseover="over('r99', 's99')" onmouseout="out('s99')">19 http://www.csie.ntu.edu.tw/∼cjlin/liblinear/20実装の詳細については、付録（A.3）を参照してください。</a><br><br><a id="r100" onmouseover="over('r100', 's100')" onmouseout="out('s100')">ウィンドウサイズ：5、ディメンション数 400.21d. Affect Lexicons (L): つぶやきに含まれるすべての単語の情報を集約して、表4に示す語彙を使用します。レキシコンが名目的な関連ラベル(ポジティブ、怒りなど)を提供している場合は、各クラスにマッチするツイート内の単語数をカウントします。数値スコアが提供されている場合は、各クラスの個々のスコアを合計します。これらのリソースは、辞書にTwitter固有の用語が含まれているかどうか、単語が手動でアノテーションされているか自動でアノテーションされているか、単語に感情や情動がアノテーションされているかどうか、提供される感情の関連付けが名目的なものか数値的なものかによって異なります。評価 自動システムがテストセットで生成したスコアとゴールドインテンシティスコアの間のピアソン相関係数（r）を計算し，システムの出力が人間のアノテーションの結果とどの程度一致するかを判断した．0は相関がないことを示す。</a><br><br><a id="r101" onmouseover="over('r101', 's101')" onmouseout="out('s101')">6.1 スーパーバイズド回帰とアブレーション</a><br><br><a id="r102" onmouseover="over('r102', 's102')" onmouseout="out('s102')">我々は，公式のトレーニングセットでトレーニングを行い，学習したモデルを開発セットに適用することで，システムを開発した．システムのパラメータが確定した後，システムはトレーニング用コーパスと開発用コーパスを組み合わせて学習した．そして，これらのモデルを公式テストセットに適用した．表 5 は，さまざまな特徴を個別に，または組み合わせてテストセットに適用した結果を示している．最後の列「avg.」は，すべての情 報の相関関係のマクロ平均を示している．</a><br><br><a id="r103" onmouseover="over('r103', 's103')" onmouseout="out('s103')">21独立したデータセット（Bravo-Marquez et al, 2016）上で、単語と感情の分類というタスクに最適化されています。</a><br><br><a id="r104" onmouseover="over('r104', 's104')" onmouseout="out('s104')">22スピアマン順位相関も求めたが、Pearsonを用いて得られた結果と一致していた。</a><br><br><a id="r105" onmouseover="over('r105', 's105')" onmouseout="out('s105')">表4：実験で使用した影響辞書</a><br><br><a id="r106" onmouseover="over('r106', 's106')" onmouseout="out('s106')"> 怒り 恐怖 ジョイサド アベレージ</a><br><br><a id="r107" onmouseover="over('r107', 's107')" onmouseout="out('s107')">0.49 0.48 0.49 0.48 0.60 0.55 0.68 0.63</a><br><br><a id="r108" onmouseover="over('r108', 's108')" onmouseout="out('s108')">0.28 0.36 0.23 0.31 0.12 0.20 0.32 0.30 0.23 0.26 0.37 0.37 0.54 0.53 0.39 0.34 0.48 0.41 0.16 0.19 0.61 0.46</a><br><br><a id="r109" onmouseover="over('r109', 's109')" onmouseout="out('s109')">0.49 0.48 0.63 0.61 0.71 0.66 0.65 0.65 0.63 0.62 0.63 0.62</a><br><br><a id="r110" onmouseover="over('r110', 's110')" onmouseout="out('s110')">辞書の中では、NRC-Hash-Emoが最も予測性の高い辞書です。このタスクとデータセットの組み合わせでは、Twitter固有のエントリを含む語彙、強度スコアを含む語彙、感情をラベル付けする語彙が、より予測性が高い傾向にあります。NRC-Aff-Intは、NRC-EmoLexに含まれる怒り、恐れ、喜び、悲しみに関連するとされたすべての単語について、実数値の細かい単語-感情関連スコアを持っています。怒り、恐怖、喜びの相関は0.65前後とほぼ同じですが、悲しみの相関は0.71と著しく高くなっています。表5によると、悲しみに対する性能の向上は、ある程度は単語埋め込みによるものですが、それ以上に語彙機能、特にSentiStrengthによるものが大きいことがわかります。SentiStrengthはポジティブなクラスとネガティブなクラスにのみ焦点を当て、それぞれに数値スコアを提供しています。</a><br><br><a id="r111" onmouseover="over('r111', 's111')" onmouseout="out('s111')">6.1.1 中程度から高い強度の予測</a><br><br><a id="r112" onmouseover="over('r112', 's112')" onmouseout="out('s112')">このような場合には，感情の強さを正しく判断するためには，感情の強さが低い範囲よりも高い範囲の方が重要になることがあります．そこで，感情の強さの尺度が中程度から高程度の範囲にある場合の性能を評価するために，金の感情の強さのスコアが0.5以上のインスタンスのみを抽出したテストデータのサブセットについて，相関スコアを算出した．</a><br><br><a id="r113" onmouseover="over('r113', 's113')" onmouseout="out('s113')">その結果を表6に示します。まず、相関スコアは、0.5～1の範囲の強度のスコアでは、全強度の範囲での実験よりも全般的に低くなります。これは単純に、0.5から1の範囲では、ツイートが低い範囲にあるか高い範囲にあるかを粗く区別することでシステムが利益を得ることができないため、より困難なタスクであるためです。しかし、結果の大まかなパターンの多くは変わらず、いくつかの違いがあることがわかりました。レキシコンは依然として重要な役割を果たしていますが、現在ではエンベッディングとワードングラムもそれに劣らず重要な役割を果たしています。SentiStrengthは、この範囲ではあまり役に立たないようで、その主な利点は、低強度の悲しみの単語と高強度の悲しみの単語を分離することであったことを示唆しています。NRC-Hash-Emoは依然として最も予測性の高いレキシコン機能の源となっています。</a><br><br><a id="r114" onmouseover="over('r114', 's114')" onmouseout="out('s114')">25 http://saifmohammad.com/WebPages/AffectIntensity.htm...</a><br><br><a id="r115" onmouseover="over('r115', 's115')" onmouseout="out('s115')"> 個々の特徴セット単語のグラム(WN) 文字のグラム(CN) 単語のエンベッド。(WE) 全レキシコン (L) 個別レキシコン</a><br><br><a id="r116" onmouseover="over('r116', 's116')" onmouseout="out('s116')">AFINN BingLiu</a><br><br><a id="r117" onmouseover="over('r117', 's117')" onmouseout="out('s117')">MPQA NRC-Aff-Int NRC-EmoLex NRC10E NRC-Hash-Emo NRC-Hash-Sent Sentiment140 SentiWordNet SentiStrengthCombinationsWN + CN + WE WN + CN + LWE + LWN + WE + L</a><br><br><a id="r118" onmouseover="over('r118', 's118')" onmouseout="out('s118')">CN＋WE＋L WN＋CN＋WE＋L</a><br><br><a id="r119" onmouseover="over('r119', 's119')" onmouseout="out('s119')">0.42 0.49 0.52 0.50 0.48 0.45 0.48 0.54 0.57 0.62 0.60 0.60</a><br><br><a id="r120" onmouseover="over('r120', 's120')" onmouseout="out('s120')">0.48 0.27 0.40 0.33 0.31 0.37 0.18 0.20 0.28 0.24 0.28 0.37 0.18 0.26 0.36 0.35 0.34 0.43 0.55 0.55 0.46 0.33 0.24 0.41 0.33 0.41 0.40 0.14 0.19 0.26 0.43 0.34 0.46</a><br><br><a id="r121" onmouseover="over('r121', 's121')" onmouseout="out('s121')">0.50 0.48 0.45 0.61 0.61 0.61 0.64 0.63 0.65 0.63 0.65 0.65 0.65 0.61 0.61 0.62 0.61 0.61 0.61</a><br><br><a id="r122" onmouseover="over('r122', 's122')" onmouseout="out('s122')"> 表5： 感情の強さの予測値とゴールドスコアのピアソン相関（r）．各列の最良の結果は太字で示されている：特徴セットによる最高スコア、単一の語彙を用いた最高スコア、特徴セットの組み合わせによる最高スコア。</a><br><br><a id="r123" onmouseover="over('r123', 's123')" onmouseout="out('s123')">文字のみ、単語のみのN-gramを用いた場合、0.48前後の結果となり、それだけで感情の強さを表す指標として十分な効果があることが示唆されました。感情の強さのスコアを0から1の間でランダムに推測すると、相関が0に近くなることが予想されます）。感情辞書から抽出した特徴量を用いると、SentiWordNetの平均r = 0.19からNRC-Hash-Emoの平均r = 0.53までの結果が得られます。すべての語彙を組み合わせることで、個々の語彙に比べて統計的に有意な改善が見られます（平均r = 0.63）。異なる種類の特徴量を組み合わせると、さらに高いスコアが得られ、総合的には、単語埋め込みとレキシコンの特徴量を用いた結果が最も優れています（平均r = 0.66）24。また、文字ングラムなどの一部の特徴は、他の特徴があると冗長になることがわかりました。</a><br><br><a id="r124" onmouseover="over('r124', 's124')" onmouseout="out('s124')">23本論文で報告されているすべての有意差検定には、データを10回無作為に分割して算出した0.05の有意差レベルのWilcoxon signed-rank検定を使用しました。</a><br><br><a id="r125" onmouseover="over('r125', 's125')" onmouseout="out('s125')">240.63から0.66への増加は、統計的に有意である。</a><br><br><a id="r126" onmouseover="over('r126', 's126')" onmouseout="out('s126')">  怒り 恐怖 単語 ngrams (WN)文字 ngrams (CN)単語 embeds. (WE)全語彙 (L)個別語彙(低スコアの行はスペースの関係で表示されていない)Test Onfear joy 0.37 -0.37 0.65 -0.39-0.23 0.65 0.47 -0.32joy sad.</a><br><br><a id="r127" onmouseover="over('r127', 's127')" onmouseout="out('s127')">0.38 0.40 0.38.</a><br><br><a id="r128" onmouseover="over('r128', 's128')" onmouseout="out('s128')">avg.</a><br><br><a id="r129" onmouseover="over('r129', 's129')" onmouseout="out('s129')"> 個々の特徴セットの悲しさ 0.45 0.63 -0.41 0.65ピアソンの相関関係を見ると、逆に予測力が必要であることがわかります。また、恐怖と悲しみのデータを単純に組み合わせて学習し、そのモデルを使って悲しみを予測すると、0.67の相関が得られた（悲しみの学習セットだけで得られたスコアを上回る）27。</a><br><br><a id="r130" onmouseover="over('r130', 's130')" onmouseout="out('s130')">このセクションの実験では、2つの感情がどの程度、言語で表現されたときに類似しているかを示しました。ここで調べた4つの感情の類似性は、小さなもの（喜びと恐怖）からかなりのもの（悲しみと恐怖）まで様々である。また、その類似性は非対称である。また、興味のある感情の学習データを補完するために、別の感情の学習データを使用することが有益な場合があることを示しています。例えば、楽観主義は喜びと期待の組み合わせなのか、畏怖は恐怖と驚きの組み合わせなのかなど、感情の構成に関する理論を検証することが今後の課題である（Plutchik, 1980）。</a><br><br><a id="r131" onmouseover="over('r131', 's131')" onmouseout="out('s131')">7 おわりに</a><br><br><a id="r132" onmouseover="over('r132', 's132')" onmouseout="out('s132')">我々は、ツイートの感情強度データセットを初めて作成しました。ベストワーストスケーリングを用いてアノテーションの一貫性を向上させ、きめ細かなスコアを得ました。感情を表す言葉のハッシュタグは、感情の強さに影響を与え、より強い感情を伝えることが多いことを示しました。ベンチマーク回帰システムを作成して実験を行い、感情語彙、特に単語と感情の関連スコアが細かいものは、感情の強さを判断するのに有用であることを示しました。最後に、感情ペアがどの程度相関しているか、またその相関は非対称であることを示した。例えば、恐怖は悲しみを強く示すが、悲しみは恐怖を中程度にしか示さない。</a><br><br><a id="r133" onmouseover="over('r133', 's133')" onmouseout="out('s133')">感謝の気持ちを込めて</a><br><br><a id="r134" onmouseover="over('r134', 's134')" onmouseout="out('s134')">Svetlana Kiritchenko氏とTara Small氏には有益な議論をいただきました。</a><br><br><a id="r135" onmouseover="over('r135', 's135')" onmouseout="out('s135')">270.67-0.63の差は統計的に有意な差であるが、0.67-0.65と0.65-0.63の差は有意ではない。</a><br><br><a id="r136" onmouseover="over('r136', 's136')" onmouseout="out('s136')">電車に乗る 怒り 0.63 恐怖 0.46 喜び -0.41 悲しみ 0.39 0.36 0.39 0.36 0.41 0.42 0.48 0.47</a><br><br><a id="r137" onmouseover="over('r137', 's137')" onmouseout="out('s137')">0.34 0.34 0.36 0.37 0.51 0.43 0.29 0.51 0.44</a><br><br><a id="r138" onmouseover="over('r138', 's138')" onmouseout="out('s138')"> AFINN BingLiu NRC10E NRC-Hash-Emo Sentiment140 SentiStrengthCombinationsWN + CN + WE WN + CN + LWE + LWN + WE + L</a><br><br><a id="r139" onmouseover="over('r139', 's139')" onmouseout="out('s139')">CN＋WE＋L WN＋CN＋WE＋L</a><br><br><a id="r140" onmouseover="over('r140', 's140')" onmouseout="out('s140')">0.31 0.06 0.31 0.06 0.27 0.14 0.43 0.39 0.18 0.24 0.23 0.04</a><br><br><a id="r141" onmouseover="over('r141', 's141')" onmouseout="out('s141')">0.37 0.35 0.44 0.45 0.51 0.49 0.51 0.51 0.45 0.45 0.44 0.45...</a><br><br><a id="r142" onmouseover="over('r142', 's142')" onmouseout="out('s142')">0.11 0.05 0.13 0.11 0.05 0.13 0.25 0.30 0.24 0.15 0.44 0.35 0.09 0.32 0.21</a><br><br><a id="r143" onmouseover="over('r143', 's143')" onmouseout="out('s143')">表7：対象となる全ツイートの感情の強さの変換結果</a><br><br><a id="r144" onmouseover="over('r144', 's144')" onmouseout="out('s144')">表6：金色のスコアが0.5以上のテストセットのサブセットでのピアソン相関。</a><br><br><a id="r145" onmouseover="over('r145', 's145')" onmouseout="out('s145')">6.2 感情ペアの類似性</a><br><br><a id="r146" onmouseover="over('r146', 's146')" onmouseout="out('s146')">人間には何百種類もの感情がありますが、その中にはお互いに近いものもあります。ある感情ペアが近いと認識される理由の1つは、言語での表現が似ていることです。このような言語表現の類似性を定量化するために、Tweet Emotion Intensityデータセットを用いて以下の実験を行った。ある感情の学習データで回帰システム（特徴量WN + WE + L）を学習し、別の感情のテストデータで予測を評価する。</a><br><br><a id="r147" onmouseover="over('r147', 's147')" onmouseout="out('s147')">その結果を表7に示します。対角線上の数字は，同じ感情に関わるトレーニングデータとテストデータを用いて得られた結果である。これらの結果は，非対角線上の結果に対する上限のベンチマークであり，より低い値となることが予想される．ネガティブな感情同士は正の相関があり，唯一のポジティブな感情（喜び）とは負の相関があることがわかります。これらの相関の絶対値は、r=0.23からr=0.65となっています。これは、すべての感情ペアが少なくともある程度は相関していることを示していますが、例えば、恐怖のデータから学習して悲しみのスコアを予測する場合には、上限のベンチマーク（r = 0.65）に近い結果（r = 0.63）が得られる場合もあります26。これは、ある感情が260.63と0.65を強く予測していても、統計的に有意な差がないことを意味しています。</a><br><br><a id="r148" onmouseover="over('r148', 's148')" onmouseout="out('s148')">0.19 0.34</a><br><br><a id="r149" onmouseover="over('r149', 's149')" onmouseout="out('s149')">0.20</a><br><br><a id="r150" onmouseover="over('r150', 's150')" onmouseout="out('s150')">0.33 0.34 0.35 0.34 0.43 0.41 0.38 0.54 0.48</a><br><br><a id="r151" onmouseover="over('r151', 's151')" onmouseout="out('s151')">0.40 0.49</a><br><br><a id="r152" onmouseover="over('r152', 's152')" onmouseout="out('s152')">0.34 0.43 0.42 0.34 0.43 0.42.</a><br><br><a id="r153" onmouseover="over('r153', 's153')" onmouseout="out('s153')">0.47似ていない</a><br><br><a id="r154" onmouseover="over('r154', 's154')" onmouseout="out('s154')">リファレンス</a><br><br><a id="r155" onmouseover="over('r155', 's155')" onmouseout="out('s155')">Cecilia Ovesdotter Alm, Dan Roth, and Richard Sproat. 2005. Emotions from text: テキストベースの感情予測のための機械学習。2005 年。Van-couver, Canada.</a><br><br><a id="r156" onmouseover="over('r156', 's156')" onmouseout="out('s156')">Saima AmanとStan Szpakowicz。2007. テキスト中の感情表現の識別 In Text, Speech and Dialogue, volume 4629 of Lecture Notes in Com-puter Science, pages 196-205.</a><br><br><a id="r157" onmouseover="over('r157', 's157')" onmouseout="out('s157')">Johan Bollen, Huina Mao, and Alberto Pepe. 2009. 公共のムードと感情のモデリング。ツイッターの認知度と社会経済的現象。2009 年には、Twitter の認知度と社会経済的現象を考慮したモデル化を行いました。</a><br><br><a id="r158" onmouseover="over('r158', 's158')" onmouseout="out('s158')">Felipe Bravo-Marquez, Eibe Frank, Saif M Moham- mad, and Bernhard Pfahringer. 2016. マルチラベル分類によるツイートからの単語と感情の関連性の決定。In Proceedings of the 2016 IEEE/WIC/ACM International Conference on Web Intelligence. Omaha, NE, USA, pages 536-539.</a><br><br><a id="r159" onmouseover="over('r159', 's159')" onmouseout="out('s159')">Michael Brooks, Katie Kuksenok, Megan K Torkild- son, Daniel Perry, John J Robinson, Taylor J Scott, Ona Anicello, Ariana Zukowski, and Harris. 2013. 協調的なチャットにおける統計的な感情検出。本論文では、このようにして得られた知見をもとに、今後の研究開発の方向性を探る。2013年に開催されたComputer supported cooperative workの会議録。</a><br><br><a id="r160" onmouseover="over('r160', 's160')" onmouseout="out('s160')">LJ Cronbach. 1946. 半分の信頼性係数の事例研究。教育心理学雑誌 37(8):473.</a><br><br><a id="r161" onmouseover="over('r161', 's161')" onmouseout="out('s161')">ハーバート・アロン・デヴィッド 1963. 対になった比較の方法。Hafner Publishing Company, New York.</a><br><br><a id="r162" onmouseover="over('r162', 's162')" onmouseout="out('s162')">ポール・エックマン 1992. 基本的な感情のための議論。Cognition and Emotion 6(3):169-200.</a><br><br><a id="r163" onmouseover="over('r163', 's163')" onmouseout="out('s163')">Andrea Esuli, Fabrizio Sebastiani. 2006. senti-ワードネット。オピニオンマイニングのための一般に利用可能な字句資源。このようにして得られた成果は、今後の言語資源の活用に活かされるだろう。ジェノバ、イタリア、ページ417-422。</a><br><br><a id="r164" onmouseover="over('r164', 's164')" onmouseout="out('s164')">T. T.N.フリンとA.A.J.マーリー。2014. Best-Worst scal-ing: theory and methods. In Stephane Hess and An- drew Daly, editors, Handbook of Choice Modelling, Edward Elgar Publishing, pages 178-201.</a><br><br><a id="r165" onmouseover="over('r165', 's165')" onmouseout="out('s165')">ニコ・H・フレイダ。1988. 感情の法則。アメリカの心理学者 43(5):349.</a><br><br><a id="r166" onmouseover="over('r166', 's166')" onmouseout="out('s166')">Kevin Gimpel, Nathan Schneider, et al.2011. Twitterのための品詞タグ付け。アノテーション、機能、および実験。このようにして得られた成果は、今後も継続していきます。米国オレゴン州ポートランド市。</a><br><br><a id="r167" onmouseover="over('r167', 's167')" onmouseout="out('s167')">Alec Go, Richa Bhayani, and Lei Huang. 2009. 遠隔監視を用いたTwit-terセンチメント分類．CS224N Project Report, Stanford 1(12).</a><br><br><a id="r168" onmouseover="over('r168', 's168')" onmouseout="out('s168')">Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. WEKAデータマイニングソフトウェア。An update. SIGKDD Explor. Newsl. 11(1):10–18. https://doi.org/10.1145/1656274.1656278.</a><br><br><a id="r169" onmouseover="over('r169', 's169')" onmouseout="out('s169')">Minqing Hu and Bing Liu. 2004. カスタマーレビューのマイニングと集計。このように、本研究では様々な分野の研究者が参加している。ACM, New York, NY, USA, pages 168-177.</a><br><br><a id="r170" onmouseover="over('r170', 's170')" onmouseout="out('s170')">デビッド・ユルゲンス 2013. Embracing ambiguity: A com-parison of annotation methodologies for crowd-sourcing word sense labels. このようにして、私たちは自分たちの生活をより豊かにすることができるのです。米国ジョージア州アトランタ。</a><br><br><a id="r171" onmouseover="over('r171', 's171')" onmouseout="out('s171')">David Jurgens, Saif M. Mohammad, Peter Turney, and Keith Holyoak. 2012. Semeval-2012 task 2: Mea'suring degree of relational similarity. 2012.Semeval-2012 task 2: Mea'suring degree of relational similarity.In Proceed-ings of the 6th International Workshop on Semantic Evaluation. カナダ、モントレ・イェーナル、356-364ページ</a><br><br><a id="r172" onmouseover="over('r172', 's172')" onmouseout="out('s172')">スヴェトラーナ・キリチェンコ、サイフ・M・モハマド 2016. crowdsourcing and best-worst scalingによる信頼性の高い細やかな感情のアソシエーションの取得（Capturing fine-grained sentiment associa- tions by crowdsourcing and best-worst scaling）。In Proceedings of The 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: NAACL（Human Language Tech-nologies）。サンディエゴ、カリフォルニア。</a><br><br><a id="r173" onmouseover="over('r173', 's173')" onmouseout="out('s173')">スヴェトラーナ・キリチェンコ、サイフ・M・モハマド。2017. 評価スケールよりも信頼性の高いBest-worstスケーリング。A case study on sentiment intensity annotation. In Proceedings of The Annual Meeting of the Associa- tion for Computational Linguistics (ACL). Vancou- ver, Canada.</a><br><br><a id="r174" onmouseover="over('r174', 's174')" onmouseout="out('s174')">Svetlana Kiritchenko, Xiaodan Zhu, and Saif M. Mo- hammad. 2014. 短い情報量のテキストのセンチメント分析。人工知能研究誌 50:723-762.</a><br><br><a id="r175" onmouseover="over('r175', 's175')" onmouseout="out('s175')">G・フレデリック・クーダー、マリオン・W・リチャードソン 1937. テストの信頼性の推定の理論。Psy- chometrika 2(3):151-160.</a><br><br><a id="r176" onmouseover="over('r176', 's176')" onmouseout="out('s176')">FA Kunneman, CC Liebrecht, and APJ van den Bosch. 2014. ツイッターにおける感情的なハッシュタグの（非）予測可能性。第5回ワークショップ「ソーシャルメディアのための言語分析」の議事録。スウェーデン、ヨーテボリ、ページ26-34。</a><br><br><a id="r177" onmouseover="over('r177', 's177')" onmouseout="out('s177')">Jordan J. Louviere. 1991. 最悪のスケーリング。最大差判定のモデル。Working Paper.</a><br><br><a id="r178" onmouseover="over('r178', 's178')" onmouseout="out('s178')">Jordan J. Louviere, Terry N. Flynn, and A. A. J. Mar- ley. 2015. Best-Worst Scaling: Theory, Methods and Applications. Cambridge University Press.</a><br><br><a id="r179" onmouseover="over('r179', 's179')" onmouseout="out('s179')">Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. ベクトル空間における単語表現の効率的な推定。本論文では、このようにして得られた知見をもとに、今後の研究の方向性を検討する。</a><br><br><a id="r180" onmouseover="over('r180', 's180')" onmouseout="out('s180')">Saif M. Mohammad. 2012. #Emotional tweets. 本論文では、このような状況を想定した上で、本論文を作成した。</a><br><br><a id="r181" onmouseover="over('r181', 's181')" onmouseout="out('s181')">Saif M Mohammad. 2017. 単語の感情の強さ. arXiv preprint arXiv:1704.08798 .</a><br><br><a id="r182" onmouseover="over('r182', 's182')" onmouseout="out('s182')">Saif M. Mohammad、Felipe Bravo-Marquez。2017. WASSA-2017 感情強度に関する共有タスク。WASSA（Computational Ap-proaches to Subjectivity, Sentiment and Social Me-dia Analysis）のワークショップの議事録。デンマーク、コペンハーゲン。</a><br><br><a id="r183" onmouseover="over('r183', 's183')" onmouseout="out('s183')">Saif M. Mohammad and Svetlana Kiritchenko. 2015.</a><br><br><a id="r184" onmouseover="over('r184', 's184')" onmouseout="out('s184')">ハッシュタグを使って、ツイートから細かい感情の分類を捉える。Computational Intelligence 31(2):301-326. https://doi.org/10.1111/coin.12024.</a><br><br><a id="r185" onmouseover="over('r185', 's185')" onmouseout="out('s185')">Saif M. Mohammad, Svetlana Kiritchenko, and Xiao-dan Zhu. 2013. NRC-Canada: NRC-Canada: Building the state-of-the-art in sentiment analysis of tweets. NRC-Canada: Building state-of-the-art of sentiment analysis of tweets, In Pro-ceedings of the International Workshop on Semantic Evaluation. 米国ジョージア州アトランタ。</a><br><br><a id="r186" onmouseover="over('r186', 's186')" onmouseout="out('s186')">Saif M. Mohammad, Parinaz Sobhani, and Svetlana Kiritchenko. 2017. つぶやきにおけるスタンスとセンチメント。Special Section of the ACM Transactions on Inter-net Technology on Argumentation in Social Media 17(3).</a><br><br><a id="r187" onmouseover="over('r187', 's187')" onmouseout="out('s187')">Saif M. Mohammad and Peter D. Turney. 2013. 単語と感情の関連付け辞書のクラウドソーシング。Computational Intelligence 29(3):436-465.</a><br><br><a id="r188" onmouseover="over('r188', 's188')" onmouseout="out('s188')">Saif M. Mohammad, Xiaodan Zhu, Svetlana Kir- itchenko, and Joel Martin. 2015年7月。選挙人のツイートにおけるセンチメント、感情、目的、スタイル。In- formation Processing and Management 51(4):480- 499.</a><br><br><a id="r189" onmouseover="over('r189', 's189')" onmouseout="out('s189')">Alena Neviarouskaya, Helmut Prendinger, and Mit-suru Ishizuka. 2009. テキストから細かい感情を認識する際の合成原理。本論文では、このようにして得られた知見をもとに、今後の研究開発の方向性を探る。カリフォルニア州サンノゼ、ページ278-281。</a><br><br><a id="r190" onmouseover="over('r190', 's190')" onmouseout="out('s190')">FinnA ̊rupNielsen.2011.AnewANEW:Evaluation of a word list for sentiment analysis in microblogs. ESWC Workshop on 'Mak-ing Sense of Microposts'の議事録に掲載されています。大きなものは小さなパッケージでやってくる。Heraklion, Crete, pages 93-98.</a><br><br><a id="r191" onmouseover="over('r191', 's191')" onmouseout="out('s191')">Bryan Orme. 2009. Maxdiff分析．シンプルなカウントイン、個人レベルのロジット、およびHB。Sawtooth Soft-ware, Inc.</a><br><br><a id="r192" onmouseover="over('r192', 's192')" onmouseout="out('s192')">Alexander PakとPatrick Paroubek。2010. センチメント分析とオピニオンマイニングのためのコーパスとしてのTwitter。感情分析とオピニオンマイニングのためのコーパスとしてのTwitter。マルタ...</a><br><br><a id="r193" onmouseover="over('r193', 's193')" onmouseout="out('s193')">W Parrot. 2001. Emotions in Social Psychology（社会心理学における感情）．Psy-chology Press.</a><br><br><a id="r194" onmouseover="over('r194', 's194')" onmouseout="out('s194')">Sasˇa Petrovic ́, Miles Osborne, and Victor Lavrenko. 2010. Edinburgh Twitter corpus. このような場合には、このようなコーパスを使用してもよいでしょう。このように、本稿では、Twitterコーパスを利用した研究を紹介します。</a><br><br><a id="r195" onmouseover="over('r195', 's195')" onmouseout="out('s195')">ロバート・プラーチク 1980. 感情の一般的な精神進化論。Emotion: Theory, research, and experience 1(3):3-33.</a><br><br><a id="r196" onmouseover="over('r196', 's196')" onmouseout="out('s196')">Ashequl Qadir and Ellen Riloff. 2013. 感情ハッシュタグのブートストラップ付き学習# hashtags4you. 感情のハッシュタグ# hashtags4youのブートストラップ学習。2013.</a><br><br><a id="r197" onmouseover="over('r197', 's197')" onmouseout="out('s197')">Ashequl Qadir and Ellen Riloff. 2014. つぶやきからエモーション指標を学習する。ハッシュタグ、ハッシュタグパタン、およびフレーズ。In Proceedings of the EMNLP Workshop on Arabic Natural Langauge Processing (EMNLP). Doha, Qatar, pages 1203-1209.</a><br><br><a id="r198" onmouseover="over('r198', 's198')" onmouseout="out('s198')">Kirk Roberts, Michael A Roach, Joseph Johnson, Josh Guthrie, and Sanda M Harabagiu. 2012. Em- patweet: ツイッター上の感情の注釈付けと検出。このようにして得られた結果が、本論文である。</a><br><br><a id="r199" onmouseover="over('r199', 's199')" onmouseout="out('s199')">James A Russell. 2003. Core affect and the psychologically - ical construction of emotion. Psychological review 110(1):145.</a><br><br><a id="r200" onmouseover="over('r200', 's200')" onmouseout="out('s200')">Carlo Strapparava、Rada Mihalcea。2007. Semeval-2007 task 14: Affective text. SemEval-2007の議事録。プラハ、チェコ共和国、70-74ページ。</a><br><br><a id="r201" onmouseover="over('r201', 's201')" onmouseout="out('s201')">Anja Summa, Bernd Resch, Geoinformatics-Z GIS, and Michael Strube. 2016. テキスト、時間、空間の類似性を計算することによるマイクロブログの感情のクラス分け。COLINGでのPEOPLESワークショップの議事録である。大阪, 日本, ページ 153-162.</a><br><br><a id="r202" onmouseover="over('r202', 's202')" onmouseout="out('s202')">ジャレッド・サトルズとナンシー・イデ。2013. 離散的なバイナリ値を用いた感情分類のための遠隔監視。感情の分類には，離散的な二値値を用いた遠隔監視が必要である．</a><br><br><a id="r203" onmouseover="over('r203', 's203')" onmouseout="out('s203')">Mike Thelwall, Kevan Buckley, and Georgios Pal- toglou. 2012. ソーシャルウェブのためのセンチメント強度検出 本論文では、「ソーシャル・ウェブのためのセンチメント・ストレングス検出」をテーマとしています。</a><br><br><a id="r204" onmouseover="over('r204', 's204')" onmouseout="out('s204')">Louis L. Thurstone. 1927. 比較判断の法則。Psychological review 34(4):273.</a><br><br><a id="r205" onmouseover="over('r205', 's205')" onmouseout="out('s205')">Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. フレーズレベルのセンチメント分析における文脈上の極性の認識。このようにして、私たちは、この問題を解決することができました。米国ペンシルバニア州ストラウドスバーグ、ページ347-354。</a><br><br><a id="r206" onmouseover="over('r206', 's206')" onmouseout="out('s206')">フランク・イエーツ 1936. 不完全な無作為化ブロック。Annals of Human Genetics 7(2):121-140.</a><br><br><a id="r207" onmouseover="over('r207', 's207')" onmouseout="out('s207')">付録</a><br><br><a id="r208" onmouseover="over('r208', 's208')" onmouseout="out('s208')">A.1 感情の強さのスコアを得るためのBest-Worst Scaling質問票恐怖のアノテーションを得るために使用したBWS質問票を以下に示す。</a><br><br><a id="r209" onmouseover="over('r209', 's209')" onmouseout="out('s209')">英語のツイートにおける恐怖の度合い</a><br><br><a id="r210" onmouseover="over('r210', 's210')" onmouseout="out('s210')">恐怖心の尺度は、まったく怖くない（恐怖心ゼロ）から極度の恐怖心まで様々です。人はしばしば、その人が感じたり表現したりする恐怖の度合いを、その人の発言から推測することができます。この課題の目的は、この恐怖心の度合いを決定することです。恐怖の度合いを数値で表すのは難しいので、4種類のツイートをしてもらい、それを回答してもらいます。</a><br><br><a id="r211" onmouseover="over('r211', 's211')" onmouseout="out('s211')">- 4人のスピーカーのうち、どの人が最も恐怖を感じていると思われますか？</a><br><br><a id="r212" onmouseover="over('r212', 's212')" onmouseout="out('s212')">- 4人のスピーカーのうち、最も恐怖心が少ないと思われるのはどれでしょうか。</a><br><br><a id="r213" onmouseover="over('r213', 's213')" onmouseout="out('s213')">重要なお知らせ</a><br><br><a id="r214" onmouseover="over('r214', 's214')" onmouseout="out('s214')">- この課題は、話し手の恐怖レベルに関するものです（他の誰かが言及されたり話しかけられたりすることに対する恐怖ではありません）。</a><br><br><a id="r215" onmouseover="over('r215', 's215')" onmouseout="out('s215')">- 答えが2人以上のスピーカーのどちらかである可能性がある（つまり、同じように恐怖を感じている可能性が高い）場合は、いずれかのスピーカーを答えとして選択します。</a><br><br><a id="r216" onmouseover="over('r216', 's216')" onmouseout="out('s216')">- 最も重要なのは、答えを考えすぎないことです。本能の赴くままに。</a><br><br><a id="r217" onmouseover="over('r217', 's217')" onmouseout="out('s217')">例題</a><br><br><a id="r218" onmouseover="over('r218', 's218')" onmouseout="out('s218')">発言者1：私の写真をFBに載せないで！ #grrr 発言者2：先生がこんなに無能だと、どんな結果になるか心配です。</a><br><br><a id="r219" onmouseover="over('r219', 's219')" onmouseout="out('s219')">スピーカー3：今日の健康診断の結果 #terrified スピーカー4：たくさんの人の前で話さなければならないので、緊張しています。</a><br><br><a id="r220" onmouseover="over('r220', 's220')" onmouseout="out('s220')">Q1. 4人のスピーカーのうち、最も恐怖を感じていると思われるのはどのスピーカーでしょうか？ - 複数の選択肢があります。スピーカー1、2、3、4 - 回答：スピーカー3Q2. 4人のスピーカーのうち、最も恐怖を感じないと思われるのは誰でしょうか？選択肢：スピーカー1、2、3、4 - 回答：スピーカー1...</a><br><br><a id="r221" onmouseover="over('r221', 's221')" onmouseout="out('s221')">他の感情に関するアンケートも同様の構成となっています。アノテーション後のアンケートでは、課題は少なからず考える必要があるにもかかわらず、指示の明確さ（4.2/5）で高い評価を得ました（課題の容易さでは5点満点中3.5）。</a><br><br><a id="r222" onmouseover="over('r222', 's222')" onmouseout="out('s222')">A.2 感情を表す言葉のハッシュタグの使用</a><br><br><a id="r223" onmouseover="over('r223', 's223')" onmouseout="out('s223')">感情を表す言葉のハッシュタグ（#angry, #fearなど）を使って、関心のある感情を伝えている可能性の高いツイートを検索し、まとめています。多くの場合、これらのツイートは次の2つの方法のいずれかで使用されます。1. 遠隔監視のためのノイズの多いトレーニングデータとして（Pak and Paroubek, 2010; Mohammad, 2012; Sut- tles and Ide, 2013）。2. 2. 機械学習に適したトレーニングおよびテストデータセットを作成するために、手動で感情をアノテーションしたデータとして(Roberts et al., 2012; Qadir and Riloff, 2014; Mohammad et al., July 2015) 28 感情語ハッシュタグを使用して、「2」と同様のアノテーションデータを作成しますが、感情ごとに別々の感情強度データセットを作成するために使用します。また、感情語ハッシュタグが感情のインテンシティに与える影響を調べます。これまでに、特定の感情に関連するハッシュタグを学習する研究(Qadir and Riloff, 2013)や、感情語ハッシュタグの中には、ツイートの残りの部分における感情の存在を強く示唆するものとそうでないものがあることを示す研究(Kunneman et al., 2014)がありますが、これはこれまでに研究されていませんでした。</a><br><br><a id="r224" onmouseover="over('r224', 's224')" onmouseout="out('s224')">A.3 AffectiveTweets Wekaパッケージ</a><br><br><a id="r225" onmouseover="over('r225', 's225')" onmouseout="out('s225')">AffectiveTweetsには、ツイートを特徴ベクトルに変換するための5つのフィルターが含まれており、Weka内に実装された機械学習アルゴリズムの大規模なコレクションに供給することができます。このパッケージは、WekaPackageManagerを使用してインストールされ、WekaのGUIまたはコマンドラインインターフェースから使用できます。トークン化とPOSタグ付けにはTweetNLPライブラリ(Gimpel et al., 2011)を使用しています。フィルターの説明は以下の通りです。</a><br><br><a id="r226" onmouseover="over('r226', 's226')" onmouseout="out('s226')">- TweetToSparseFeatureVectorフィルター：単語Nグラム（否定文脈に出現する単語にはNEG接頭辞を付加）、文字Nグラム（CN）、POSタグ、Brown単語クラスタのスパースな特徴量を計算する29。</a><br><br><a id="r227" onmouseover="over('r227', 's227')" onmouseout="out('s227')">28分類タスクの明らかな手がかりを消すために、ツイートからクエリ用語が削除されることがよくあります。</a><br><br><a id="r228" onmouseover="over('r228', 's228')" onmouseout="out('s228')">否定の範囲は、「否定語の出現から、句読点または文末まで」というシンプルなヒューリスティックな方法で決定しました。否定語としては、no, not, won't, never...など28語のリストを用いた。</a><br><br><a id="r229" onmouseover="over('r229', 's229')" onmouseout="out('s229')"> 図2：Tweet Emotion Intensity Datasetを探索するためのインタラクティブ・ビジュアライゼーションのスクリーンショット。利用可能なサイト： http://saifmohammad.com/WebPages/EmotionIntensity-SharedTask.html</a><br><br><a id="r230" onmouseover="over('r230', 's230')" onmouseout="out('s230')">- TweetToLexiconFeatureVectorフィルタ：固定された語彙リストから特徴量を計算します。- TweetToInputLexiconFeatureVector：特徴量を計算します。</a><br><br><a id="r231" onmouseover="over('r231', 's231')" onmouseout="out('s231')">の機能を利用することができます。入力辞書は、複数の数値または名詞の単語と影響の関連を持つことができます。</a><br><br><a id="r232" onmouseover="over('r232', 's232')" onmouseout="out('s232')">- TweetToSentiStrengthFeatureVectorフィルター：SentiStrength辞書ベースの手法を用いて、ツイートの正負の感情強度を計算する（Thelwall et al, 2012）。</a><br><br><a id="r233" onmouseover="over('r233', 's233')" onmouseout="out('s233')">- TweetToEmbeddingsFeatureVector フィルタ: 事前に学習された単語埋め込みを用いてツイートレベルの特徴表現を計算し、次の集約スキームをサポートします: 単語埋め込みの平均、単語埋め込みの追加、ツイートの最初のk個の単語埋め込みの連結。また、本パッケージは Word2Vec の事前学習済みの単語埋め込みを提供します。</a><br><br><a id="r234" onmouseover="over('r234', 's234')" onmouseout="out('s234')">また、ツイートから感情を表す語彙を作成するフィルターや、遠隔地からの監視をサポートする機能は現在開発中です。</a><br><br><a id="r235" onmouseover="over('r235', 's235')" onmouseout="out('s235')">A.4 ツイートの感情の強さのデータセットを探索するためのインタラクティブな視覚化</a><br><br><a id="r236" onmouseover="over('r236', 's236')" onmouseout="out('s236')">私たちは、この新しいデータセットを簡単に探索できるように、インタラクティブなビジュアライゼーションを作成しました。ビジュアライゼーションにはいくつかのコンポーネントがあります。</a><br><br><a id="r237" onmouseover="over('r237', 's237')" onmouseout="out('s237')">1. のインスタンスの割合を示す表</a><br><br><a id="r238" onmouseover="over('r238', 's238')" onmouseout="out('s238')">感情の各パーティション（train, dev, test）。行にカーソルを合わせると、対応するインスタンス数が表示されます。ある感情をクリックすると、すべての可視化コンポーネントにおいて、他のすべての感情のデータがフィルタリングされます。同様に、train、dev、testの各パーティションをクリックすると、そのデータだけの情報を表示することができます。もう一度クリックすると、その項目の選択が解除されます。</a><br><br><a id="r239" onmouseover="over('r239', 's239')" onmouseout="out('s239')">2. 感情強度スコアのヒストグラム。特定のスコア範囲のツイートのみを表示するためのスライダー。</a><br><br><a id="r240" onmouseover="over('r240', 's240')" onmouseout="out('s240')">3. ツイートの一覧、感情ラベル、感情強度スコア。</a><br><br><a id="r241" onmouseover="over('r241', 's241')" onmouseout="out('s241')">フィルターは組み合わせて使うことができます。例えば、恐怖、テストデータをクリックし、スライダーを0.5から1の範囲に設定すると、スコアが0.5以上の恐怖-テストデータのインスタンスのみの情報が表示されます。</a><br>
</div>
</div><style>
:root {
--main-text: #452b15;
--main-bg: #f8f1e2;
--highlight-text: #db8e3c;
}
:root[theme="dark"] {
--main-text: #b0b0b0;
--main-bg: #121212;
--highlight-text: #fd8787;
}
h1 {
color: var(--main-text);
}
input {
position: absolute;
top: 1%;
right: 1%;
}
#source {
width: 43%;
height: 90%;
padding: 0 2%;
float: left;
border-right:1px solid #ccc;
margin: 1%;
overflow: auto;
}
#result {
width: 43%;
height: 90%;
padding: 0 2%;
float: right;
margin: 1%;
overflow: auto;
}
a,
a:hover,
a:visited,
a:link,
a:active {
color: var(--main-text);
text-decoration: none;
}
body {
background-color: var(--main-bg);
}
</style>
<script>
var a = document.getElementsByTagName("a");
function over(s,o) {
var elements = document.getElementById(s);
var elemento = document.getElementById(o);
var rects = elements.getBoundingClientRect();
var recto = elemento.getBoundingClientRect();
var x = recto.left;
var y = recto.top - rects.top;
elemento.parentNode.scrollBy(x, y);
elemento.style.color = getComputedStyle(elemento).getPropertyValue("--highlight-text");
}
function out(e) {
document.getElementById(e).style.color = getComputedStyle(document.getElementById(e)).getPropertyValue("--main-text");
}
const btn = document.querySelector("#btn-mode");
btn.addEventListener("change", () => {
if (btn.checked == true) {
document.documentElement.setAttribute("theme", "dark");
} else {
document.documentElement.setAttribute("theme", "light");
}
for (var i = 0; i < a.length; i++) {
a[i].style.color = getComputedStyle(a[i]).getPropertyValue("--main-text");
}
});
</script>
</body>